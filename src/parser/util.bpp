// parse_util.b - Parser utility functions
//
// Core parser operations:
// - Parser state management (new, peek, advance, prev)
// - Token matching and consuming
// - Error reporting

import std.io;
import std.vec;
import std.util;
import std.str;
import types;
import lexer;
import compiler;

var g_active_parser: *Parser = 0;

// ============================================
// Error Reporting Helpers
// ============================================

func token_kind_name(kind: u64) -> u64 {
    switch (kind) {
        case TOKEN_EOF: return "EOF";
        case TOKEN_NUMBER: return "number";
        case TOKEN_FLOAT: return "float";
        case TOKEN_IDENTIFIER: return "identifier";
        case TOKEN_STRING: return "string";
        case TOKEN_LPAREN: return "'('";
        case TOKEN_RPAREN: return "')'";
        case TOKEN_LBRACE: return "'{'";
        case TOKEN_RBRACE: return "'}'";
        case TOKEN_LBRACKET: return "'['";
        case TOKEN_RBRACKET: return "']'";
        case TOKEN_SEMICOLON: return "';'";
        case TOKEN_COLON: return "':'";
        case TOKEN_COMMA: return "','";
        case TOKEN_DOT: return "'.'";
        case TOKEN_DOT_Q: return "'.?'";
        case TOKEN_ARROW: return "'->'";
        case TOKEN_QUESTION: return "'?'";
        case TOKEN_AT: return "'@'";
        case TOKEN_PLUS: return "'+'";
        case TOKEN_MINUS: return "'-'";
        case TOKEN_STAR: return "'*'";
        case TOKEN_SLASH: return "'/'";
        case TOKEN_PERCENT: return "'%'";
        case TOKEN_EQ: return "'='";
        case TOKEN_EQEQ: return "'=='";
        case TOKEN_BANGEQ: return "'!='";
        case TOKEN_LT: return "'<'";
        case TOKEN_LTEQ: return "'<='";
        case TOKEN_GT: return "'>'";
        case TOKEN_GTEQ: return "'>='";
        case TOKEN_AMPERSAND: return "'&'";
        case TOKEN_PIPE: return "'|'";
        case TOKEN_CARET: return "'^'";
        case TOKEN_ANDAND: return "'&&'";
        case TOKEN_OROR: return "'||'";
        case TOKEN_BANG: return "'!'";
        case TOKEN_PLUSPLUS: return "'++'";
        case TOKEN_MINUSMINUS: return "'--'";
        case TOKEN_PLUS_EQ: return "'+='";
        case TOKEN_MINUS_EQ: return "'-='";
        case TOKEN_STAR_EQ: return "'*='";
        case TOKEN_SLASH_EQ: return "'/='";
        case TOKEN_PERCENT_EQ: return "'%='";
        case TOKEN_TILDE: return "'~'";
        case TOKEN_LSHIFT: return "'<<'";
        case TOKEN_RSHIFT: return "'>>'";
        case TOKEN_VAR: return "'var'";
        case TOKEN_FUNC: return "'func'";
        case TOKEN_RETURN: return "'return'";
        case TOKEN_IF: return "'if'";
        case TOKEN_ELSE: return "'else'";
        case TOKEN_WHILE: return "'while'";
        case TOKEN_MATCH: return "'match'";
        case TOKEN_TRY: return "'try'";
        case TOKEN_CATCH: return "'catch'";
        case TOKEN_FINALLY: return "'finally'";
        case TOKEN_THROW: return "'throw'";
        case TOKEN_WHERE: return "'where'";
        case TOKEN_FOR: return "'for'";
        case TOKEN_BREAK: return "'break'";
        case TOKEN_CONTINUE: return "'continue'";
        case TOKEN_ALIAS: return "'alias'";
        case TOKEN_DEFER: return "'defer'";
        case TOKEN_NEW: return "'new'";
        case TOKEN_DELETE: return "'delete'";
        case TOKEN_PUBLIC: return "'public'";
        case TOKEN_PRIVATE: return "'private'";
        case TOKEN_PROTECTED: return "'protected'";
        case TOKEN_SUPER: return "'super'";
        case TOKEN_STATIC: return "'static'";
        case TOKEN_ABST: return "'abst'";
        case TOKEN_ASSERT: return "'assert'";
        case TOKEN_TODO: return "'todo'";
        case TOKEN_UNREACHABLE: return "'unreachable'";
        case TOKEN_BOOL: return "'bool'";
        case TOKEN_I8: return "'i8'";
        case TOKEN_I16: return "'i16'";
        case TOKEN_I32: return "'i32'";
        case TOKEN_F64: return "'f64'";
        case TOKEN_CONSTRUCTOR: return "'constructor'";
        case TOKEN_DESTRUCTOR: return "'destructor'";
        case TOKEN_IMPORT: return "'import'";
        case TOKEN_STRUCT: return "'struct'";
        case TOKEN_UNION: return "'union'";
        case TOKEN_ENUM: return "'enum'";
        case TOKEN_CONST: return "'const'";
        case TOKEN_TRUE: return "'true'";
        case TOKEN_FALSE: return "'false'";
        case TOKEN_SIZEOF: return "'sizeof'";
        case TOKEN_CHAR: return "'char'";
    }
    return "unknown token";
}

func token_kind_name_len(kind: u64) -> u64 {
    return str_len(token_kind_name(kind));
}

func parse_normalize_error_msg(msg: u64) -> u64 {
    if (msg == 0) { return "Syntax error"; }
    if (str_eq(msg, str_len(msg), "Parse error", 11)) {
        return "Syntax error";
    }
    if (str_eq(msg, str_len(msg), "Syntax error", 12)) {
        return "Syntax error";
    }
    return msg;
}

func parse_set_active_parser(p: *Parser) -> u64 {
    g_active_parser = p;
    return 0;
}

func parse_error_count(p: *Parser) -> u64 {
    if (p == 0) { return 0; }
    return p.error_count;
}

func parse_has_errors(p: *Parser) -> u64 {
    if (p == 0) { return 0; }
    if (p.error_count == 0) { return 0; }
    return 1;
}

func parse_set_recovery_mode(p: *Parser, enabled: u64, max_errors: u64) -> u64 {
    if (p == 0) { return 0; }
    p.recovery_enabled = enabled;
    if (max_errors == 0) { max_errors = 20; }
    p.max_errors = max_errors;
    p.error_limit_reached = 0;
    return 0;
}

func parse_record_error(p: *Parser) -> u64 {
    if (p == 0) { return 0; }
    if (p.error_limit_reached != 0) { return p.error_count; }
    p.error_count = p.error_count + 1;
    return p.error_count;
}

func parse_is_sync_decl_token(kind: u64) -> u64 {
    switch (kind) {
        case TOKEN_FUNC:
        case TOKEN_CONST:
        case TOKEN_ENUM:
        case TOKEN_STRUCT:
        case TOKEN_UNION:
        case TOKEN_PACKED:
        case TOKEN_TRAIT:
        case TOKEN_IMPL:
        case TOKEN_VAR:
        case TOKEN_IMPORT:
        case TOKEN_AT:
            return 1;
    }
    return 0;
}

func parse_recover_sync(p: *Parser) -> u64 {
    if (p == 0) { return 0; }
    if (p.recovering != 0) { return 0; }
    if (p.error_limit_reached != 0) {
        while (parse_peek_kind(p) != TOKEN_EOF) {
            parse_adv(p);
        }
        return 0;
    }
    p.recovering = 1;

    // Ensure forward progress first.
    if (parse_peek_kind(p) != TOKEN_EOF) {
        parse_adv(p);
    }

    while (1) {
        var k: u64 = parse_peek_kind(p);
        if (k == TOKEN_EOF) { break; }
        if (parse_is_sync_decl_token(k) != 0) { break; }
        if (k == TOKEN_SEMICOLON) {
            parse_adv(p);
            break;
        }
        if (k == TOKEN_RBRACE) { break; }
        parse_adv(p);
    }

    p.recovering = 0;
    return 0;
}

func parse_panic_at_tok(tok: *Token, msg: u64) -> u64 {
    var err_msg: u64 = parse_normalize_error_msg(msg);
    var err_len: u64 = str_len(err_msg);
    end_error_capture();
    set_error_context(err_msg, err_len);

    emit_stderr("[ERROR] ");
    emit_stderr_len(err_msg, err_len);
    if (tok != 0) {
        emit_stderr(" at line ");
        emit_u64_stderr(tok.line);
        emit_stderr(", column ");
        emit_u64_stderr(tok.col);
        emit_stderr(" (token kind=");
        emit_stderr_len(token_kind_name(tok.kind), token_kind_name_len(tok.kind));
        emit_stderr(", id=");
        emit_u64_stderr(tok.kind);
        emit_stderr(")");
        if (tok.kind != TOKEN_EOF && tok.ptr != 0 && tok.len != 0) {
            emit_stderr(" near `");
            emit_stderr_len(tok.ptr, tok.len);
            emit_stderr("`");
        }
    }
    emit_stderr_nl();

    var p: *Parser = g_active_parser;
    if (p != 0 && p.recovery_enabled != 0) {
        var total: u64 = parse_record_error(p);
        if (total >= p.max_errors) {
            if (p.error_limit_reached == 0) {
                emit_stderr("[ERROR] parser error limit reached; aborting parse\n");
            }
            p.error_limit_reached = 1;
            parse_recover_sync(p);
            return 0;
        }
        parse_recover_sync(p);
        return 0;
    }

    panic(err_msg);
    return 0;
}

func parse_panic_here(p: *Parser, msg: u64) -> u64 {
    var tok: *Token = parse_peek(p);
    if (tok == 0) { tok = parse_prev(p); }
    return parse_panic_at_tok(tok, msg);
}

func report_parse_error(expected_kind: u64, actual_kind: u64, tok: *Token) -> u64 {
    end_error_capture();
    set_error_context("Unexpected token", 16);
    
    emit_stderr("\n[ERROR] Syntax error at line ");
    if (tok != 0) {
        emit_u64_stderr(tok.line);
        emit_stderr(", column ");
        emit_u64_stderr(tok.col);
    }
    emit_stderr_nl();
    
    emit_stderr("  Expected: ");
    emit_stderr_len(token_kind_name(expected_kind), token_kind_name_len(expected_kind));
    emit_stderr_nl();
    emit_stderr("  Expected kind id: ");
    emit_u64_stderr(expected_kind);
    emit_stderr_nl();
    
    emit_stderr("  Got:      ");
    emit_stderr_len(token_kind_name(actual_kind), token_kind_name_len(actual_kind));
    
    if (tok != 0) {
        if (actual_kind != TOKEN_EOF) {
            emit_stderr(" ");
            emit_stderr_len(tok.ptr, tok.len);
        }
    }
    emit_stderr_nl();
    emit_stderr("  Got kind id: ");
    emit_u64_stderr(actual_kind);
    emit_stderr_nl();
    if (tok != 0 && actual_kind != TOKEN_EOF && tok.ptr != 0 && tok.len != 0) {
        emit_stderr("  Near: ");
        emit_stderr_len(tok.ptr, tok.len);
        emit_stderr_nl();
    }
    parse_panic_at_tok(tok, "Unexpected token");
    return 0;
}

func report_integer_overflow_error(tok: *Token) -> u64 {
    set_error_context("Integer overflow", 16);
    emit_stderr("[ERROR] Integer literal overflow at ");
    emit_u64_stderr(tok.line);
    emit_stderr(":");
    emit_u64_stderr(tok.col);
    emit_stderr(" literal=");
    emit_stderr_len(tok.ptr, tok.len);
    emit_stderr_nl();
    parse_panic_at_tok(tok, "Integer literal overflow");
    return 0;
}

func parse_is_keyword_char_token(tok: *Token) -> u64 {
    if (tok == 0) { return 0; }
    if (tok.kind != TOKEN_CHAR) { return 0; }
    if (tok.len != 4) { return 0; }
    if (str_eq(tok.ptr, tok.len, "char", 4) == 0) { return 0; }
    return 1;
}

func parse_is_char_literal_token(tok: *Token) -> u64 {
    if (tok == 0) { return 0; }
    if (tok.kind != TOKEN_CHAR) { return 0; }
    if (tok.len < 3) { return 0; }
    var u8_view: []u8 = slice(tok.ptr, tok.len);
    if (u8_view[0] != 39) { return 0; }
    if (u8_view[tok.len - 1] != 39) { return 0; }
    return 1;
}

func parse_char_literal_value(tok: *Token) -> u64 {
    if (parse_is_char_literal_token(tok) == 0) {
        emit_stderr("[ERROR] Invalid char literal\n");
        parse_panic_at_tok(tok, "Syntax error");
    }

    var u8_view2: []u8 = slice(tok.ptr, tok.len);
    if (tok.len == 3) {
        if (u8_view2[1] == 92) {
            emit_stderr("[ERROR] Invalid escape char literal\n");
            parse_panic_at_tok(tok, "Syntax error");
        }
        return u8_view2[1];
    }

    if (tok.len == 4 && u8_view2[1] == 92) {
        var esc: u64 = u8_view2[2];
        if (esc == 110) { return 10; }  // \n
        if (esc == 116) { return 9; }   // \t
        if (esc == 114) { return 13; }  // \r
        if (esc == 48) { return 0; }    // \0
        if (esc == 92) { return 92; }   // \\
        if (esc == 39) { return 39; }   // \'
        emit_stderr("[ERROR] Unknown escape in char literal\n");
        parse_panic_at_tok(tok, "Syntax error");
    }

    emit_stderr("[ERROR] Char literal must contain exactly one character\n");
    parse_panic_at_tok(tok, "Syntax error");
    return 0;
}

// Parser structure: [tokens_vec, cur]

func parse_new(tokens: *Vec<*Token>) -> *Parser {
    var p: *Parser = new Parser();
    p.tokens_vec = tokens;
    p.cur = 0;
    p.pending_gt_active = 0;
    p.pending_gt_tok = 0;
    p.peek_cache_valid = 0;
    p.peek_cache_pos = 0;
    p.peek_cache_tok = 0;
    p.recovery_enabled = 1;
    p.recovering = 0;
    p.error_count = 0;
    p.max_errors = 20;
    p.error_limit_reached = 0;
    p.fn_param_scope_stack = 0;
    return p;
}

func parser_push_function_param_scope(p: *Parser, params: *Vec<*Param>) -> u64 {
    if (p == 0 || params == 0) { return 0; }
    if (p.fn_param_scope_stack == 0) {
        p.fn_param_scope_stack = new Vec<*Vec<*Param>>(8);
    }
    p.fn_param_scope_stack.push(params);
    return 0;
}

func parser_pop_function_param_scope(p: *Parser) -> u64 {
    if (p == 0 || p.fn_param_scope_stack == 0) { return 0; }
    if (p.fn_param_scope_stack.len() == 0) { return 0; }
    p.fn_param_scope_stack.pop();
    return 0;
}

func parser_current_function_has_param_name(p: *Parser, name_ptr: u64, name_len: u64) -> u64 {
    if (p == 0 || name_ptr == 0 || name_len == 0) { return 0; }
    if (p.fn_param_scope_stack == 0 || p.fn_param_scope_stack.len() == 0) { return 0; }
    var top_idx: u64 = p.fn_param_scope_stack.len() - 1;
    var params: *Vec<*Param> = p.fn_param_scope_stack.get(top_idx);
    if (params == 0) { return 0; }
    var n: u64 = params.len();
    for (var i: u64 = 0; i < n; i++) {
        var param: *Param = params.get(i);
        if (param == 0) { continue; }
        if (str_eq(param.name_ptr, param.name_len, name_ptr, name_len) != 0) {
            return 1;
        }
    }
    return 0;
}

func parse_peek(p: *Parser) -> *Token {
    var parser: *Parser = p;
    if (parser.pending_gt_active != 0) { return parser.pending_gt_tok; }
    if (parser.peek_cache_valid != 0 && parser.peek_cache_pos == parser.cur) {
        return parser.peek_cache_tok;
    }
    if (parser.cur >= parser.tokens_vec.len()) { return 0; }
    var tok: *Token = parser.tokens_vec.get(parser.cur);
    parser.peek_cache_valid = 1;
    parser.peek_cache_pos = parser.cur;
    parser.peek_cache_tok = tok;
    return tok;
}

func parse_peek_kind(p: *Parser) -> u64 {
    if (p != 0 && p.error_limit_reached != 0) { return TOKEN_EOF; }
    var tok: *Token = parse_peek(p);
    if (tok == 0) { return TOKEN_EOF; }
    return tok.kind;
}

func parse_adv(p: *Parser) -> u64 {
    var parser: *Parser = p;
    if (parser.pending_gt_active != 0) {
        parser.pending_gt_active = 0;
        parser.pending_gt_tok = 0;
        parser.peek_cache_valid = 0;
        return 0;
    }
    parser.cur = parser.cur + 1;
    parser.peek_cache_valid = 0;
}

func parser_pos(p: *Parser) -> u64 {
    var parser: *Parser = p;
    return parser.cur;
}

func parser_set_pos(p: *Parser, pos: u64) {
    var parser: *Parser = p;
    parser.cur = pos;
    parser.pending_gt_active = 0;
    parser.pending_gt_tok = 0;
    parser.peek_cache_valid = 0;
}

func parse_prev(p: *Parser) -> *Token {
    var parser: *Parser = p;
    if (parser.cur == 0) { return 0; }
    return parser.tokens_vec.get(parser.cur - 1);
}

func parse_match(p: *Parser, kind: u64) -> u64 {
    if (parse_peek_kind(p) == kind) {
        parse_adv(p);
        return true;
    }
    return false;
}

func parse_consume(p: *Parser, kind: u64) -> u64 {
    if (p != 0 && p.error_limit_reached != 0) { return 0; }
    if (!parse_match(p, kind)) {
        var tok: *Token = parse_peek(p);
        var got: u64 = parse_peek_kind(p);
        report_parse_error(kind, got, tok);
    }
}

func parse_consume_generic_gt(p: *Parser) -> u64 {
    var parser: *Parser = p;
    var k: u64 = parse_peek_kind(p);
    if (k == TOKEN_GT) {
        parse_adv(p);
        return 0;
    }
    if (k == TOKEN_RSHIFT) {
        var t: *Token = parse_peek(p);
        var pending: *Token = tok_new(TOKEN_GT, t.ptr + 1, 1, t.line, t.col + 1);
        parser.pending_gt_active = 1;
        parser.pending_gt_tok = pending;
        parser.cur = parser.cur + 1;
        parser.peek_cache_valid = 0;
        return 0;
    }
    var tok2: *Token = parse_peek(p);
    report_parse_error(TOKEN_GT, k, tok2);
}

func parse_capture_annotation_args(p: *Parser) -> *NameInfo {
    if (parse_peek_kind(p) != TOKEN_LPAREN) { return 0; }
    var start_tok: *Token = parse_peek(p);
    var start_ptr: u64 = start_tok.ptr;
    parse_adv(p);

    var depth: u64 = 1;
    var end_ptr: u64 = start_ptr + 1;
    while (depth > 0) {
        var tok: *Token = parse_peek(p);
        var k: u64 = tok.kind;
        if (k == TOKEN_EOF) {
            emit_stderr("[ERROR] annotation argument list is not closed\n");
            parse_panic_here(p, "Syntax error");
            return 0;
        }
        if (k == TOKEN_LPAREN) {
            depth = depth + 1;
        } else if (k == TOKEN_RPAREN) {
            depth = depth - 1;
        }
        parse_adv(p);
        end_ptr = tok.ptr + tok.len;
    }
    return new NameInfo{start_ptr, end_ptr - start_ptr};
}

func parse_annotation_compose_name(name_ptr: u64, name_len: u64, args: *NameInfo) -> *NameInfo {
    if (args == 0 || args.ptr == 0 || args.len == 0) {
        return new NameInfo{name_ptr, name_len};
    }
    var out_len: u64 = name_len + args.len;
    var out_ptr: u64 = heap_alloc((out_len + 1) * sizeof(u8));
    var out_u8: []u8 = slice(out_ptr, out_len + 1);
    str_copy(out_ptr, name_ptr, name_len);
    str_copy(out_ptr + name_len, args.ptr, args.len);
    out_u8[out_len] = 0;
    return new NameInfo{out_ptr, out_len};
}

func parse_consume_annotation_group(p: *Parser) -> *Vec<*NameInfo> {
    parse_consume(p, TOKEN_AT);
    parse_consume(p, TOKEN_LBRACKET);

    var names: *Vec<*NameInfo> = new Vec<*NameInfo>(2);
    while (1) {
        var name_tok: *Token = parse_peek(p);
        if (parse_peek_kind(p) != TOKEN_IDENTIFIER) {
            emit_stderr("[ERROR] annotation name must be identifier\n");
            parse_panic_here(p, "Syntax error");
        }
        parse_adv(p);
        var ann_args: *NameInfo = 0;
        if (parse_peek_kind(p) == TOKEN_LPAREN) {
            ann_args = parse_capture_annotation_args(p);
        }
        names.push(parse_annotation_compose_name(name_tok.ptr, name_tok.len, ann_args));
        if (parse_match(p, TOKEN_COMMA) == 0) { break; }
    }

    parse_consume(p, TOKEN_RBRACKET);
    return names;
}

func parse_annotations_append(dst: *Vec<*NameInfo>, src: *Vec<*NameInfo>) -> *Vec<*NameInfo> {
    if (src == 0) { return dst; }
    if (dst == 0) {
        dst = new Vec<*NameInfo>(src.len() + 1);
    }
    var n: u64 = src.len();
    for (var i: u64 = 0; i < n; i++) {
        dst.push(src.get(i));
    }
    return dst;
}

func parse_take_leading_annotations(p: *Parser) -> *Vec<*NameInfo> {
    var annotations: *Vec<*NameInfo> = 0;
    while (parse_peek_kind(p) == TOKEN_AT) {
        var group: *Vec<*NameInfo> = parse_consume_annotation_group(p);
        annotations = parse_annotations_append(annotations, group);
    }
    return annotations;
}

func parse_annotation_name_base_len(name_ptr: u64, name_len: u64) -> u64 {
    if (name_ptr == 0 || name_len == 0) { return 0; }
    var s: []u8 = slice(name_ptr, name_len);
    for (var i: u64 = 0; i < name_len; i++) {
        if (s[i] == 40) { // '('
            return i;
        }
    }
    return name_len;
}

func parse_annotation_name_matches(info: *NameInfo, name_ptr: u64, name_len: u64) -> u64 {
    if (info == 0 || info.ptr == 0 || info.len == 0) { return 0; }
    var base_len: u64 = parse_annotation_name_base_len(info.ptr, info.len);
    if (base_len != name_len) { return 0; }
    if (str_eq(info.ptr, base_len, name_ptr, name_len) == 0) { return 0; }
    return 1;
}

func parse_annotations_contains(annotations: *Vec<*NameInfo>, name_ptr: u64, name_len: u64) -> u64 {
    if (annotations == 0) { return 0; }
    var n: u64 = annotations.len();
    for (var i: u64 = 0; i < n; i++) {
        var info: *NameInfo = annotations.get(i);
        if (parse_annotation_name_matches(info, name_ptr, name_len) != 0) { return 1; }
    }
    return 0;
}

func parse_peek_kind_after_annotations(p: *Parser) -> u64 {
    if (parse_peek_kind(p) != TOKEN_AT) { return parse_peek_kind(p); }

    var saved: u64 = parser_pos(p);
    while (parse_peek_kind(p) == TOKEN_AT) {
        parse_adv(p);
        if (parse_peek_kind(p) != TOKEN_LBRACKET) {
            parser_set_pos(p, saved);
            return TOKEN_AT;
        }
        parse_adv(p);
        if (parse_peek_kind(p) != TOKEN_IDENTIFIER) {
            parser_set_pos(p, saved);
            return TOKEN_AT;
        }
        parse_adv(p);
        if (parse_peek_kind(p) == TOKEN_LPAREN) {
            var depth: u64 = 1;
            parse_adv(p);
            while (depth > 0) {
                var ak: u64 = parse_peek_kind(p);
                if (ak == TOKEN_EOF) {
                    parser_set_pos(p, saved);
                    return TOKEN_AT;
                }
                if (ak == TOKEN_LPAREN) {
                    depth = depth + 1;
                } else if (ak == TOKEN_RPAREN) {
                    depth = depth - 1;
                }
                parse_adv(p);
            }
        }
        while (parse_peek_kind(p) == TOKEN_COMMA) {
            parse_adv(p);
            if (parse_peek_kind(p) != TOKEN_IDENTIFIER) {
                parser_set_pos(p, saved);
                return TOKEN_AT;
            }
            parse_adv(p);
            if (parse_peek_kind(p) == TOKEN_LPAREN) {
                var depth2: u64 = 1;
                parse_adv(p);
                while (depth2 > 0) {
                    var ak2: u64 = parse_peek_kind(p);
                    if (ak2 == TOKEN_EOF) {
                        parser_set_pos(p, saved);
                        return TOKEN_AT;
                    }
                    if (ak2 == TOKEN_LPAREN) {
                        depth2 = depth2 + 1;
                    } else if (ak2 == TOKEN_RPAREN) {
                        depth2 = depth2 - 1;
                    }
                    parse_adv(p);
                }
            }
        }
        if (parse_peek_kind(p) != TOKEN_RBRACKET) {
            parser_set_pos(p, saved);
            return TOKEN_AT;
        }
        parse_adv(p);
    }
    var out_kind: u64 = parse_peek_kind(p);
    parser_set_pos(p, saved);
    return out_kind;
}

// Shared lookahead for generic angle-bracket lists.
// - require_follow != 0: require the list to be immediately followed by follow_kind
// - reject_lparen_inside != 0: fail if '(' appears inside the generic list
func parse_scan_generic_list_followed_by(p: *Parser, follow_kind: u64, require_follow: u64, reject_lparen_inside: u64) -> u64 {
    if (parse_peek_kind(p) != TOKEN_LT) { return false; }

    var saved: u64 = parser_pos(p);
    var depth: u64 = 0;
    var bracket_depth: u64 = 0;
    var paren_depth: u64 = 0;

    while (1) {
        var k: u64 = parse_peek_kind(p);
        if (k == TOKEN_EOF) {
            parser_set_pos(p, saved);
            return false;
        }

        if (k == TOKEN_LT) {
            depth = depth + 1;
        } else if (k == TOKEN_GT) {
            if (depth == 0) {
                parser_set_pos(p, saved);
                return false;
            }
            depth = depth - 1;
            if (depth == 0 && bracket_depth == 0 && paren_depth == 0) {
                parse_adv(p);
                var next_k: u64 = parse_peek_kind(p);
                parser_set_pos(p, saved);
                if (require_follow == 0) { return true; }
                if (next_k == follow_kind) { return true; }
                return false;
            }
        } else if (k == TOKEN_RSHIFT) {
            if (depth < 2) {
                parser_set_pos(p, saved);
                return false;
            }
            depth = depth - 2;
            if (depth == 0 && bracket_depth == 0 && paren_depth == 0) {
                parse_adv(p);
                var next_k2: u64 = parse_peek_kind(p);
                parser_set_pos(p, saved);
                if (require_follow == 0) { return true; }
                if (next_k2 == follow_kind) { return true; }
                return false;
            }
        } else if (k == TOKEN_LBRACKET) {
            bracket_depth = bracket_depth + 1;
        } else if (k == TOKEN_RBRACKET) {
            if (bracket_depth == 0) {
                parser_set_pos(p, saved);
                return false;
            }
            bracket_depth = bracket_depth - 1;
        } else if (k == TOKEN_LPAREN) {
            if (reject_lparen_inside != 0) {
                parser_set_pos(p, saved);
                return false;
            }
            paren_depth = paren_depth + 1;
        } else if (k == TOKEN_RPAREN) {
            if (paren_depth == 0) {
                parser_set_pos(p, saved);
                return false;
            }
            paren_depth = paren_depth - 1;
        } else if (k == TOKEN_IDENTIFIER || k == TOKEN_NUMBER || k == TOKEN_COMMA ||
                   k == TOKEN_EQ ||
                   k == TOKEN_COLON || k == TOKEN_CONST || k == TOKEN_BOOL || k == TOKEN_U8 ||
                   k == TOKEN_U16 || k == TOKEN_U32 || k == TOKEN_U64 ||
                   k == TOKEN_I8 || k == TOKEN_I16 || k == TOKEN_I32 || k == TOKEN_I64 || k == TOKEN_F64 || k == TOKEN_CHAR ||
                   k == TOKEN_STAR || k == TOKEN_TAGGED) {
            // allowed token in generic lists
        } else {
            parser_set_pos(p, saved);
            return false;
        }

        parse_adv(p);
    }
}

// ============================================
// Number parsing helper
// ============================================

func parse_num_val(tok: *Token) -> u64 {
    var t: *Token = tok;
    var ptr: u64 = t.ptr;
    var len: u64 = t.len;
    var val: u64 = 0;
    var ptr_u8: *u8 = (*u8)ptr;

    // u64 max = 18446744073709551615
    var max_u64: u64 = 0 - 1;
    var max_div10: u64 = max_u64 / 10;
    var max_mod10: u64 = max_u64 % 10;

    for (var i: u64 = 0; i < len; i++) {
        var c: u64 = ptr_u8[i];
        var digit: u64 = c - 48;

        if (val > max_div10) {
            report_integer_overflow_error(t);
        }
        if (val == max_div10) {
            if (digit > max_mod10) {
                report_integer_overflow_error(t);
            }
        }

        val = val * 10 + digit;
    }
    return val;
}

func parse_generated_funcs_begin(p: *Parser) -> u64 {
    p.generated_funcs = new Vec<u64>(8);
    p.generated_globals = new Vec<u64>(8);
    p.generated_id_counter = 0;
    return 0;
}

func parse_generated_funcs_push(p: *Parser, func_ptr: u64) -> u64 {
    if (func_ptr == 0) { return 0; }
    if (p.generated_funcs == 0) {
        p.generated_funcs = new Vec<u64>(8);
    }
    p.generated_funcs.push(func_ptr);
    return 0;
}

func parse_generated_funcs_take(p: *Parser) -> *Vec<u64> {
    var out: *Vec<u64> = p.generated_funcs;
    p.generated_funcs = 0;
    return out;
}

func parse_generated_globals_push(p: *Parser, global_ptr: u64) -> u64 {
    if (global_ptr == 0) { return 0; }
    if (p.generated_globals == 0) {
        p.generated_globals = new Vec<u64>(8);
    }
    p.generated_globals.push(global_ptr);
    return 0;
}

func parse_generated_globals_take(p: *Parser) -> *Vec<u64> {
    var out: *Vec<u64> = p.generated_globals;
    p.generated_globals = 0;
    return out;
}

func parse_next_generated_id(p: *Parser) -> u64 {
    p.generated_id_counter = p.generated_id_counter + 1;
    return p.generated_id_counter;
}
