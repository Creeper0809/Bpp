// ssa_regalloc.b - SSA register allocation (graph coloring) (v3_17)
//
// This pass builds an interference graph using liveness analysis
// and assigns colors with a simple greedy algorithm.

import std.io;
import std.util;
import std.vec;
import ssa.datastruct;
import ssa.core;

const SSA_REGALLOC_DEBUG = 0;

const SSA_PHYS_RAX = 1;
const SSA_PHYS_RBX = 2;
const SSA_PHYS_RCX = 3;
const SSA_PHYS_RDX = 4;
const SSA_PHYS_R8 = 5;
const SSA_PHYS_R9 = 6;
const SSA_PHYS_R10 = 7;
const SSA_PHYS_R11 = 8;

const SSA_REG_MAX_LIMIT = 1048576;

var g_regalloc_ctx;

func _ssa_all_ones() -> u64 {
    var v: u64 = 0;
    v = v - 1;
    return v;
}


func _ssa_bits_len(nbits: u64) -> u64 {
    var words: u64 = nbits / 64;
    if ((nbits % 64) != 0) { words = words + 1; }
    return words;
}

func _ssa_bitset_new(nbits: u64) -> u64 {
    var words: u64 = _ssa_bits_len(nbits);
    var buf: u64 = heap_alloc(words * sizeof(u64));
    var buf_u64: *u64 = (*u64)buf;
    for (var i: u64 = 0; i < words; i++) {
        buf_u64[i] = 0;
    }
    return buf;
}

func _ssa_bitset_zero(buf: u64, nbits: u64) -> u64 {
    var words: u64 = _ssa_bits_len(nbits);
    var buf_u64: *u64 = (*u64)buf;
    for (var i: u64 = 0; i < words; i++) {
        buf_u64[i] = 0;
    }
    return 0;
}

func _ssa_bitset_set(buf: u64, bit: u64) -> u64 {
    var idx: u64 = bit / 64;
    var off: u64 = bit % 64;
    var mask: u64 = 1;
    mask = mask << off;
    var buf_u64: *u64 = (*u64)buf;
    buf_u64[idx] = buf_u64[idx] | mask;
    return 0;
}

func _ssa_bitset_clear(buf: u64, bit: u64) -> u64 {
    var idx: u64 = bit / 64;
    var off: u64 = bit % 64;
    var mask: u64 = 1;
    mask = mask << off;
    var all: u64 = _ssa_all_ones();
    var buf_u64: *u64 = (*u64)buf;
    buf_u64[idx] = buf_u64[idx] & (all ^ mask);
    return 0;
}

func _ssa_bitset_test(buf: u64, bit: u64) -> u64 {
    var idx: u64 = bit / 64;
    var off: u64 = bit % 64;
    var mask: u64 = 1;
    mask = mask << off;
    var buf_u64: *u64 = (*u64)buf;
    var v: u64 = buf_u64[idx];
    v = v & mask;
    if (v != 0) { return true; }
    return false;
}

func _ssa_bitset_or(dst: u64, src: u64, nbits: u64) -> u64 {
    var words: u64 = _ssa_bits_len(nbits);
    var dst_u64: *u64 = (*u64)dst;
    var src_u64: *u64 = (*u64)src;
    for (var i: u64 = 0; i < words; i++) {
        dst_u64[i] = dst_u64[i] | src_u64[i];
    }
    return 0;
}

func _ssa_bitset_copy(dst: u64, src: u64, nbits: u64) -> u64 {
    var words: u64 = _ssa_bits_len(nbits);
    var dst_u64: *u64 = (*u64)dst;
    var src_u64: *u64 = (*u64)src;
    for (var i: u64 = 0; i < words; i++) {
        dst_u64[i] = src_u64[i];
    }
    return 0;
}

func _ssa_bitset_sub(dst: u64, sub: u64, nbits: u64) -> u64 {
    var words: u64 = _ssa_bits_len(nbits);
    var all: u64 = _ssa_all_ones();
    var dst_u64: *u64 = (*u64)dst;
    var sub_u64: *u64 = (*u64)sub;
    for (var i: u64 = 0; i < words; i++) {
        dst_u64[i] = dst_u64[i] & (all ^ sub_u64[i]);
    }
    return 0;
}

func _ssa_reg_is_reasonable(id: u64) -> u64 {
    if (id == 0) { return false; }
    var mask: u64 = 1;
    mask = mask << 63;
    if ((id & mask) != 0) { return false; }
    if (id > SSA_REG_MAX_LIMIT) { return false; }
    return true;
}

func _ssa_reg_max_update(max_ptr: *u64, reg_id: u64) -> u64 {
    if (_ssa_reg_is_reasonable(reg_id) != 0 && reg_id > *max_ptr) {
        *max_ptr = reg_id;
    }
    return 0;
}

func _ssa_reg_max_update_from_args(max_ptr: *u64, args_vec: *Vec<u64>, nargs: u64) -> u64 {
    var n: u64 = _ssa_call_args_len(args_vec, nargs);
    for (var i: u64 = 0; i < n; i++) {
        _ssa_reg_max_update(max_ptr, args_vec.get(i));
    }
    return 0;
}

func _ssa_reg_max_update_from_call(max_ptr: *u64, info_ptr: u64, op: u64) -> u64 {
    if (op == SSA_OP_CALL) {
        var info: *SSACallInfo = (*SSACallInfo)info_ptr;
        return _ssa_reg_max_update_from_args(max_ptr, info.args_vec, info.nargs);
    }
    if (op == SSA_OP_CALL_PTR) {
        var info_ptrp: *SSACallPtrInfo = (*SSACallPtrInfo)info_ptr;
        _ssa_reg_max_update(max_ptr, info_ptrp.callee_reg);
        return _ssa_reg_max_update_from_args(max_ptr, info_ptrp.args_vec, info_ptrp.nargs);
    }
    if (op == SSA_OP_CALL_SLICE_STORE) {
        var info_s: *SSACallSliceStoreInfo = (*SSACallSliceStoreInfo)info_ptr;
        if (info_s.is_ptr > 1) {
            var info_call: *SSACallInfo = (*SSACallInfo)info_ptr;
            return _ssa_reg_max_update_from_args(max_ptr, info_call.args_vec, info_call.nargs);
        }
        if (info_s.is_ptr != 0) {
            _ssa_reg_max_update(max_ptr, info_s.callee_reg);
        }
        return _ssa_reg_max_update_from_args(max_ptr, info_s.args_vec, info_s.nargs);
    }
    return 0;
}

func _ssa_reg_max(fn: *SSAFunction) -> u64 {
    var max_id: u64 = 0;
    var blocks: []*SSABlock = fn.blocks;
    var n: u64 = ssa_slice_len(blocks);
    for (var i: u64 = 0; i < n; i++) {
        var b: *SSABlock = blocks[i];
        if (b == 0) { continue; }

        var phi: *SSAInstruction = b.phi_head;
        while (phi != 0) {
            _ssa_reg_max_update(&max_id, phi.dest);
            var arg: *SSAPhiArg = (*SSAPhiArg)phi.src1;
            while (arg != 0) {
                _ssa_reg_max_update(&max_id, arg.val);
                arg = arg.next;
            }
            phi = phi.next;
        }

        var cur: *SSAInstruction = b.inst_head;
        while (cur != 0) {
            var op: u64 = ssa_inst_get_op(cur);
            if (op != SSA_OP_BR && op != SSA_OP_JMP && op != SSA_OP_RET_SLICE_HEAP) {
                var mask: u64 = 1;
                mask = mask << 63;
                if ((cur.dest & mask) == 0) {
                    _ssa_reg_max_update(&max_id, cur.dest);
                }
            }
            if (op == SSA_OP_CALL || op == SSA_OP_CALL_PTR || op == SSA_OP_CALL_SLICE_STORE) {
                _ssa_reg_max_update_from_call(&max_id, ssa_operand_value(cur.src1), op);
            }
            if (op == SSA_OP_PHI) {
                cur = cur.next;
                continue;
            }
            if (!ssa_operand_is_const(cur.src1)) {
                _ssa_reg_max_update(&max_id, ssa_operand_value(cur.src1));
            }
            if (!ssa_operand_is_const(cur.src2)) {
                _ssa_reg_max_update(&max_id, ssa_operand_value(cur.src2));
            }
            cur = cur.next;
        }

    }
    return max_id;
}

func _ssa_use_add_if_not_def(use: u64, def: u64, reg: u64, max_reg: u64) -> u64 {
    if (reg <= max_reg && _ssa_bitset_test(def, reg) == 0) {
        _ssa_bitset_set(use, reg);
    }
    return 0;
}

func _ssa_use_add_args_if_not_def(use: u64, def: u64, args_vec: *Vec<u64>, nargs: u64, max_reg: u64) -> u64 {
    var n: u64 = _ssa_call_args_len(args_vec, nargs);
    for (var i: u64 = 0; i < n; i++) {
        _ssa_use_add_if_not_def(use, def, args_vec.get(i), max_reg);
    }
    return 0;
}

func _ssa_use_add_call_operands(use: u64, def: u64, info_ptr: u64, op: u64, max_reg: u64) -> u64 {
    if (op == SSA_OP_CALL) {
        var info: *SSACallInfo = (*SSACallInfo)info_ptr;
        return _ssa_use_add_args_if_not_def(use, def, info.args_vec, info.nargs, max_reg);
    }
    if (op == SSA_OP_CALL_PTR) {
        var info_ptrp: *SSACallPtrInfo = (*SSACallPtrInfo)info_ptr;
        _ssa_use_add_if_not_def(use, def, info_ptrp.callee_reg, max_reg);
        return _ssa_use_add_args_if_not_def(use, def, info_ptrp.args_vec, info_ptrp.nargs, max_reg);
    }
    if (op == SSA_OP_CALL_SLICE_STORE) {
        var info_s: *SSACallSliceStoreInfo = (*SSACallSliceStoreInfo)info_ptr;
        if (info_s.is_ptr > 1) {
            var info_call: *SSACallInfo = (*SSACallInfo)info_ptr;
            return _ssa_use_add_args_if_not_def(use, def, info_call.args_vec, info_call.nargs, max_reg);
        }
        if (info_s.is_ptr != 0) {
            _ssa_use_add_if_not_def(use, def, info_s.callee_reg, max_reg);
        }
        return _ssa_use_add_args_if_not_def(use, def, info_s.args_vec, info_s.nargs, max_reg);
    }
    return 0;
}

func _ssa_build_use_def(fn: *SSAFunction, max_reg: u64, use_arr: u64, def_arr: u64) -> u64 {
    var blocks: []*SSABlock = fn.blocks;
    var n: u64 = ssa_slice_len(blocks);
    var use_arr_u64: *u64 = (*u64)use_arr;
    var def_arr_u64: *u64 = (*u64)def_arr;
    for (var i: u64 = 0; i < n; i++) {
        var b: *SSABlock = blocks[i];

        var use: u64 = _ssa_bitset_new(max_reg + 1);
        var def: u64 = _ssa_bitset_new(max_reg + 1);

        var cur: *SSAInstruction = b.inst_head;
        while (cur != 0) {
            var op: u64 = ssa_inst_get_op(cur);
            if (op == SSA_OP_NOP) {
                cur = cur.next;
                continue;
            }

            if (op == SSA_OP_PHI) {
                if (cur.dest != 0 && cur.dest <= max_reg) {
                    _ssa_bitset_set(def, cur.dest);
                }
                cur = cur.next;
                continue;
            }

            if (op == SSA_OP_CALL || op == SSA_OP_CALL_PTR || op == SSA_OP_CALL_SLICE_STORE) {
                _ssa_use_add_call_operands(use, def, ssa_operand_value(cur.src1), op, max_reg);
            }

            if (!(op == SSA_OP_CALL || op == SSA_OP_CALL_PTR)) {
                if (!ssa_operand_is_const(cur.src1)) {
                    _ssa_use_add_if_not_def(use, def, ssa_operand_value(cur.src1), max_reg);
                }
                if (!ssa_operand_is_const(cur.src2)) {
                    _ssa_use_add_if_not_def(use, def, ssa_operand_value(cur.src2), max_reg);
                }
            }

            if (cur.dest != 0) {
                if (op != SSA_OP_BR && op != SSA_OP_JMP && op != SSA_OP_RET_SLICE_HEAP) {
                    var mask2: u64 = 1;
                    mask2 = mask2 << 63;
                    if ((cur.dest & mask2) == 0 && cur.dest <= max_reg) {
                        _ssa_bitset_set(def, cur.dest);
                    }
                }
            }
            if (op == SSA_OP_CALL || op == SSA_OP_CALL_PTR) {
                if (cur.src2 != 0 && ssa_operand_is_const(cur.src2) == 0) {
                    var extra_def: u64 = ssa_operand_value(cur.src2);
                    if (extra_def <= max_reg) { _ssa_bitset_set(def, extra_def); }
                }
            }

            cur = cur.next;
        }

        use_arr_u64[i] = use;
        def_arr_u64[i] = def;
    }
    return 0;
}

func _ssa_liveness(fn: *SSAFunction, max_reg: u64, live_in: u64, live_out: u64) -> u64 {
    var n: u64 = ssa_slice_len(fn.blocks);
    var live_in_u64: *u64 = (*u64)live_in;
    var live_out_u64: *u64 = (*u64)live_out;
    for (var i: u64 = 0; i < n; i++) {
        live_in_u64[i] = _ssa_bitset_new(max_reg + 1);
        live_out_u64[i] = _ssa_bitset_new(max_reg + 1);
    }

    var use_arr: u64 = heap_alloc(n * sizeof(u64));
    var def_arr: u64 = heap_alloc(n * sizeof(u64));
    _ssa_build_use_def(fn, max_reg, use_arr, def_arr);
    var use_arr_u64: *u64 = (*u64)use_arr;
    var def_arr_u64: *u64 = (*u64)def_arr;
    var blocks: []*SSABlock = fn.blocks;
    var words: u64 = _ssa_bits_len(max_reg + 1);

    var max_block_id: u64 = 0;
    for (var bi0: u64 = 0; bi0 < n; bi0++) {
        var b0: *SSABlock = blocks[bi0];
        if (b0.id > max_block_id) { max_block_id = b0.id; }
    }
    var idx_cap: u64 = max_block_id + 1;
    var undef_idx: u64 = _ssa_all_ones();
    var idx_map: u64 = heap_alloc(idx_cap * sizeof(u64));
    var idx_map_u64: *u64 = (*u64)idx_map;
    for (var fill: u64 = 0; fill < idx_cap; fill++) {
        idx_map_u64[fill] = undef_idx;
    }
    for (var bi1: u64 = 0; bi1 < n; bi1++) {
        var b1: *SSABlock = blocks[bi1];
        idx_map_u64[b1.id] = bi1;
    }

    var tmp_out_arr: u64 = heap_alloc(n * sizeof(u64));
    var tmp_in_arr: u64 = heap_alloc(n * sizeof(u64));
    var tmp_out_arr_u64: *u64 = (*u64)tmp_out_arr;
    var tmp_in_arr_u64: *u64 = (*u64)tmp_in_arr;
    for (var ti: u64 = 0; ti < n; ti++) {
        tmp_out_arr_u64[ti] = _ssa_bitset_new(max_reg + 1);
        tmp_in_arr_u64[ti] = _ssa_bitset_new(max_reg + 1);
    }

    var changed: u64 = 1;
    while (changed != 0) {
        changed = 0;
        for (var bi: u64 = 0; bi < n; bi++) {
            var b: *SSABlock = blocks[bi];

            var out: u64 = tmp_out_arr_u64[bi];
            _ssa_bitset_zero(out, max_reg + 1);
            var succs: []*SSABlock = b.succs;
            var succ_count: u64 = ssa_slice_len(succs);
            for (var si: u64 = 0; si < succ_count; si++) {
                var s: *SSABlock = succs[si];
                if (s.id < idx_cap) {
                    var s_idx: u64 = idx_map_u64[s.id];
                    if (s_idx != undef_idx) {
                        _ssa_bitset_or(out, live_in_u64[s_idx], max_reg + 1);
                    }
                }
            }

            var in: u64 = tmp_in_arr_u64[bi];
            _ssa_bitset_copy(in, out, max_reg + 1);
            _ssa_bitset_sub(in, def_arr_u64[bi], max_reg + 1);
            _ssa_bitset_or(in, use_arr_u64[bi], max_reg + 1);

            var changed_local: u64 = 0;
            var live_in_ptr: u64 = live_in_u64[bi];
            var live_out_ptr: u64 = live_out_u64[bi];
            var live_in_ptr_u64: *u64 = (*u64)live_in_ptr;
            var live_out_ptr_u64: *u64 = (*u64)live_out_ptr;
            var in_u64: *u64 = (*u64)in;
            var out_u64: *u64 = (*u64)out;
            for (var wi: u64 = 0; wi < words; wi++) {
                var old_in: u64 = live_in_ptr_u64[wi];
                var old_out: u64 = live_out_ptr_u64[wi];
                var new_in: u64 = in_u64[wi];
                var new_out: u64 = out_u64[wi];
                if (old_in != new_in || old_out != new_out) { changed_local = 1; }
            }

            if (changed_local != 0) {
                _ssa_bitset_copy(live_in_u64[bi], in, max_reg + 1);
                _ssa_bitset_copy(live_out_u64[bi], out, max_reg + 1);
                changed = 1;
            }

        }
    }

    return 0;
}

func _ssa_call_args_len(args_vec: *Vec<u64>, nargs: u64) -> u64 {
    var n: u64 = nargs;
    if (n == 0 && args_vec != 0) { n = args_vec.len(); }
    return n;
}

func _ssa_interference_mark_args_pairwise(adj_u64: *u64, args_vec: *Vec<u64>, nargs: u64, nregs: u64) -> u64 {
    var n: u64 = _ssa_call_args_len(args_vec, nargs);
    for (var i: u64 = 0; i < n; i++) {
        var r1: u64 = args_vec.get(i);
        if (r1 >= nregs) { continue; }
        for (var j: u64 = i + 1; j < n; j++) {
            var r2: u64 = args_vec.get(j);
            if (r2 < nregs && r2 != r1) {
                _ssa_bitset_set(adj_u64[r1], r2);
                _ssa_bitset_set(adj_u64[r2], r1);
            }
        }
    }
    return 0;
}

func _ssa_live_mark_args(live: u64, args_vec: *Vec<u64>, nargs: u64, nregs: u64) -> u64 {
    var n: u64 = _ssa_call_args_len(args_vec, nargs);
    for (var i: u64 = 0; i < n; i++) {
        var r: u64 = args_vec.get(i);
        if (r < nregs) { _ssa_bitset_set(live, r); }
    }
    return 0;
}

func _ssa_interference_mark_call_operands(adj_u64: *u64, info_ptr: u64, op: u64, nregs: u64) -> u64 {
    if (op == SSA_OP_CALL) {
        var info: *SSACallInfo = (*SSACallInfo)info_ptr;
        return _ssa_interference_mark_args_pairwise(adj_u64, info.args_vec, info.nargs, nregs);
    }
    if (op == SSA_OP_CALL_PTR) {
        var info_ptrp: *SSACallPtrInfo = (*SSACallPtrInfo)info_ptr;
        return _ssa_interference_mark_args_pairwise(adj_u64, info_ptrp.args_vec, info_ptrp.nargs, nregs);
    }
    if (op == SSA_OP_CALL_SLICE_STORE) {
        var info_s: *SSACallSliceStoreInfo = (*SSACallSliceStoreInfo)info_ptr;
        if (info_s.is_ptr > 1) {
            var info_call: *SSACallInfo = (*SSACallInfo)info_ptr;
            return _ssa_interference_mark_args_pairwise(adj_u64, info_call.args_vec, info_call.nargs, nregs);
        }
        return _ssa_interference_mark_args_pairwise(adj_u64, info_s.args_vec, info_s.nargs, nregs);
    }
    return 0;
}

func _ssa_live_mark_call_operands(live: u64, info_ptr: u64, op: u64, nregs: u64) -> u64 {
    if (op == SSA_OP_CALL) {
        var info: *SSACallInfo = (*SSACallInfo)info_ptr;
        return _ssa_live_mark_args(live, info.args_vec, info.nargs, nregs);
    }
    if (op == SSA_OP_CALL_PTR) {
        var info_ptrp: *SSACallPtrInfo = (*SSACallPtrInfo)info_ptr;
        var callee_reg: u64 = info_ptrp.callee_reg;
        if (callee_reg < nregs) { _ssa_bitset_set(live, callee_reg); }
        return _ssa_live_mark_args(live, info_ptrp.args_vec, info_ptrp.nargs, nregs);
    }
    if (op == SSA_OP_CALL_SLICE_STORE) {
        var info_s: *SSACallSliceStoreInfo = (*SSACallSliceStoreInfo)info_ptr;
        if (info_s.is_ptr > 1) {
            var info_call: *SSACallInfo = (*SSACallInfo)info_ptr;
            return _ssa_live_mark_args(live, info_call.args_vec, info_call.nargs, nregs);
        }
        if (info_s.is_ptr != 0) {
            var callee_reg2: u64 = info_s.callee_reg;
            if (callee_reg2 < nregs) { _ssa_bitset_set(live, callee_reg2); }
        }
        return _ssa_live_mark_args(live, info_s.args_vec, info_s.nargs, nregs);
    }
    return 0;
}

func _ssa_interference_build(fn: *SSAFunction, max_reg: u64) -> u64 {
    var nregs: u64 = max_reg + 1;
    var adj: u64 = heap_alloc(nregs * sizeof(u64));
    var adj_u64: *u64 = (*u64)adj;
    for (var r: u64 = 0; r < nregs; r++) {
        adj_u64[r] = _ssa_bitset_new(nregs);
    }

    var blocks: []*SSABlock = fn.blocks;
    var bcount: u64 = ssa_slice_len(blocks);
    var live_in: u64 = heap_alloc(bcount * sizeof(u64));
    var live_out: u64 = heap_alloc(bcount * sizeof(u64));
    _ssa_liveness(fn, max_reg, live_in, live_out);
    var live_in_u64: *u64 = (*u64)live_in;
    var live_out_u64: *u64 = (*u64)live_out;

    for (var bi: u64 = 0; bi < bcount; bi++) {
        var b: *SSABlock = blocks[bi];
        var live: u64 = _ssa_bitset_new(nregs);
        _ssa_bitset_copy(live, live_out_u64[bi], nregs);

            var insts: *Vec<*SSAInstruction> = new Vec<*SSAInstruction>(8);
        var cur: *SSAInstruction = b.inst_head;
        while (cur != 0) {
            insts.push(cur);
            cur = cur.next;
        }

        for (var ilen: u64 = insts.len(); ilen > 0; ilen = ilen - 1) {
            var inst: *SSAInstruction = insts.get(ilen - 1);
            var op: u64 = ssa_inst_get_op(inst);

            if (inst.dest != 0) {
                var d: u64 = inst.dest;
                if (d < nregs && op != SSA_OP_BR && op != SSA_OP_JMP && op != SSA_OP_RET_SLICE_HEAP) {
                    for (var i2: u64 = 1; i2 < nregs; i2++) {
                        if (_ssa_bitset_test(live, i2) != 0 && i2 != d) {
                            _ssa_bitset_set(adj_u64[d], i2);
                            _ssa_bitset_set(adj_u64[i2], d);
                        }
                    }
                    _ssa_bitset_clear(live, d);
                }
            }

            if (op == SSA_OP_CALL || op == SSA_OP_CALL_PTR || op == SSA_OP_CALL_SLICE_STORE) {
                _ssa_interference_mark_call_operands(adj_u64, ssa_operand_value(inst.src1), op, nregs);
            }

            if (op == SSA_OP_RET || op == SSA_OP_RET_SLICE_HEAP) {
                if (ssa_operand_is_const(inst.src1) == 0 && ssa_operand_is_const(inst.src2) == 0) {
                    var r1: u64 = ssa_operand_value(inst.src1);
                    var r2: u64 = ssa_operand_value(inst.src2);
                    if (r1 < nregs && r2 < nregs && r1 != r2) {
                        _ssa_bitset_set(adj_u64[r1], r2);
                        _ssa_bitset_set(adj_u64[r2], r1);
                    }
                }
            }
            // Ensure binary operands do not share the same physical register.
            if (op != SSA_OP_NOP && op != SSA_OP_PHI) {
                if (ssa_operand_is_const(inst.src1) == 0 && ssa_operand_is_const(inst.src2) == 0) {
                    var r1b2: u64 = ssa_operand_value(inst.src1);
                    var r2b2: u64 = ssa_operand_value(inst.src2);
                    if (r1b2 != 0 && r2b2 != 0 && r1b2 < nregs && r2b2 < nregs && r1b2 != r2b2) {
                        _ssa_bitset_set(adj_u64[r1b2], r2b2);
                        _ssa_bitset_set(adj_u64[r2b2], r1b2);
                    }
                }
            }
            if (op != SSA_OP_NOP && op != SSA_OP_PHI) {
                if (op == SSA_OP_CALL || op == SSA_OP_CALL_PTR || op == SSA_OP_CALL_SLICE_STORE) {
                    _ssa_live_mark_call_operands(live, ssa_operand_value(inst.src1), op, nregs);
                }
                if (!ssa_operand_is_const(inst.src1)) {
                    var r1b: u64 = ssa_operand_value(inst.src1);
                    if (r1b < nregs) { _ssa_bitset_set(live, r1b); }
                }
                if (!ssa_operand_is_const(inst.src2)) {
                    var r2b: u64 = ssa_operand_value(inst.src2);
                    if (r2b < nregs) { _ssa_bitset_set(live, r2b); }
                }
            }
        }

    }

    return adj;
}

func ssa_regalloc_color_fn(fn: *SSAFunction, k: u64) -> *Vec<u64> {
    var max_reg: u64 = _ssa_reg_max(fn);
    if (max_reg == 0) { return 0; }

    var adj: u64 = _ssa_interference_build(fn, max_reg);
    var adj_u64: *u64 = (*u64)adj;
        var colors_vec: *Vec<u64> = new Vec<u64>(max_reg + 1);
    for (var i: u64 = 0; i <= max_reg; i++) {
        colors_vec.push(0);
    }
    var used_vec: *Vec<u64> = new Vec<u64>(k + 1);
        for (var j: u64 = 0; j <= k; j++) {
        used_vec.push(0);
    }

    for (var r: u64 = 1; r <= max_reg; r++) {
        for (var j: u64 = 0; j <= k; j++) {
            used_vec.set(j, 0);
        }

        var neigh: u64 = adj_u64[r];
        for (var n: u64 = 1; n <= max_reg; n++) {
            if (_ssa_bitset_test(neigh, n) != 0) {
                var c: u64 = colors_vec.get(n);
                if (c <= k) { used_vec.set(c, 1); }
            }
        }

        var color: u64 = k + 1;
        for (var c: u64 = 1; c <= k; c++) {
            if (used_vec.get(c) == 0) { color = c; break; }
        }

        if (color > k) { color = 0; }
        colors_vec.set(r, color);
    }

    if (SSA_REGALLOC_DEBUG != 0) {
        println("[DEBUG] ssa_regalloc_color_fn: done", 36);
    }

    return colors_vec;
}

func _ssa_regalloc_color_to_phys(color: u64) -> u64 {
    switch (color) {
        case 1: return SSA_PHYS_RAX;
        case 2: return SSA_PHYS_RBX;
        case 3: return SSA_PHYS_RCX;
        case 4: return SSA_PHYS_RDX;
        case 5: return SSA_PHYS_R8;
        case 6: return SSA_PHYS_R9;
        case 7: return SSA_PHYS_R10;
        case 8: return SSA_PHYS_R11;
        default: return 0;
    }
}

func ssa_regalloc_map_fn(fn: *SSAFunction, k: u64) -> u64 {
    var max_reg: u64 = _ssa_reg_max(fn);
    if (max_reg == 0) {
        fn.regalloc_failed = 0;
        fn.regalloc_done = 1;
        return 0;
    }

    var colors: *Vec<u64> = ssa_regalloc_color_fn(fn, k);
    if (colors == 0) {
        fn.regalloc_failed = 1;
        fn.regalloc_done = 0;
        fn.reg_map_data = 0;
        fn.reg_map_len = 0;
        return 0;
    }

    var map: u64 = heap_alloc((max_reg + 1) * sizeof(u64));
    var map_u64: *u64 = (*u64)map;
    for (var i: u64 = 0; i <= max_reg; i++) {
        map_u64[i] = 0;
    }

    var failed: u64 = 0;
    for (var r: u64 = 1; r <= max_reg; r++) {
        var c: u64 = colors.get(r);
        if (c == 0) {
            failed = 1;
            break;
        }
        var phys: u64 = _ssa_regalloc_color_to_phys(c);
        if (phys == 0) {
            failed = 1;
            break;
        }
        map_u64[r] = phys;
    }

    if (failed != 0) {
        fn.regalloc_failed = 1;
        fn.regalloc_done = 0;
        fn.reg_map_data = 0;
        fn.reg_map_len = 0;
        return 0;
    }

    fn.reg_map_data = map;
    fn.reg_map_len = max_reg + 1;
    fn.regalloc_failed = 0;
    fn.regalloc_done = 1;
    return map;
}

func ssa_regalloc_run(ctx: *SSAContext, k: u64) -> u64 {
    push_trace("ssa_regalloc_run", "ssa_regalloc.b", __LINE__);
    defer pop_trace();
    if (ctx == 0) { return 0; }
    g_regalloc_ctx = (u64)ctx;
    var funcs: []*SSAFunction = ctx.funcs;
    var n: u64 = ssa_slice_len(funcs);
    for (var i: u64 = 0; i < n; i++) {
        if (SSA_REGALLOC_DEBUG != 0) {
            println("[DEBUG] ssa_regalloc_run", 26);
        }
        var fn: *SSAFunction = funcs[i];
        ssa_regalloc_map_fn(fn, k);
        if (fn.regalloc_failed == 0 && fn.regalloc_done != 0) {
            ssa_regalloc_apply_fn(fn);
        }
    }
    return 0;
}

func _ssa_regalloc_remap_reg_value(reg: u64, map_u64: *u64, map_len: u64) -> u64 {
    if (reg >= map_len) { return reg; }
    var mapped: u64 = map_u64[reg];
    if (mapped != 0) { return mapped; }
    return reg;
}

func _ssa_regalloc_remap_reg_in_place(reg_ptr: *u64, map_u64: *u64, map_len: u64) -> u64 {
    *reg_ptr = _ssa_regalloc_remap_reg_value(*reg_ptr, map_u64, map_len);
    return 0;
}

func _ssa_regalloc_remap_operand_in_place(opr_ptr: *u64, map_u64: *u64, map_len: u64) -> u64 {
    if (ssa_operand_is_const(*opr_ptr)) { return 0; }
    var reg: u64 = ssa_operand_value(*opr_ptr);
    var mapped: u64 = _ssa_regalloc_remap_reg_value(reg, map_u64, map_len);
    if (mapped != reg) { *opr_ptr = ssa_operand_reg(mapped); }
    return 0;
}

func _ssa_regalloc_remap_args(args_vec: *Vec<u64>, nargs: u64, map_u64: *u64, map_len: u64) -> u64 {
    var n: u64 = _ssa_call_args_len(args_vec, nargs);
    for (var i: u64 = 0; i < n; i++) {
        var reg: u64 = args_vec.get(i);
        var mapped: u64 = _ssa_regalloc_remap_reg_value(reg, map_u64, map_len);
        if (mapped != reg) { args_vec.set(i, mapped); }
    }
    return 0;
}

func _ssa_regalloc_remap_call_operands(op: u64, info_ptr: u64, map_u64: *u64, map_len: u64) -> u64 {
    if (op == SSA_OP_CALL) {
        var info: *SSACallInfo = (*SSACallInfo)info_ptr;
        return _ssa_regalloc_remap_args(info.args_vec, info.nargs, map_u64, map_len);
    }
    if (op == SSA_OP_CALL_PTR) {
        var info_ptrp: *SSACallPtrInfo = (*SSACallPtrInfo)info_ptr;
        _ssa_regalloc_remap_reg_in_place(&info_ptrp.callee_reg, map_u64, map_len);
        return _ssa_regalloc_remap_args(info_ptrp.args_vec, info_ptrp.nargs, map_u64, map_len);
    }
    if (op == SSA_OP_CALL_SLICE_STORE) {
        var info_s: *SSACallSliceStoreInfo = (*SSACallSliceStoreInfo)info_ptr;
        if (info_s.is_ptr > 1) {
            var info_call: *SSACallInfo = (*SSACallInfo)info_ptr;
            return _ssa_regalloc_remap_args(info_call.args_vec, info_call.nargs, map_u64, map_len);
        }
        if (info_s.is_ptr != 0) {
            _ssa_regalloc_remap_reg_in_place(&info_s.callee_reg, map_u64, map_len);
        }
        return _ssa_regalloc_remap_args(info_s.args_vec, info_s.nargs, map_u64, map_len);
    }
    return 0;
}

func ssa_regalloc_apply_fn(fn: *SSAFunction) -> u64 {
    push_trace("ssa_regalloc_apply_fn", "ssa_regalloc.b", __LINE__);
    defer pop_trace();
    if (fn == 0) { return 0; }
    if (fn.reg_map_data == 0) { return 0; }

    var blocks: []*SSABlock = fn.blocks;
    var n: u64 = ssa_slice_len(blocks);
    if (n == 0) { return 0; }

    var map: u64 = fn.reg_map_data;
    var map_len: u64 = fn.reg_map_len;
    var map_u64: *u64 = (*u64)map;
    if (SSA_REGALLOC_DEBUG != 0) {
        println("[DEBUG] ssa_regalloc_apply_fn", 30);
        emit_len("  fn=", 5);
        print_u64((u64)fn);
        emit_len(" blocks_len=", 12);
        print_u64(n);
        emit_len(" map_len=", 9);
        print_u64(map_len);
        print_nl();
    }
    for (var i: u64 = 0; i < n; i++) {
        var b: *SSABlock = blocks[i];
        if (b == 0) { continue; }
        if (SSA_REGALLOC_DEBUG != 0) {
            emit_len("  block idx=", 12);
            print_u64(i);
            emit_len(" ptr=", 5);
            print_u64((u64)b);
            emit_len(" id=", 4);
            print_u64(b.id);
            emit_len(" phi=", 5);
            print_u64((u64)b.phi_head);
            emit_len(" inst=", 6);
            print_u64((u64)b.inst_head);
            print_nl();
        }

        var phi: *SSAInstruction = b.phi_head;
        while (phi != 0) {
            _ssa_regalloc_remap_reg_in_place(&phi.dest, map_u64, map_len);
            var args: *SSAPhiArg = (*SSAPhiArg)phi.src1;
            while (args != 0) {
                _ssa_regalloc_remap_reg_in_place(&args.val, map_u64, map_len);
                args = args.next;
            }
            phi = phi.next;
        }

        var cur: *SSAInstruction = b.inst_head;
        while (cur != 0) {
            var op2: u64 = ssa_inst_get_op(cur);
            if (op2 != SSA_OP_BR && op2 != SSA_OP_JMP && op2 != SSA_OP_RET_SLICE_HEAP) {
                if (cur.dest != 0) {
                    _ssa_regalloc_remap_reg_in_place(&cur.dest, map_u64, map_len);
                }
            }
            if (op2 == SSA_OP_CALL || op2 == SSA_OP_CALL_PTR || op2 == SSA_OP_CALL_SLICE_STORE) {
                _ssa_regalloc_remap_call_operands(op2, ssa_operand_value(cur.src1), map_u64, map_len);
            }
            _ssa_regalloc_remap_operand_in_place(&cur.src1, map_u64, map_len);
            _ssa_regalloc_remap_operand_in_place(&cur.src2, map_u64, map_len);
            if (op2 == SSA_OP_RET_SLICE_HEAP) {
                ssa_ret_slice_heap_remap_ex((u64)cur, map, map_len);
            }
            cur = cur.next;
        }

    }

    return 0;
}

func ssa_regalloc_apply_run(ctx: *SSAContext) -> u64 {
    push_trace("ssa_regalloc_apply_run", "ssa_regalloc.b", __LINE__);
    defer pop_trace();
    if (ctx == 0 && g_regalloc_ctx != 0) {
        ctx = (*SSAContext)g_regalloc_ctx;
    }
    if (ctx == 0) { return 0; }
    if (ssa_slice_len(ctx.funcs) == 0 && g_regalloc_ctx != 0) {
        ctx = (*SSAContext)g_regalloc_ctx;
    }
    var funcs: []*SSAFunction = ctx.funcs;
    var n: u64 = ssa_slice_len(funcs);
    for (var i: u64 = 0; i < n; i++) {
        ssa_regalloc_apply_fn(funcs[i]);
    }
    return 0;
}
