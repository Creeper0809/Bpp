// ssa_builder.b - SSA CFG builder (v3_17)
//
// AST를 순회하며 기본 블록/엣지 연결과 명령어 생성까지 처리합니다.
// (SSA Rename은 다음 단계)

import std.io;
import std.util;
import std.vec;
import std.hashmap;
import std.str;
import types;
import ast;
import ssa.datastruct;
import ssa.core;
import emitter.typeinfo;
import emitter.symtab;
import emitter.emitter;
import compiler;
import ssa.codegen;

const SSA_BUILDER_DEBUG = 0;
const TAGGED_PTR_MASK = 281474976710655;

// Simple pointer+length pair for name lookups and metadata.
struct PtrLen {
    ptr: u64;
    len: u64;
}

// Slice register bundle (ptr,len) used in SSA builder.
struct SliceRegs {
    ptr_reg: u64;
    len_reg: u64;
}

impl SliceRegs {
    constructor() {
        self.ptr_reg = 0;
        self.len_reg = 0;
    }
}

func builder_make_bitmask(bit_width: u64) -> u64 {
    if (bit_width >= 64) { return 0; }
    var one: u64 = 1;
    var mask: u64 = one << bit_width;
    return mask - 1;
}

func builder_mask_low_bits(ctx: *BuilderCtx, value_reg: u64, bit_width: u64) -> u64 {
    if (bit_width >= 64) { return value_reg; }
    var mask_val: u64 = builder_make_bitmask(bit_width);
    var mask_reg: u64 = build_const(ctx, mask_val);
    var out_reg: u64 = builder_new_reg(ctx);
    var and_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_AND, out_reg, ssa_operand_reg(value_reg), ssa_operand_reg(mask_reg));
    ssa_inst_append(ctx.cur_block, and_ptr);
    return out_reg;
}

func builder_shift_left(ctx: *BuilderCtx, value_reg: u64, shift_bits: u64) -> u64 {
    if (shift_bits == 0) { return value_reg; }
    var shift_reg: u64 = build_const(ctx, shift_bits);
    var out_reg: u64 = builder_new_reg(ctx);
    var shl_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_SHL, out_reg, ssa_operand_reg(value_reg), ssa_operand_reg(shift_reg));
    ssa_inst_append(ctx.cur_block, shl_ptr);
    return out_reg;
}

func builder_shift_right(ctx: *BuilderCtx, value_reg: u64, shift_bits: u64) -> u64 {
    if (shift_bits == 0) { return value_reg; }
    var shift_reg: u64 = build_const(ctx, shift_bits);
    var out_reg: u64 = builder_new_reg(ctx);
    var shr_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_SHR, out_reg, ssa_operand_reg(value_reg), ssa_operand_reg(shift_reg));
    ssa_inst_append(ctx.cur_block, shr_ptr);
    return out_reg;
}

func builder_resolve_struct_literal_size(ctx: *BuilderCtx, lit: *AstStructLiteral, fallback_name_ptr: u64, fallback_name_len: u64) -> u64 {
    if (lit == 0) { return 0; }
    var size: u64 = builder_struct_size_from_def(lit.struct_def);
    if (size != 0) { return size; }
    if (fallback_name_ptr != 0 && fallback_name_len != 0) {
        size = sizeof_type(TYPE_STRUCT, 0, fallback_name_ptr, fallback_name_len);
        if (size != 0) { return size; }
        var fb_def: *AstStructDef = get_struct_def(fallback_name_ptr, fallback_name_len);
        if (fb_def != 0) {
            size = builder_struct_size_from_def(fb_def);
            if (size != 0) { return size; }
        }
    }
    var ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)lit, ctx.symtab);
    if (ti == 0) { return 0; }
    if (ti.type_kind != TYPE_STRUCT || ti.ptr_depth != 0) { return 0; }
    if (ti.struct_def != 0) {
        size = builder_struct_size_from_def(ti.struct_def);
        if (size != 0) { return size; }
    }
    if (ti.struct_name_ptr != 0 && ti.struct_name_len != 0) {
        size = sizeof_type(TYPE_STRUCT, 0, ti.struct_name_ptr, ti.struct_name_len);
        if (size != 0) { return size; }
        var name_def: *AstStructDef = get_struct_def(ti.struct_name_ptr, ti.struct_name_len);
        if (name_def != 0) {
            size = builder_struct_size_from_def(name_def);
            if (size != 0) { return size; }
        }
    }
    return 0;
}

func builder_extract_field_from_small_struct_regs(ctx: *BuilderCtx, lo_reg: u64, hi_reg: u64, struct_size: u64, field_offset: u64, field_size: u64) -> u64 {
    if (struct_size == 0 || field_size == 0) { return 0; }
    var temp_offset: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, struct_size);
    var temp_addr: u64 = builder_new_lea_local(ctx, temp_offset);
    builder_store_by_size(ctx, temp_addr, lo_reg, 8);
    if (struct_size > 8) {
        var off8: u64 = build_const(ctx, 8);
        var addr2: u64 = builder_new_reg(ctx);
        var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(temp_addr), ssa_operand_reg(off8));
        ssa_inst_append(ctx.cur_block, add_ptr);
        var tail_size: u64 = struct_size - 8;
        if (tail_size > 8) { tail_size = 8; }
        builder_store_by_size(ctx, addr2, hi_reg, tail_size);
    }
    var field_addr: u64 = temp_addr;
    if (field_offset != 0) {
        var off_reg: u64 = build_const(ctx, field_offset);
        var addr3: u64 = builder_new_reg(ctx);
        var add_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr3, ssa_operand_reg(temp_addr), ssa_operand_reg(off_reg));
        ssa_inst_append(ctx.cur_block, add_ptr2);
        field_addr = addr3;
    }
    if (ctx.debug_mode != 0) {
        emit("[DEBUG] ssa member access span field via temp, size=");
        print_u64(struct_size);
        emit(" offset=");
        print_u64(field_offset);
        emit(" field=");
        print_u64(field_size);
        emit("\n");
    }
    return builder_load_by_size(ctx, field_addr, field_size);
}

func builder_emit_call_name_raw(ctx: *BuilderCtx, name_ptr: u64, name_len: u64, arg_regs: *Vec<u64>, dst: u64, extra_dst: u64, ret_type: u64, ret_ptr_depth: u64, ret_struct_size: u64) -> u64 {
    if (arg_regs == 0) { return 0; }
    var total_regs: u64 = arg_regs.len();
    var info: *SSACallInfo = new SSACallInfo();
    info.name_ptr = name_ptr;
    info.name_len = name_len;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;
    info.ret_struct_size = ret_struct_size;
    var extra_opr: u64 = 0;
    if (extra_dst != 0) { extra_opr = ssa_operand_reg(extra_dst); }
    var call_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL, dst, ssa_operand_const((u64)info), extra_opr);
    ssa_inst_append(ctx.cur_block, call_ptr);
    return dst;
}

func builder_emit_call_ptr_raw(ctx: *BuilderCtx, callee_reg: u64, arg_regs: *Vec<u64>, dst: u64, extra_dst: u64, ret_type: u64, ret_ptr_depth: u64, ret_struct_size: u64) -> u64 {
    if (arg_regs == 0) { return 0; }
    var total_regs: u64 = arg_regs.len();
    var info: *SSACallPtrInfo = new SSACallPtrInfo();
    info.callee_reg = callee_reg;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;
    info.ret_struct_size = ret_struct_size;
    var extra_opr: u64 = 0;
    if (extra_dst != 0) { extra_opr = ssa_operand_reg(extra_dst); }
    var call_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL_PTR, dst, ssa_operand_const((u64)info), extra_opr);
    ssa_inst_append(ctx.cur_block, call_ptr);
    return dst;
}

func builder_emit_trait_vptr_init_at_addr(ctx: *BuilderCtx, base_addr: u64, struct_name_ptr: u64, struct_name_len: u64) -> u64 {
    if (base_addr == 0) { return 0; }
    var impls: *Vec<*TraitImpl> = compiler_get_trait_impls();
    if (impls == 0) { return 0; }
    var struct_def: *AstStructDef = get_struct_def(struct_name_ptr, struct_name_len);
    if (struct_def == 0) { return 0; }
    var n: u64 = impls.len();
    for (var i: u64 = 0; i < n; i++) {
        var impl_info: *TraitImpl = impls.get(i);
        if (!str_eq(impl_info.struct_ptr, impl_info.struct_len, struct_name_ptr, struct_name_len)) { continue; }
        var vptr_name: *NameInfo = compiler_build_vptr_field_name(impl_info.trait_ptr, impl_info.trait_len);
        var field_offset: u64 = 0;
        var field_desc: *FieldDesc = 0;
        var found: u64 = struct_find_field_desc_scoped(struct_def, 0, 0, vptr_name.ptr, vptr_name.len, &field_offset, &field_desc);
        if (found == 0) {
            emit_stderr("[ERROR] vptr field not found for trait init\n");
            panic("SSA build error");
        }
        var vtable_reg: u64 = builder_new_lea_global(ctx, impl_info.vtable_global_ptr, impl_info.vtable_global_len);
        var addr_reg: u64 = base_addr;
        if (field_offset != 0) {
            var off_reg: u64 = build_const(ctx, field_offset);
            var addr2: u64 = builder_new_reg(ctx);
            var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(base_addr), ssa_operand_reg(off_reg));
            ssa_inst_append(ctx.cur_block, add_ptr);
            addr_reg = addr2;
        }
        builder_store_by_size(ctx, addr_reg, vtable_reg, 8);
    }
    return 0;
}

func builder_emit_return_struct_from_addr_reg(ctx: *BuilderCtx, addr_reg: u64, struct_size: u64) -> u64 {
    if (addr_reg == 0 || struct_size == 0) { return 0; }
    var head_size: u64 = struct_size;
    if (head_size > 8) { head_size = 8; }
    var lo_reg: u64 = builder_load_by_size(ctx, addr_reg, head_size);
    if (lo_reg == 0) { lo_reg = build_const(ctx, 0); }
    var hi_reg: u64 = 0;
    if (struct_size > 8) {
        var off_reg: u64 = build_const(ctx, 8);
        var addr2: u64 = builder_new_reg(ctx);
        var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(addr_reg), ssa_operand_reg(off_reg));
        ssa_inst_append(ctx.cur_block, add_ptr);
        var tail_size: u64 = struct_size - 8;
        if (tail_size > 8) { tail_size = 8; }
        hi_reg = builder_load_by_size(ctx, addr2, tail_size);
        if (hi_reg == 0) { hi_reg = build_const(ctx, 0); }
    }
    var ret_src2: u64 = 0;
    if (struct_size > 8) {
        if (hi_reg != 0) { ret_src2 = ssa_operand_reg(hi_reg); }
        else { ret_src2 = ssa_operand_reg(build_const(ctx, 0)); }
    }
    var ret_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, ssa_operand_reg(lo_reg), ret_src2);
    ssa_inst_append(ctx.cur_block, ret_ptr);
    return 0;
}

func builder_resolve_constructor_name(struct_ptr: u64, struct_len: u64) -> *PtrLen {
    var method_ptr: u64 = (u64)"constructor";
    var method_len: u64 = 11;
    var base_len: u64 = compiler_find_generic_suffix_index(struct_ptr, struct_len);
    var suffix_len: u64 = struct_len - base_len;
    var name_info: *NameInfo = compiler_build_method_name_base(struct_ptr, base_len, method_ptr, method_len, suffix_len);
    if (compiler_func_exists(name_info.ptr, name_info.len) == 0) {
        var alt_info: *NameInfo = compiler_build_method_name_base(struct_ptr, base_len, method_ptr, method_len, 0);
        if (compiler_func_exists(alt_info.ptr, alt_info.len) == 0) {
            emit_stderr("[ERROR] constructor not found for stack/new\n");
            emit_stderr_len(struct_ptr, struct_len);
            emit_stderr("\n");
            return 0;
        }
        name_info = alt_info;
    }
    var resolved_ptr: u64 = name_info.ptr;
    var resolved_len: u64 = name_info.len;
    var resolved: *NameInfo = resolve_name(name_info.ptr, name_info.len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }
    return new PtrLen{resolved_ptr, resolved_len};
}

func builder_stack_ctor_init_at_addr(ctx: *BuilderCtx, sc: *AstStackCtor, base_addr: u64) -> u64 {
    if (sc == 0 || base_addr == 0) { return 0; }
    if (sc.type_kind != TYPE_STRUCT) {
        emit_stderr("[ERROR] stack constructor requires struct type\n");
        panic("SSA build error");
    }
    var size: u64 = sizeof_type(sc.type_kind, sc.ptr_depth, sc.struct_name_ptr, sc.struct_name_len);

    var memset_ptr: u64 = (u64)"memset";
    var memset_len: u64 = 6;
    var memset_res: *NameInfo = resolve_name(memset_ptr, memset_len);
    if (memset_res != 0) {
        memset_ptr = memset_res.ptr;
        memset_len = memset_res.len;
    }

    var memset_args: *Vec<u64> = new Vec<u64>(3);
    var zero_reg: u64 = build_const(ctx, 0);
    var size_reg: u64 = build_const(ctx, size);
    memset_args.push(base_addr);
    memset_args.push(zero_reg);
    memset_args.push(size_reg);
    builder_emit_call_name_raw(ctx, memset_ptr, memset_len, memset_args, 0, 0, TYPE_I64, 0, 0);

    builder_emit_trait_vptr_init_at_addr(ctx, base_addr, sc.struct_name_ptr, sc.struct_name_len);

    var args: *Vec<*AstNode> = sc.ctor_args_vec;
    if (args != 0) {
        var name_info: *PtrLen = builder_resolve_constructor_name(sc.struct_name_ptr, sc.struct_name_len);
        if (name_info == 0) { return 0; }
        var nargs: u64 = 0;
        if (args != 0) { nargs = args.len(); }
        var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2 + 1);
        arg_regs.push(base_addr);
        for (var i: u64 = 0; i < nargs; i++) {
            var arg: u64 = args.get(i);
            builder_append_call_arg(ctx, arg_regs, arg);
        }
        builder_emit_call_name_raw(ctx, name_info.ptr, name_info.len, arg_regs, 0, 0, TYPE_VOID, 0, 0);
    }
    return 0;
}

func builder_mask_tagged_ptr(ctx: *BuilderCtx, value_reg: u64) -> u64 {
    var mask_reg: u64 = build_const(ctx, TAGGED_PTR_MASK);
    var out_reg: u64 = builder_new_reg(ctx);
    var and_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_AND, out_reg, ssa_operand_reg(value_reg), ssa_operand_reg(mask_reg));
    ssa_inst_append(ctx.cur_block, and_ptr);
    return out_reg;
}

func builder_all_ones_reg(ctx: *BuilderCtx) -> u64 {
    var zero_reg: u64 = build_const(ctx, 0);
    var one_reg: u64 = build_const(ctx, 1);
    var out_reg: u64 = builder_new_reg(ctx);
    var sub_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_SUB, out_reg, ssa_operand_reg(zero_reg), ssa_operand_reg(one_reg));
    ssa_inst_append(ctx.cur_block, sub_ptr);
    return out_reg;
}

func builder_get_packed_layout_total_bits(struct_def: *AstStructDef) -> u64 {
    var sd: *AstStructDef = struct_def;
    var fields: *Vec<*FieldDesc> = sd.fields_vec;
    var num_fields: u64 = fields.len();
    var total_bits: u64 = 0;
    for (var i: u64 = 0; i < num_fields; i++) {
        var field: *FieldDesc = fields.get(i);
        if (field.bit_width > 0) {
            total_bits = total_bits + field.bit_width;
        } else {
            var fsize: u64 = sizeof_field_desc(field);
            total_bits = total_bits + fsize * 8;
        }
    }
    return total_bits;
}

func builder_get_packed_field_bit_offset(struct_def: *AstStructDef, field_name_ptr: u64, field_name_len: u64) -> u64 {
    var sd: *AstStructDef = struct_def;
    var fields: *Vec<*FieldDesc> = sd.fields_vec;
    var num_fields: u64 = fields.len();
    var bit_cursor: u64 = 0;
    for (var i: u64 = 0; i < num_fields; i++) {
        var field: *FieldDesc = fields.get(i);
        if (str_eq(field.name_ptr, field.name_len, field_name_ptr, field_name_len)) {
            return bit_cursor;
        }
        if (field.bit_width > 0) {
            bit_cursor = bit_cursor + field.bit_width;
        } else {
            var fsize2: u64 = sizeof_field_desc(field);
            bit_cursor = bit_cursor + fsize2 * 8;
        }
    }
    emit("[ERROR] Packed field not found\n");
    panic("SSA build error");
    return 0;
}

func builder_get_packed_field_bit_width(struct_def: *AstStructDef, field_name_ptr: u64, field_name_len: u64) -> u64 {
    var sd: *AstStructDef = struct_def;
    var fields: *Vec<*FieldDesc> = sd.fields_vec;
    var num_fields: u64 = fields.len();
    for (var i: u64 = 0; i < num_fields; i++) {
        var field: *FieldDesc = fields.get(i);
        if (str_eq(field.name_ptr, field.name_len, field_name_ptr, field_name_len)) {
            if (field.bit_width > 0) { return field.bit_width; }
            return sizeof_field_desc(field) * 8;
        }
    }
    emit("[ERROR] Packed field not found\n");
    panic("SSA build error");
    return 0;
}

func builder_struct_size_from_def(struct_def: *AstStructDef) -> u64 {
    if (struct_def == 0) { return 0; }
    var sd: *AstStructDef = struct_def;
    if (sd.is_packed == 1) {
        if (sd.parents_vec != 0 && sd.parents_vec.len() > 0) {
            emit("[ERROR] packed struct cannot use inheritance\n");
            panic("SSA build error");
        }
        var total_bits: u64 = builder_get_packed_layout_total_bits(struct_def);
        return (total_bits + 7) / 8;
    }
    var total_size: u64 = 0;
    if (sd.parents_vec != 0) {
        var parents: *Vec<*ParentDesc> = sd.parents_vec;
        var pn: u64 = parents.len();
        for (var pi: u64 = 0; pi < pn; pi++) {
            var parent_desc: *ParentDesc = parents.get(pi);
            var parent_def: *AstStructDef = parent_desc.struct_def;
            if (parent_def == 0) {
                parent_def = get_struct_def(parent_desc.name_ptr, parent_desc.name_len);
                if (parent_def == 0) {
                    emit("[ERROR] Parent struct not found\n");
                    panic("SSA build error");
                }
                parent_desc.struct_def = parent_def;
            }
            total_size = total_size + builder_struct_size_from_def(parent_def);
        }
    }
    var fields: *Vec<*FieldDesc> = sd.fields_vec;
    var num_fields: u64 = fields.?len();
    for (var i: u64 = 0; i < num_fields; i++) {
        var field: *FieldDesc = fields.get(i);
        total_size = total_size + sizeof_field_desc(field);
    }
    return total_size;
}

// ============================================
// Builder Context
// ============================================

struct BuilderCtx {
    ssa_ctx: *SSAContext;
    cur_func: *SSAFunction;
    cur_block: *SSABlock;
    break_stack: *Vec<*SSABlock>;    // vec of *SSABlock
    continue_stack: *Vec<*SSABlock>; // vec of *SSABlock
    var_map: *HashMap<u64, u64>;         // hashmap: name -> var_id
    const_map: *HashMap<u64, u64>;       // hashmap: name -> const value
    func_ptr_map: *HashMap<u64, *PtrLen>;    // hashmap: name -> [func_name_ptr, func_name_len]
    addr_taken_map: *HashMap<u64, u64>;  // hashmap: name -> 1
    symtab: *Symtab;           // symtab for type/offset lookup
    next_reg: u64;
    next_var_id: u64;
    sret_addr_reg: u64;
    debug_mode: u64;
    build_failed: u64;
}

impl BuilderCtx {
    constructor() {
        self.ssa_ctx = 0;
        self.cur_func = 0;
        self.cur_block = 0;
        self.break_stack = 0;
        self.continue_stack = 0;
        self.var_map = 0;
        self.const_map = 0;
        self.func_ptr_map = 0;
        self.addr_taken_map = 0;
        self.symtab = 0;
        self.next_reg = 0;
        self.next_var_id = 0;
        self.sret_addr_reg = 0;
        self.debug_mode = 0;
        self.build_failed = 0;
    }
}

func builder_ctx_new(ssa_ctx: *SSAContext) -> *BuilderCtx {
    push_trace("builder_ctx_new", "ssa_builder.b", __LINE__);
    defer pop_trace();
    var ctx: *BuilderCtx = new BuilderCtx();
    ctx.ssa_ctx = ssa_ctx;
    ctx.break_stack = new Vec<*SSABlock>(8);
    ctx.continue_stack = new Vec<*SSABlock>(8);
    ctx.next_reg = 1;
    ctx.next_var_id = 1;
    ctx.debug_mode = SSA_BUILDER_DEBUG;
    return ctx;
}

func builder_set_block(ctx: *BuilderCtx, block: *SSABlock) -> u64 {
    ctx.cur_block = block;
    return 0;
}

func builder_push_loop(ctx: *BuilderCtx, break_bb: *SSABlock, continue_bb: *SSABlock) -> u64 {
    ctx.break_stack.push(break_bb);
    ctx.continue_stack.push(continue_bb);
    return 0;
}

func builder_pop_loop(ctx: *BuilderCtx) -> u64 {
    var blen: u64 = ctx.break_stack.len();
    var clen: u64 = ctx.continue_stack.len();
    if (blen > 0) { ctx.break_stack.pop(); }
    if (clen > 0) { ctx.continue_stack.pop(); }
    return 0;
}

func builder_top_break(ctx: *BuilderCtx) -> *SSABlock {
    var blen: u64 = ctx.break_stack.len();
    if (blen == 0) { return 0; }
    return ctx.break_stack.get(blen - 1);
}

func builder_top_continue(ctx: *BuilderCtx) -> *SSABlock {
    var clen: u64 = ctx.continue_stack.len();
    if (clen == 0) { return 0; }
    return ctx.continue_stack.get(clen - 1);
}

func builder_reset_func(ctx: *BuilderCtx) -> u64 {
    push_trace("builder_reset_func", "ssa_builder.b", __LINE__);
    defer pop_trace();
    ctx.var_map = new HashMap<u64, u64>(16);
    ctx.const_map = 0;
    ctx.func_ptr_map = 0;
    ctx.addr_taken_map = new HashMap<u64, u64>(16);
    ctx.symtab = symtab_new();
    ctx.next_reg = 1;
    ctx.next_var_id = 1;
    var break_len: u64 = ctx.break_stack.len();
    for (var bi: u64 = 0; bi < break_len; bi++) {
        ctx.break_stack.pop();
    }
    var continue_len: u64 = ctx.continue_stack.len();
    for (var ci: u64 = 0; ci < continue_len; ci++) {
        ctx.continue_stack.pop();
    }
    compiler_reg_alias_reset();
    ctx.build_failed = 0;
    return 0;
}

func builder_mark_addr_taken(ctx: *BuilderCtx, name_ptr: u64, name_len: u64) -> u64 {
    if (ctx.addr_taken_map == 0) { ctx.addr_taken_map = new HashMap<u64, u64>(16); }
    ctx.addr_taken_map.put(name_ptr, name_len, 1);
    return 0;
}

func builder_is_addr_taken(ctx: *BuilderCtx, name_ptr: u64, name_len: u64) -> u64 {
    if (ctx.addr_taken_map == 0) { return 0; }
    return ctx.addr_taken_map.get(name_ptr, name_len);
}

func builder_scan_addr_taken_expr(ctx: *BuilderCtx, expr: u64) -> u64 {
    if (expr == 0) { return 0; }
    var kind: u64 = ast_kind(expr);
    switch (kind) {
        case AST_ADDR_OF:
            var ao: *AstAddrOf = (*AstAddrOf)expr;
            if (ao.operand != 0 && ast_kind(ao.operand) == AST_IDENT) {
                var idn: *AstIdent = (*AstIdent)ao.operand;
                builder_mark_addr_taken(ctx, idn.name_ptr, idn.name_len);
            } else if (ao.operand != 0) {
                builder_scan_addr_taken_expr(ctx, ao.operand);
            }
            return 0;
        case AST_BINARY:
            var bin: *AstBinary = (*AstBinary)expr;
            builder_scan_addr_taken_expr(ctx, bin.left);
            builder_scan_addr_taken_expr(ctx, bin.right);
            return 0;
        case AST_UNARY:
            var un: *AstUnary = (*AstUnary)expr;
            builder_scan_addr_taken_expr(ctx, un.operand);
            return 0;
        case AST_CAST:
            var cs: *AstCast = (*AstCast)expr;
            builder_scan_addr_taken_expr(ctx, cs.expr);
            return 0;
        case AST_INDEX:
            var ix: *AstIndex = (*AstIndex)expr;
            builder_scan_addr_taken_expr(ctx, ix.base);
            builder_scan_addr_taken_expr(ctx, ix.index);
            return 0;
        case AST_MEMBER_ACCESS:
            var ma: *AstMemberAccess = (*AstMemberAccess)expr;
            builder_scan_addr_taken_expr(ctx, ma.object);
            return 0;
        case AST_CALL:
            var call: *AstCall = (*AstCall)expr;
            var args: *Vec<*AstNode> = call.args_vec;
            if (args != 0) {
                var n: u64 = args.len();
                for (var i: u64 = 0; i < n; i++) {
                    builder_scan_addr_taken_expr(ctx, args.get(i));
                }
            }
            return 0;
        case AST_METHOD_CALL:
            var mc: *AstMethodCall = (*AstMethodCall)expr;
            builder_scan_addr_taken_expr(ctx, mc.receiver);
            var args2: *Vec<*AstNode> = mc.args_vec;
            if (args2 != 0) {
                var n2: u64 = args2.len();
                for (var i2: u64 = 0; i2 < n2; i2++) {
                    builder_scan_addr_taken_expr(ctx, args2.get(i2));
                }
            }
            return 0;
        case AST_CALL_PTR:
            var cp: *AstCallPtr = (*AstCallPtr)expr;
            builder_scan_addr_taken_expr(ctx, cp.callee);
            var args3: *Vec<*AstNode> = cp.args_vec;
            if (args3 != 0) {
                var n3: u64 = args3.len();
                for (var i3: u64 = 0; i3 < n3; i3++) {
                    builder_scan_addr_taken_expr(ctx, args3.get(i3));
                }
            }
            return 0;
        case AST_SLICE:
            var sl: *AstSlice = (*AstSlice)expr;
            builder_scan_addr_taken_expr(ctx, sl.ptr_expr);
            builder_scan_addr_taken_expr(ctx, sl.len_expr);
            return 0;
        case AST_SIZEOF_EXPR:
            var se: *AstSizeofExpr = (*AstSizeofExpr)expr;
            builder_scan_addr_taken_expr(ctx, se.expr);
            return 0;
        case AST_STRUCT_LITERAL:
            var st: *AstStructLiteral = (*AstStructLiteral)expr;
            var vals: *Vec<*AstNode> = st.values_vec;
            if (vals != 0) {
                var vn: u64 = vals.len();
                for (var vi: u64 = 0; vi < vn; vi++) {
                    builder_scan_addr_taken_expr(ctx, vals.get(vi));
                }
            }
            return 0;
        default:
            return 0;
    }
}

func builder_scan_addr_taken_stmt(ctx: *BuilderCtx, stmt: u64) -> u64 {
    if (stmt == 0) { return 0; }
    var kind: u64 = ast_kind(stmt);
    switch (kind) {
        case AST_VAR_DECL:
            var vd: *AstVarDecl = (*AstVarDecl)stmt;
            builder_scan_addr_taken_expr(ctx, vd.init_expr);
            return 0;
        case AST_ASSIGN:
            var asn: *AstAssign = (*AstAssign)stmt;
            builder_scan_addr_taken_expr(ctx, asn.target);
            builder_scan_addr_taken_expr(ctx, asn.value);
            return 0;
        case AST_EXPR_STMT:
            var es: *AstExprStmt = (*AstExprStmt)stmt;
            builder_scan_addr_taken_expr(ctx, es.expr);
            return 0;
        case AST_RETURN:
            var ret: *AstReturn = (*AstReturn)stmt;
            builder_scan_addr_taken_expr(ctx, ret.expr);
            return 0;
        case AST_IF:
            var ifs: *AstIf = (*AstIf)stmt;
            builder_scan_addr_taken_expr(ctx, ifs.cond);
            builder_scan_addr_taken_stmt(ctx, ifs.then_block);
            builder_scan_addr_taken_stmt(ctx, ifs.else_block);
            return 0;
        case AST_WHILE:
            var wl: *AstWhile = (*AstWhile)stmt;
            builder_scan_addr_taken_expr(ctx, wl.cond);
            builder_scan_addr_taken_stmt(ctx, wl.body);
            return 0;
        case AST_FOR:
            var fr: *AstFor = (*AstFor)stmt;
            builder_scan_addr_taken_stmt(ctx, fr.init);
            builder_scan_addr_taken_expr(ctx, fr.cond);
            builder_scan_addr_taken_expr(ctx, fr.update);
            builder_scan_addr_taken_stmt(ctx, fr.body);
            return 0;
        case AST_SWITCH:
            var sw: *AstSwitch = (*AstSwitch)stmt;
            builder_scan_addr_taken_expr(ctx, sw.expr);
            var cases: *Vec<*AstCase> = sw.cases_vec;
            if (cases != 0) {
                var cn: u64 = cases.len();
                for (var ci: u64 = 0; ci < cn; ci++) {
                    builder_scan_addr_taken_stmt(ctx, cases.get(ci));
                }
            }
            return 0;
        case AST_CASE:
            var cs: *AstCase = (*AstCase)stmt;
            builder_scan_addr_taken_stmt(ctx, cs.body);
            return 0;
        case AST_BLOCK:
            var blk: *AstBlock = (*AstBlock)stmt;
            var stmts: *Vec<*AstNode> = blk.stmts_vec;
            if (stmts != 0) {
                var n: u64 = stmts.len();
                for (var i: u64 = 0; i < n; i++) {
                    builder_scan_addr_taken_stmt(ctx, stmts.get(i));
                }
            }
            return 0;
        default:
            return 0;
    }
}

// ============================================
// Symtab Helpers
// ============================================

func builder_typeinfo_new(type_kind: u64, ptr_depth: u64) -> *TypeInfo {
    var ti: *TypeInfo = (*TypeInfo)heap_alloc(sizeof(TypeInfo));
    ti.type_kind = type_kind;
    ti.ptr_depth = ptr_depth;
    ti.is_tagged = 0;
    ti.struct_name_ptr = 0;
    ti.struct_name_len = 0;
    ti.tag_layout_ptr = 0;
    ti.tag_layout_len = 0;
    ti.struct_def = 0;
    ti.elem_type_kind = 0;
    ti.elem_ptr_depth = 0;
    ti.array_len = 0;
    ti.array_len_is_param = 0;
    ti.array_len_param_ptr = 0;
    ti.array_len_param_len = 0;
    return ti;
}

func builder_symtab_add_param(ctx: *BuilderCtx, p: *Param, offset: u64) -> u64 {
    var symtab: *Symtab = ctx.symtab;
    var names: *Vec<*NameInfo> = symtab.names_vec;
    var offsets: *Vec<u64> = symtab.offsets_vec;
    var types: *Vec<*TypeInfo> = symtab.types_vec;

    var name_info: *NameInfo = new NameInfo{p.name_ptr, p.name_len};
    names.push(name_info);
    offsets.push(offset);

    var ti: *TypeInfo = builder_typeinfo_new(p.type_kind, p.ptr_depth);
    ti.is_tagged = p.is_tagged;
    ti.struct_name_ptr = p.struct_name_ptr;
    ti.struct_name_len = p.struct_name_len;
    ti.tag_layout_ptr = p.tag_layout_ptr;
    ti.tag_layout_len = p.tag_layout_len;
    ti.struct_def = 0;
    ti.elem_type_kind = p.elem_type_kind;
    ti.elem_ptr_depth = p.elem_ptr_depth;
    ti.array_len = p.array_len;

    var g_structs_vec: *Vec<*AstStructDef> = typeinfo_get_structs();
    if (p.type_kind == TYPE_STRUCT && g_structs_vec != 0 && p.struct_name_ptr != 0) {
        var num_structs: u64 = g_structs_vec.len();
        for (var si: u64 = 0; si < num_structs; si++) {
            var sd: *AstStructDef = g_structs_vec.get(si);
            if (sd.name_len == p.struct_name_len && str_eq(sd.name_ptr, sd.name_len, p.struct_name_ptr, p.struct_name_len) != 0) {
                ti.struct_def = sd;
                break;
            }
        }
    }
    if (p.elem_type_kind == TYPE_STRUCT && g_structs_vec != 0 && p.struct_name_ptr != 0) {
        var num_structs2: u64 = g_structs_vec.len();
        for (var sj: u64 = 0; sj < num_structs2; sj++) {
            var sd2: *AstStructDef = g_structs_vec.get(sj);
            if (sd2.name_len == p.struct_name_len && str_eq(sd2.name_ptr, sd2.name_len, p.struct_name_ptr, p.struct_name_len) != 0) {
                ti.struct_def = sd2;
                break;
            }
        }
    }

    types.push(ti);
    if (p.name_ptr != 0 && p.name_len != 0) {
        symtab.name_to_offset_map.?put(p.name_ptr, p.name_len, offset);
        symtab.name_to_type_map.?put(p.name_ptr, p.name_len, ti);
    }
    symtab.count = symtab.count + 1;
    return 0;
}

func builder_symtab_add_local(ctx: *BuilderCtx, decl: *AstVarDecl) -> u64 {
    var name_ptr: u64 = decl.name_ptr;
    var name_len: u64 = decl.name_len;
    var type_kind: u64 = decl.type_kind;
    var ptr_depth: u64 = decl.ptr_depth;
    var struct_name_ptr: u64 = decl.struct_name_ptr;
    var struct_name_len: u64 = decl.struct_name_len;
    var elem_type_kind: u64 = decl.elem_type_kind;
    var elem_ptr_depth: u64 = decl.elem_ptr_depth;
    var array_len: u64 = decl.array_len;

    var size: u64 = 0;
    if (type_kind == TYPE_ARRAY) {
        var elem_size: u64 = sizeof_type(elem_type_kind, elem_ptr_depth, struct_name_ptr, struct_name_len);
        size = elem_size * array_len;
    } else if (type_kind == TYPE_SLICE) {
        size = 16;
    } else {
        size = sizeof_type(type_kind, ptr_depth, struct_name_ptr, struct_name_len);
    }

    symtab_add(ctx.symtab, name_ptr, name_len, type_kind, ptr_depth, size);

    var ti: *TypeInfo = symtab_get_type(ctx.symtab, name_ptr, name_len);
    ti.is_tagged = decl.is_tagged;
    ti.struct_name_ptr = struct_name_ptr;
    ti.struct_name_len = struct_name_len;
    ti.tag_layout_ptr = decl.tag_layout_ptr;
    ti.tag_layout_len = decl.tag_layout_len;
    ti.elem_type_kind = elem_type_kind;
    ti.elem_ptr_depth = elem_ptr_depth;
    ti.array_len = array_len;

    var g_structs_vec: *Vec<*AstStructDef> = typeinfo_get_structs();
    if (type_kind == TYPE_STRUCT && g_structs_vec != 0 && struct_name_ptr != 0) {
        var num_structs: u64 = g_structs_vec.len();
        for (var si: u64 = 0; si < num_structs; si++) {
            var sd: *AstStructDef = g_structs_vec.get(si);
            if (sd.name_len == struct_name_len && str_eq(sd.name_ptr, sd.name_len, struct_name_ptr, struct_name_len) != 0) {
                ti.struct_def = sd;
                break;
            }
        }
    }
    if (type_kind == TYPE_ARRAY || type_kind == TYPE_SLICE) {
        if (elem_type_kind == TYPE_STRUCT && g_structs_vec != 0 && struct_name_ptr != 0) {
            var num_structs2: u64 = g_structs_vec.len();
            for (var sj: u64 = 0; sj < num_structs2; sj++) {
                var sd2: *AstStructDef = g_structs_vec.get(sj);
                if (sd2.name_len == struct_name_len && str_eq(sd2.name_ptr, sd2.name_len, struct_name_ptr, struct_name_len) != 0) {
                    ti.struct_def = sd2;
                    break;
                }
            }
        }
    }

    return 0;
}

func builder_new_reg(ctx: *BuilderCtx) -> u64 {
    var id: u64 = ctx.next_reg;
    ctx.next_reg = ctx.next_reg + 1;
    return id;
}

func builder_new_var_id(ctx: *BuilderCtx) -> u64 {
    var id: u64 = ctx.next_var_id;
    ctx.next_var_id = ctx.next_var_id + 1;
    return id;
}

func builder_get_var_id(ctx: *BuilderCtx, name_ptr: u64, name_len: u64) -> u64 {
    if (ctx.var_map == 0) {
        ctx.var_map = new HashMap<u64, u64>(16);
    }

    var found: u64 = ctx.var_map.get(name_ptr, name_len);
    if (found != 0) { return found; }

    var new_id: u64 = builder_new_var_id(ctx);
    ctx.var_map.put(name_ptr, name_len, new_id);
    return new_id;
}

func builder_set_const(ctx: *BuilderCtx, name_ptr: u64, name_len: u64, value: u64) -> u64 {
    if (ctx.const_map == 0) {
        ctx.const_map = new HashMap<u64, u64>(16);
    }
    ctx.const_map.put(name_ptr, name_len, value + 1);
    return 0;
}

func builder_get_const(ctx: *BuilderCtx, name_ptr: u64, name_len: u64) -> u64 {
    if (ctx.const_map == 0) { return 0; }
    return ctx.const_map.get(name_ptr, name_len);
}

func builder_set_func_ptr(ctx: *BuilderCtx, name_ptr: u64, name_len: u64, func_ptr: u64, func_len: u64) -> u64 {
    if (ctx.func_ptr_map == 0) {
        ctx.func_ptr_map = new HashMap<u64, *PtrLen>(16);
    }
    if (func_ptr == 0 || func_len == 0) {
        ctx.func_ptr_map.put(name_ptr, name_len, 0);
        return 0;
    }
    var info: *PtrLen = new PtrLen{func_ptr, func_len};
    ctx.func_ptr_map.put(name_ptr, name_len, info);
    return 0;
}

func builder_get_func_ptr(ctx: *BuilderCtx, name_ptr: u64, name_len: u64) -> *PtrLen {
    if (ctx.func_ptr_map == 0) { return 0; }
    return ctx.func_ptr_map.get(name_ptr, name_len);
}

func builder_apply_param_typeinfo(p: *Param, ti: *TypeInfo) -> u64 {
    if (p == 0 || ti == 0) {
        return 0;
    }
    ti.is_tagged = p.is_tagged;
    ti.struct_name_ptr = p.struct_name_ptr;
    ti.struct_name_len = p.struct_name_len;
    ti.tag_layout_ptr = p.tag_layout_ptr;
    ti.tag_layout_len = p.tag_layout_len;
    ti.elem_type_kind = p.elem_type_kind;
    ti.elem_ptr_depth = p.elem_ptr_depth;
    ti.array_len = p.array_len;

    var g_structs_vec: *Vec<*AstStructDef> = typeinfo_get_structs();
    if (g_structs_vec == 0 || p.struct_name_ptr == 0) {
        return 0;
    }
    var needs_struct_def: u64 = 0;
    if (p.type_kind == TYPE_STRUCT) {
        needs_struct_def = 1;
    } else if ((p.type_kind == TYPE_ARRAY || p.type_kind == TYPE_SLICE) && p.elem_type_kind == TYPE_STRUCT) {
        needs_struct_def = 1;
    }
    if (needs_struct_def == 0) {
        return 0;
    }
    var num_structs: u64 = g_structs_vec.len();
    for (var si: u64 = 0; si < num_structs; si++) {
        var sd: *AstStructDef = g_structs_vec.get(si);
        if (sd.name_len == p.struct_name_len && str_eq(sd.name_ptr, sd.name_len, p.struct_name_ptr, p.struct_name_len) != 0) {
            ti.struct_def = sd;
            break;
        }
    }
    return 0;
}

func builder_emit_param_struct_local(ctx: *BuilderCtx, p: *Param, start_idx: u64, offset: u64, struct_size: u64) -> u64 {
    var base_addr: u64 = builder_new_lea_local(ctx, offset);
    if (struct_size <= 8) {
        var reg0: u64 = builder_new_reg(ctx);
        var param0: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_PARAM, reg0, ssa_operand_const(start_idx), 0);
        ssa_inst_append(ctx.cur_block, param0);
        builder_store_by_size(ctx, base_addr, reg0, struct_size);
        return 0;
    }
    if (struct_size <= 16) {
        var reg_lo: u64 = builder_new_reg(ctx);
        var reg_hi: u64 = builder_new_reg(ctx);
        var param_lo: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_PARAM, reg_lo, ssa_operand_const(start_idx), 0);
        var param_hi: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_PARAM, reg_hi, ssa_operand_const(start_idx + 1), 0);
        ssa_inst_append(ctx.cur_block, param_lo);
        ssa_inst_append(ctx.cur_block, param_hi);
        builder_store_by_size(ctx, base_addr, reg_lo, 8);
        var off_reg: u64 = build_const(ctx, 8);
        var addr2: u64 = builder_new_reg(ctx);
        var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(base_addr), ssa_operand_reg(off_reg));
        ssa_inst_append(ctx.cur_block, add_ptr);
        var tail_size: u64 = struct_size - 8;
        builder_store_by_size(ctx, addr2, reg_hi, tail_size);
        return 0;
    }
    var reg_ptr: u64 = builder_new_reg(ctx);
    var param_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_PARAM, reg_ptr, ssa_operand_const(start_idx), 0);
    ssa_inst_append(ctx.cur_block, param_ptr);
    if (ctx.debug_mode != 0) {
        emit("[DEBUG] ssa param copy large struct: ");
        emit_len(p.name_ptr, p.name_len);
        emit(" size=");
        print_u64(struct_size);
        emit("\n");
    }
    builder_struct_copy(ctx, base_addr, reg_ptr, struct_size);
    return 0;
}

func builder_emit_param_slice_local(ctx: *BuilderCtx, start_idx: u64, offset: u64) -> u64 {
    var base_addr: u64 = builder_new_lea_local(ctx, offset);
    var ptr_reg: u64 = builder_new_reg(ctx);
    var ptr_param: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_PARAM, ptr_reg, ssa_operand_const(start_idx), 0);
    ssa_inst_append(ctx.cur_block, ptr_param);
    builder_store_by_size(ctx, base_addr, ptr_reg, 8);
    var len_reg: u64 = builder_new_reg(ctx);
    var len_param: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_PARAM, len_reg, ssa_operand_const(start_idx + 1), 0);
    ssa_inst_append(ctx.cur_block, len_param);
    var off_reg2: u64 = build_const(ctx, 8);
    var addr3: u64 = builder_new_reg(ctx);
    var add_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr3, ssa_operand_reg(base_addr), ssa_operand_reg(off_reg2));
    ssa_inst_append(ctx.cur_block, add_ptr2);
    builder_store_by_size(ctx, addr3, len_reg, 8);
    return 0;
}

func builder_add_params(ctx: *BuilderCtx, fn: *AstFunc) -> u64 {
    push_trace("builder_add_params", "ssa_builder.b", __LINE__);
    defer pop_trace();
    if (fn == 0) { return 0; }
    var params: *Vec<*Param> = fn.params_vec;
    if (params == 0) { return 0; }

    ctx.sret_addr_reg = 0;
    var has_sret: u64 = 0;
    if (fn.ret_type == TYPE_STRUCT && fn.ret_ptr_depth == 0) {
        var ret_struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, fn.ret_struct_name_ptr, fn.ret_struct_name_len);
        var ret_def: *AstStructDef = get_struct_def(fn.ret_struct_name_ptr, fn.ret_struct_name_len);
        var ret_def_size: u64 = builder_struct_size_from_def(ret_def);
        if (ret_def_size > ret_struct_size) { ret_struct_size = ret_def_size; }
        if (ret_struct_size > 16) { has_sret = 1; }
    }

    var n: u64 = params.len();
    var param_offsets: *Vec<u64> = new Vec<u64>(n);
    var param_arg_idx: *Vec<u64> = new Vec<u64>(n);
    var arg_idx: u64 = 0;
    if (has_sret != 0) { arg_idx = 1; }

    for (var i: u64 = 0; i < n; i++) {
        var p: *Param = params.get(i);
        var param_words: u64 = 1;
        if (p.type_kind == TYPE_STRUCT && p.ptr_depth == 0) {
            var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, p.struct_name_ptr, p.struct_name_len);
            if (struct_size == 0) { return 0; }
            if (struct_size <= 8) { param_words = 1; }
            else if (struct_size <= 16) { param_words = 2; }
            else {
                param_words = 1;
                if (ctx.debug_mode != 0) {
                    emit("[DEBUG] ssa param large struct: ");
                    emit_len(p.name_ptr, p.name_len);
                    emit(" size=");
                    print_u64(struct_size);
                    emit("\n");
                }
            }

            var offset: u64 = symtab_add(ctx.symtab, p.name_ptr, p.name_len, p.type_kind, p.ptr_depth, struct_size);
            var ti: *TypeInfo = symtab_get_type(ctx.symtab, p.name_ptr, p.name_len);
            builder_apply_param_typeinfo(p, ti);
            param_offsets.push(offset);
        } else if (p.type_kind == TYPE_SLICE && p.ptr_depth == 0) {
            var offset2: u64 = symtab_add(ctx.symtab, p.name_ptr, p.name_len, p.type_kind, p.ptr_depth, 16);
            var ti2: *TypeInfo = symtab_get_type(ctx.symtab, p.name_ptr, p.name_len);
            builder_apply_param_typeinfo(p, ti2);
            param_words = 2;
            param_offsets.push(offset2);
        } else {
            param_offsets.push(0);
        }

        param_arg_idx.push(arg_idx);
        arg_idx = arg_idx + param_words;
    }

    for (var i: u64 = n; i > 0; i--) {
        var idx: u64 = i - 1;
        var p2: *Param = params.get(idx);
        var start_idx: u64 = param_arg_idx.get(idx);
        if (p2.type_kind == TYPE_STRUCT && p2.ptr_depth == 0) {
            var struct_size2: u64 = sizeof_type(TYPE_STRUCT, 0, p2.struct_name_ptr, p2.struct_name_len);
            if (struct_size2 == 0) { return 0; }
            var offset3: u64 = param_offsets.get(idx);
            builder_emit_param_struct_local(ctx, p2, start_idx, offset3, struct_size2);
            continue;
        }

        if (p2.type_kind == TYPE_SLICE && p2.ptr_depth == 0) {
            var offset4: u64 = param_offsets.get(idx);
            builder_emit_param_slice_local(ctx, start_idx, offset4);
            continue;
        }

        var var_id: u64 = builder_get_var_id(ctx, p2.name_ptr, p2.name_len);
        var reg_id: u64 = builder_new_reg(ctx);
        var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_PARAM, reg_id, ssa_operand_const(start_idx), 0);
        ssa_inst_append(ctx.cur_block, inst_ptr);
        var st_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_STORE, 0, ssa_operand_const(var_id), ssa_operand_reg(reg_id));
        ssa_inst_append(ctx.cur_block, st_ptr);
        builder_symtab_add_param(ctx, p2, 16 + start_idx * 8);
    }
    if (has_sret != 0) {
        var sret_reg: u64 = builder_new_reg(ctx);
        var sret_param: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_PARAM, sret_reg, ssa_operand_const(0), 0);
        ssa_inst_append(ctx.cur_block, sret_param);
        ctx.sret_addr_reg = sret_reg;
    }
    return 0;
}

// ============================================
// Address/Memory Helpers
// ============================================

func builder_new_lea_local(ctx: *BuilderCtx, offset: u64) -> u64 {
    var reg_id: u64 = builder_new_reg(ctx);
    // Encode signed 64-bit stack offset into 63-bit field with bias so
    // ssa_operand_value can carry it without losing sign.
    var signed_off: i64 = (i64)offset;
    var bias: u64 = 4611686018427387904; // 1<<62
    var enc: u64 = (u64)(signed_off + (i64)bias);
    var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_LEA_LOCAL, reg_id, ssa_operand_const(enc), 0);
    ssa_inst_append(ctx.cur_block, inst_ptr);
    return reg_id;
}

func builder_new_lea_global(ctx: *BuilderCtx, name_ptr: u64, name_len: u64) -> u64 {
    var info: *PtrLen = new PtrLen{name_ptr, name_len};
    var reg_id: u64 = builder_new_reg(ctx);
    var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_LEA_GLOBAL, reg_id, ssa_operand_const((u64)info), 0);
    ssa_inst_append(ctx.cur_block, inst_ptr);
    return reg_id;
}

func builder_new_lea_func(ctx: *BuilderCtx, name_ptr: u64, name_len: u64) -> u64 {
    var info: *PtrLen = new PtrLen{name_ptr, name_len};
    var reg_id: u64 = builder_new_reg(ctx);
    var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_LEA_FUNC, reg_id, ssa_operand_const((u64)info), 0);
    ssa_inst_append(ctx.cur_block, inst_ptr);
    return reg_id;
}

func builder_load_by_size(ctx: *BuilderCtx, addr_reg: u64, size: u64) -> u64 {
    var reg_id: u64 = builder_new_reg(ctx);
    var op: u64 = SSA_OP_LOAD64;
    if (size == 1) { op = SSA_OP_LOAD8; }
    else if (size == 2) { op = SSA_OP_LOAD16; }
    else if (size == 4) { op = SSA_OP_LOAD32; }
    var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, op, reg_id, ssa_operand_reg(addr_reg), 0);
    ssa_inst_append(ctx.cur_block, inst_ptr);
    return reg_id;
}

func builder_store_by_size(ctx: *BuilderCtx, addr_reg: u64, val_reg: u64, size: u64) -> u64 {
    var op: u64 = SSA_OP_STORE64;
    if (size == 1) { op = SSA_OP_STORE8; }
    else if (size == 2) { op = SSA_OP_STORE16; }
    else if (size == 4) { op = SSA_OP_STORE32; }
    var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, op, 0, ssa_operand_reg(addr_reg), ssa_operand_reg(val_reg));
    ssa_inst_append(ctx.cur_block, inst_ptr);
    return 0;
}

func builder_struct_copy(ctx: *BuilderCtx, dst_addr: u64, src_addr: u64, size: u64) -> u64 {
    for (var offset: u64 = 0; offset < size; ) {
        var chunk: u64 = size - offset;
        if (chunk > 8) { chunk = 8; }
        var src_reg: u64 = src_addr;
        var dst_reg: u64 = dst_addr;
        if (offset != 0) {
            var off_reg: u64 = build_const(ctx, offset);
            var src_tmp: u64 = builder_new_reg(ctx);
            var dst_tmp: u64 = builder_new_reg(ctx);
            var add_src: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, src_tmp, ssa_operand_reg(src_addr), ssa_operand_reg(off_reg));
            var add_dst: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, dst_tmp, ssa_operand_reg(dst_addr), ssa_operand_reg(off_reg));
            ssa_inst_append(ctx.cur_block, add_src);
            ssa_inst_append(ctx.cur_block, add_dst);
            src_reg = src_tmp;
            dst_reg = dst_tmp;
        }
        var val_reg: u64 = builder_load_by_size(ctx, src_reg, chunk);
        builder_store_by_size(ctx, dst_reg, val_reg, chunk);
        offset = offset + chunk;
    }
    return 0;
}

func builder_append_slice_arg(ctx: *BuilderCtx, arg_regs: *Vec<u64>, arg: u64) -> u64 {
    var k: u64 = ast_kind(arg);
    if (k == AST_SLICE) {
        var slice_regs: *SliceRegs = builder_slice_regs(ctx, arg);
        var ptr_reg: u64 = slice_regs.ptr_reg;
        var len_reg: u64 = slice_regs.len_reg;
        arg_regs.push(ptr_reg);
        arg_regs.push(len_reg);
        return 0;
    }

    var addr_reg: u64 = builder_lvalue_addr(ctx, arg);
    if (addr_reg == 0) { return 0; }
    var ptr_reg2: u64 = builder_load_by_size(ctx, addr_reg, 8);
    var off_reg: u64 = build_const(ctx, 8);
    var addr2: u64 = builder_new_reg(ctx);
    var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(addr_reg), ssa_operand_reg(off_reg));
    ssa_inst_append(ctx.cur_block, add_ptr);
    var len_reg2: u64 = builder_load_by_size(ctx, addr2, 8);
    arg_regs.push(ptr_reg2);
    arg_regs.push(len_reg2);
    return 0;
}

func builder_get_sret_struct_size(ctx: *BuilderCtx, expr: u64) -> u64 {
    if (expr == 0) { return 0; }
    var struct_size: u64 = 0;
        var ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)expr, ctx.symtab);
    if (ti != 0) {
        if (ti.type_kind == TYPE_STRUCT && ti.ptr_depth == 0) {
            if (ti.struct_name_ptr != 0 && ti.struct_name_len != 0) {
                struct_size = sizeof_type(TYPE_STRUCT, 0, ti.struct_name_ptr, ti.struct_name_len);
            }
            if (struct_size <= 16 && ti.struct_def != 0) {
                var def_size: u64 = builder_struct_size_from_def(ti.struct_def);
                if (def_size > struct_size) { struct_size = def_size; }
            }
        }
    }
    if (struct_size <= 16) {
        var k: u64 = ast_kind(expr);
        if (k == AST_CALL) {
            var call_node: *AstCall = (*AstCall)expr;
            var call_fn: *AstFunc = compiler_get_func(call_node.name_ptr, call_node.name_len);
            if (call_fn != 0) {
                if (call_fn.ret_type == TYPE_STRUCT && call_fn.ret_ptr_depth == 0) {
                    var call_def: *AstStructDef = get_struct_def(call_fn.ret_struct_name_ptr, call_fn.ret_struct_name_len);
                    var call_def_size: u64 = builder_struct_size_from_def(call_def);
                    if (call_def_size == 0) {
                        call_def_size = sizeof_type(TYPE_STRUCT, 0, call_fn.ret_struct_name_ptr, call_fn.ret_struct_name_len);
                    }
                    if (call_def_size > struct_size) { struct_size = call_def_size; }
                }
            }
        }
        if (k == AST_METHOD_CALL) {
            var mc_node: *AstMethodCall = (*AstMethodCall)expr;
            var recv_ti: *TypeInfo = get_expr_type_with_symtab(mc_node.receiver, ctx.symtab);
            if (recv_ti != 0) {
                if (recv_ti.type_kind == TYPE_STRUCT && recv_ti.struct_name_ptr != 0) {
                    var name_info: *NameInfo = builder_build_method_name(recv_ti.struct_name_ptr, recv_ti.struct_name_len, mc_node.method_ptr, mc_node.method_len);
                    var call_fn2: *AstFunc = compiler_get_func(name_info.ptr, name_info.len);
                    if (call_fn2 != 0) {
                        if (call_fn2.ret_type == TYPE_STRUCT && call_fn2.ret_ptr_depth == 0) {
                            var call_def2: *AstStructDef = get_struct_def(call_fn2.ret_struct_name_ptr, call_fn2.ret_struct_name_len);
                            var call_def_size2: u64 = builder_struct_size_from_def(call_def2);
                            if (call_def_size2 == 0) {
                                call_def_size2 = sizeof_type(TYPE_STRUCT, 0, call_fn2.ret_struct_name_ptr, call_fn2.ret_struct_name_len);
                            }
                            if (call_def_size2 > struct_size) { struct_size = call_def_size2; }
                        }
                    }
                }
            }
        }
    }
    if (struct_size <= 16) { return 0; }
    if (SSA_BUILDER_DEBUG != 0) {
        println("[DEBUG] sret temp slot for expr", 31);
    }
    return struct_size;
}

func builder_append_struct_value_from_addr(ctx: *BuilderCtx, arg_regs: *Vec<u64>, addr_reg: u64, struct_size: u64) -> u64 {
    if (struct_size == 0) {
        return 0;
    }
    if (struct_size <= 8) {
        var val: u64 = builder_load_by_size(ctx, addr_reg, struct_size);
        arg_regs.push(val);
        return 0;
    }
    if (struct_size <= 16) {
        var lo: u64 = builder_load_by_size(ctx, addr_reg, 8);
        var off8: u64 = build_const(ctx, 8);
        var addr2: u64 = builder_new_reg(ctx);
        var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(addr_reg), ssa_operand_reg(off8));
        ssa_inst_append(ctx.cur_block, add_ptr);
        var tail_size: u64 = struct_size - 8;
        var hi: u64 = builder_load_by_size(ctx, addr2, tail_size);
        arg_regs.push(lo);
        arg_regs.push(hi);
        return 0;
    }
    arg_regs.push(addr_reg);
    return 0;
}

func builder_append_small_struct_call_result(ctx: *BuilderCtx, arg_regs: *Vec<u64>, arg_kind: u64, arg: u64, struct_size: u64) -> u64 {
    if (struct_size == 0 || struct_size > 16) {
        return 0;
    }
    if (!(arg_kind == AST_CALL || arg_kind == AST_METHOD_CALL || arg_kind == AST_CALL_PTR)) {
        return 0;
    }
    if (struct_size <= 8) {
        var reg0: u64 = builder_new_reg(ctx);
        if (arg_kind == AST_CALL) {
            builder_emit_call(ctx, (*AstCall)arg, reg0, 0);
        } else if (arg_kind == AST_METHOD_CALL) {
            builder_emit_method_call(ctx, (*AstMethodCall)arg, reg0, 0);
        } else {
            builder_emit_call_ptr(ctx, (*AstCallPtr)arg, reg0, 0);
        }
        arg_regs.push(reg0);
        return 1;
    }
    var lo_reg: u64 = builder_new_reg(ctx);
    var hi_reg: u64 = builder_new_reg(ctx);
    if (arg_kind == AST_CALL) {
        builder_emit_call(ctx, (*AstCall)arg, lo_reg, hi_reg);
    } else if (arg_kind == AST_METHOD_CALL) {
        builder_emit_method_call(ctx, (*AstMethodCall)arg, lo_reg, hi_reg);
    } else {
        builder_emit_call_ptr(ctx, (*AstCallPtr)arg, lo_reg, hi_reg);
    }
    arg_regs.push(lo_reg);
    arg_regs.push(hi_reg);
    return 1;
}

func builder_emit_struct_call_sret_by_kind(ctx: *BuilderCtx, arg_kind: u64, arg: u64, temp_addr: u64) -> u64 {
    if (arg_kind == AST_CALL) {
        builder_emit_call_sret(ctx, (*AstCall)arg, temp_addr);
        return 1;
    }
    if (arg_kind == AST_METHOD_CALL) {
        builder_emit_method_call_sret(ctx, (*AstMethodCall)arg, temp_addr);
        return 1;
    }
    if (arg_kind == AST_CALL_PTR) {
        builder_emit_call_ptr_sret(ctx, (*AstCallPtr)arg, temp_addr);
        return 1;
    }
    return 0;
}

func builder_append_call_arg_stack_ctor(ctx: *BuilderCtx, arg_regs: *Vec<u64>, arg: u64) -> u64 {
    if (ast_kind(arg) != AST_STACK_CTOR) {
        return 0;
    }
    var sc_arg: *AstStackCtor = (*AstStackCtor)arg;
    var sc_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)arg, ctx.symtab);
    if (sc_ti == 0 || sc_ti.type_kind != TYPE_STRUCT || sc_ti.ptr_depth != 0) {
        emit_stderr("[ERROR] SSA stack ctor arg requires struct value\n");
        return 1;
    }
    var struct_size_sc: u64 = sizeof_type(TYPE_STRUCT, 0, sc_ti.struct_name_ptr, sc_ti.struct_name_len);
    if (struct_size_sc == 0) {
        emit_stderr("[ERROR] SSA stack ctor arg struct size unresolved\n");
        return 1;
    }
    var temp_offset_sc: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, struct_size_sc);
    var temp_addr_sc: u64 = builder_new_lea_local(ctx, temp_offset_sc);
    builder_stack_ctor_init_at_addr(ctx, sc_arg, temp_addr_sc);
    builder_append_struct_value_from_addr(ctx, arg_regs, temp_addr_sc, struct_size_sc);
    return 1;
}

func builder_append_call_arg_struct_literal(ctx: *BuilderCtx, arg_regs: *Vec<u64>, arg: u64) -> u64 {
    if (ast_kind(arg) != AST_STRUCT_LITERAL) {
        return 0;
    }
    var lit: *AstStructLiteral = (*AstStructLiteral)arg;
    var struct_size_lit: u64 = builder_resolve_struct_literal_size(ctx, lit, 0, 0);
    if (struct_size_lit == 0) {
        emit_stderr("[ERROR] SSA arg struct literal size unresolved\n");
        return 1;
    }

    if (lit.struct_def != 0 && struct_size_lit <= 16) {
        var struct_info: *AstStructDef = lit.struct_def;
        var packed_flag: u64 = struct_info.is_packed;
        if (packed_flag == 0) {
            var fields: *Vec<*FieldDesc> = struct_info.fields_vec;
            var num_fields: u64 = 0;
            if (fields != 0) { num_fields = fields.len(); }
            if (num_fields >= 1 && num_fields <= 2 && lit.values_vec != 0) {
                var f0: *FieldDesc = fields.get(0);
                var f0_size: u64 = sizeof_field_desc(f0);
                var v0: *AstNode = lit.values_vec.get(0);
                var reg0: u64 = build_expr(ctx, v0);
                if (reg0 == 0) { reg0 = build_const(ctx, 0); }
                if (num_fields == 1 && f0_size == 8) {
                    arg_regs.push(reg0);
                    return 1;
                }
                if (num_fields == 2) {
                    var f1: *FieldDesc = fields.get(1);
                    var f1_size: u64 = sizeof_field_desc(f1);
                    if (f0_size == 8 && f1_size == 8 && lit.values_vec.len() > 1) {
                        var v1: *AstNode = lit.values_vec.get(1);
                        var reg1: u64 = build_expr(ctx, v1);
                        if (reg1 == 0) { reg1 = build_const(ctx, 0); }
                        arg_regs.push(reg0);
                        arg_regs.push(reg1);
                        return 1;
                    }
                }
            }
        }
    }

    var temp_offset_lit: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, struct_size_lit);
    var temp_addr_lit: u64 = builder_new_lea_local(ctx, temp_offset_lit);
    builder_struct_literal_init(ctx, lit.struct_def, lit.values_vec, temp_addr_lit);
    if (struct_size_lit > 16 && ctx.debug_mode != 0) {
        emit("[DEBUG] ssa call arg large struct literal size=");
        print_u64(struct_size_lit);
        emit("\n");
    }
    builder_append_struct_value_from_addr(ctx, arg_regs, temp_addr_lit, struct_size_lit);
    return 1;
}

func builder_append_call_arg_call_struct_fast(ctx: *BuilderCtx, arg_regs: *Vec<u64>, arg: u64) -> u64 {
    if (ast_kind(arg) != AST_CALL) {
        return 0;
    }
    var call: *AstCall = (*AstCall)arg;
    var fn: *AstFunc = compiler_get_func(call.name_ptr, call.name_len);
    if (fn == 0) {
        return 0;
    }
    if (fn.ret_type == TYPE_STRUCT && fn.ret_ptr_depth == 0) {
        var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, fn.ret_struct_name_ptr, fn.ret_struct_name_len);
        if (builder_append_small_struct_call_result(ctx, arg_regs, AST_CALL, arg, struct_size) != 0) {
            return 1;
        }
    }
    return 0;
}

func builder_append_call_arg_struct_typed(ctx: *BuilderCtx, arg_regs: *Vec<u64>, arg: u64, arg_kind: u64, ti: *TypeInfo) -> u64 {
    var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, ti.struct_name_ptr, ti.struct_name_len);
    if (struct_size == 0) {
        var def_ptr: *AstStructDef = ti.struct_def;
        if (def_ptr == 0 && arg_kind == AST_STRUCT_LITERAL) {
            var lit_def: *AstStructLiteral = (*AstStructLiteral)arg;
            def_ptr = lit_def.struct_def;
        }
        var def_size: u64 = builder_struct_size_from_def(def_ptr);
        if (def_size > 0) { struct_size = def_size; }
    }
    if (struct_size == 0 && arg_kind == AST_STRUCT_LITERAL) {
        var lit_fallback2: *AstStructLiteral = (*AstStructLiteral)arg;
        struct_size = builder_resolve_struct_literal_size(ctx, lit_fallback2, 0, 0);
    }
    if (struct_size == 0) {
        emit_stderr("[ERROR] SSA arg struct size unresolved\n");
        return 0;
    }
    if (struct_size <= 16) {
        if (builder_append_small_struct_call_result(ctx, arg_regs, arg_kind, arg, struct_size) != 0) {
            return 0;
        }
        var small_addr: u64 = builder_lvalue_addr(ctx, arg);
        builder_append_struct_value_from_addr(ctx, arg_regs, small_addr, struct_size);
        return 0;
    }
    if (ctx.debug_mode != 0) {
        emit("[DEBUG] ssa call arg large struct: ");
        emit_len(ti.struct_name_ptr, ti.struct_name_len);
        emit(" size=");
        print_u64(struct_size);
        emit("\n");
    }
    var temp_offset: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, struct_size);
    var temp_addr: u64 = builder_new_lea_local(ctx, temp_offset);
    if (arg_kind == AST_STRUCT_LITERAL) {
        var lit: *AstStructLiteral = (*AstStructLiteral)arg;
        builder_struct_literal_init(ctx, lit.struct_def, lit.values_vec, temp_addr);
    } else {
        if (builder_emit_struct_call_sret_by_kind(ctx, arg_kind, arg, temp_addr) == 0) {
            var src_addr: u64 = builder_lvalue_addr(ctx, arg);
            if (src_addr == 0) { return 0; }
            builder_struct_copy(ctx, temp_addr, src_addr, struct_size);
        }
    }
    arg_regs.push(temp_addr);
    return 0;
}

func builder_append_call_arg(ctx: *BuilderCtx, arg_regs: *Vec<u64>, arg: u64) -> u64 {
    var arg_kind: u64 = ast_kind(arg);

    if (builder_append_call_arg_stack_ctor(ctx, arg_regs, arg) != 0) {
        return 0;
    }

    if (builder_append_call_arg_struct_literal(ctx, arg_regs, arg) != 0) {
        return 0;
    }

    if (builder_append_call_arg_call_struct_fast(ctx, arg_regs, arg) != 0) {
        return 0;
    }

    var ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)arg, ctx.symtab);
    if (ti != 0) {
        if (ti.type_kind == TYPE_SLICE && ti.ptr_depth == 0) {
            return builder_append_slice_arg(ctx, arg_regs, arg);
        }
        if (ti.type_kind == TYPE_ARRAY && ti.ptr_depth == 0) {
            var addr_reg: u64 = builder_lvalue_addr(ctx, arg);
            arg_regs.push(addr_reg);
            return 0;
        }
        if (ti.type_kind == TYPE_STRUCT && ti.ptr_depth == 0) {
            builder_append_call_arg_struct_typed(ctx, arg_regs, arg, arg_kind, ti);
            return 0;
        }
    }
    var reg: u64 = build_expr(ctx, arg);
    arg_regs.push(reg);
    return 0;
}

func builder_slice_regs(ctx: *BuilderCtx, expr: u64) -> *SliceRegs {
    var info: *SliceRegs = new SliceRegs();
    var k: u64 = ast_kind(expr);
    if (k == AST_SLICE) {
        var s: *AstSlice = (*AstSlice)expr;
        var ptr_reg: u64 = 0;
        var ptr_kind: u64 = ast_kind(s.ptr_expr);
        if (ptr_kind == AST_IDENT) {
            var ti: *TypeInfo = get_expr_type_with_symtab(s.ptr_expr, ctx.symtab);
            if (ti != 0) {
                if (ti.ptr_depth == 0) {
                    if (ti.type_kind == TYPE_ARRAY || ti.array_len != 0) {
                        ptr_reg = builder_lvalue_addr(ctx, s.ptr_expr);
                    }
                }
            }
        }
        if (ptr_reg == 0) {
            ptr_reg = build_expr(ctx, s.ptr_expr);
        }
        var len_reg: u64 = build_expr(ctx, s.len_expr);
        info.ptr_reg = ptr_reg;
        info.len_reg = len_reg;
        return info;
    }

    var addr_reg: u64 = builder_lvalue_addr(ctx, expr);
    var ptr_reg2: u64 = builder_load_by_size(ctx, addr_reg, 8);
    var off_reg: u64 = build_const(ctx, 8);
    var addr2: u64 = builder_new_reg(ctx);
    var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(addr_reg), ssa_operand_reg(off_reg));
    ssa_inst_append(ctx.cur_block, add_ptr);
    var len_reg2: u64 = builder_load_by_size(ctx, addr2, 8);
    info.ptr_reg = ptr_reg2;
    info.len_reg = len_reg2;
    return info;
}

func builder_struct_literal_init(ctx: *BuilderCtx, struct_def: *AstStructDef, values: *Vec<*AstNode>, base_addr: u64) -> u64 {
    if (values == 0) { return 0; }
    if (struct_def == 0) {
        var num_values_raw: u64 = values.len();
        var field_offset_raw: u64 = 0;
        for (var ri: u64 = 0; ri < num_values_raw; ri++) {
            var addr_reg_raw: u64 = base_addr;
            if (field_offset_raw != 0) {
                var off_reg_raw: u64 = build_const(ctx, field_offset_raw);
                var addr_tmp: u64 = builder_new_reg(ctx);
                var add_ptr_raw: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr_tmp, ssa_operand_reg(base_addr), ssa_operand_reg(off_reg_raw));
                ssa_inst_append(ctx.cur_block, add_ptr_raw);
                addr_reg_raw = addr_tmp;
            }
            var value_raw: *AstNode = values.get(ri);
            var val_reg_raw: u64 = build_expr(ctx, value_raw);
            builder_store_by_size(ctx, addr_reg_raw, val_reg_raw, 8);
            field_offset_raw = field_offset_raw + 8;
        }
        return 0;
    }
    var sd: *AstStructDef = struct_def;
    var fields: *Vec<*FieldDesc> = sd.fields_vec;
    if (fields == 0) { return 0; }

    var parent_total: u64 = 0;
    if (sd.parents_vec != 0) {
        var parents: *Vec<*ParentDesc> = sd.parents_vec;
        var pn: u64 = parents.len();
        for (var pi: u64 = 0; pi < pn; pi++) {
            var parent_desc: *ParentDesc = parents.get(pi);
            var parent_def: *AstStructDef = parent_desc.struct_def;
            if (parent_def == 0) {
                parent_def = get_struct_def(parent_desc.name_ptr, parent_desc.name_len);
                if (parent_def == 0) {
                    emit("[ERROR] Parent struct not found\n");
                    panic("SSA build error");
                }
                parent_desc.struct_def = parent_def;
            }
            parent_total = parent_total + builder_struct_size_from_def(parent_def);
        }
    }

    var num_values: u64 = values.len();
    var num_fields: u64 = fields.len();
    var field_offset: u64 = parent_total;
    var value_index: u64 = 0;

    for (var fi: u64 = 0; fi < num_fields && value_index < num_values; fi++) {
        var field: *FieldDesc = fields.get(fi);
        var field_size: u64 = sizeof_field_desc(field);
        if (compiler_is_vptr_field_name(field.name_ptr, field.name_len) != 0) {
            field_offset = field_offset + field_size;
            continue;
        }

        var addr_reg: u64 = base_addr;
        if (field_offset != 0) {
            var off_reg: u64 = build_const(ctx, field_offset);
            var addr2: u64 = builder_new_reg(ctx);
            var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(base_addr), ssa_operand_reg(off_reg));
            ssa_inst_append(ctx.cur_block, add_ptr);
            addr_reg = addr2;
        }

        var value: *AstNode = values.get(value_index);
        if (ast_kind(value) == AST_STRUCT_LITERAL) {
            var lit: *AstStructLiteral = (*AstStructLiteral)value;
            var lit_def: *AstStructDef = lit.struct_def;
            if (lit_def == 0 && field.type_kind == TYPE_STRUCT) {
                lit_def = get_struct_def(field.struct_name_ptr, field.struct_name_len);
            }
            builder_struct_literal_init(ctx, lit_def, lit.values_vec, addr_reg);
        } else if (field.type_kind == TYPE_SLICE && field.ptr_depth == 0) {
            var slice_regs: *SliceRegs = builder_slice_regs(ctx, value);
            var ptr_reg: u64 = slice_regs.ptr_reg;
            var len_reg: u64 = slice_regs.len_reg;
            builder_store_by_size(ctx, addr_reg, ptr_reg, 8);
            var off8: u64 = build_const(ctx, 8);
            var addr3: u64 = builder_new_reg(ctx);
            var add_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr3, ssa_operand_reg(addr_reg), ssa_operand_reg(off8));
            ssa_inst_append(ctx.cur_block, add_ptr2);
            builder_store_by_size(ctx, addr3, len_reg, 8);
        } else {
            var val_reg: u64 = build_expr(ctx, value);
            var store_size: u64 = field_size;
            if (store_size > 8) { store_size = 8; }
            builder_store_by_size(ctx, addr_reg, val_reg, store_size);
        }

        field_offset = field_offset + field_size;
        value_index = value_index + 1;
    }

    return 0;
}

func builder_store_slice_regs(ctx: *BuilderCtx, base_addr: u64, slice_info: *SliceRegs) -> u64 {
    if (base_addr == 0 || slice_info == 0) { return 0; }
    var regs: *SliceRegs = slice_info;
    var ptr_reg: u64 = regs.ptr_reg;
    var len_reg: u64 = regs.len_reg;
    builder_store_by_size(ctx, base_addr, ptr_reg, 8);
    var off_reg: u64 = build_const(ctx, 8);
    var addr2: u64 = builder_new_reg(ctx);
    var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(base_addr), ssa_operand_reg(off_reg));
    ssa_inst_append(ctx.cur_block, add_ptr);
    builder_store_by_size(ctx, addr2, len_reg, 8);
    return 0;
}

func builder_assign_struct_literal_to_addr(ctx: *BuilderCtx, lit: *AstStructLiteral, base_addr: u64) -> u64 {
    if (lit == 0 || base_addr == 0) { return 0; }
    builder_struct_literal_init(ctx, lit.struct_def, lit.values_vec, base_addr);
    return 0;
}

func builder_assign_stack_ctor_to_addr(ctx: *BuilderCtx, sc: *AstStackCtor, base_addr: u64) -> u64 {
    if (sc == 0 || base_addr == 0) { return 0; }
    builder_stack_ctor_init_at_addr(ctx, sc, base_addr);
    return 0;
}

func builder_assign_slice_to_addr(ctx: *BuilderCtx, value: u64, base_addr: u64) -> u64 {
    if (base_addr == 0) { return 0; }
    var value_kind: u64 = ast_kind(value);
    if (value_kind == AST_CALL) {
        builder_emit_call_slice_store(ctx, (*AstCall)value, base_addr);
        return 0;
    }
    if (value_kind == AST_METHOD_CALL) {
        builder_emit_method_call_slice_store(ctx, (*AstMethodCall)value, base_addr);
        return 0;
    }
    if (value_kind == AST_CALL_PTR) {
        builder_emit_call_ptr_slice_store(ctx, (*AstCallPtr)value, base_addr);
        return 0;
    }
    var slice_info: *SliceRegs = builder_slice_regs(ctx, value);
    builder_store_slice_regs(ctx, base_addr, slice_info);
    return 0;
}

func builder_build_method_name(struct_ptr: u64, struct_len: u64, method_ptr: u64, method_len: u64) -> *NameInfo {
    return compiler_build_method_name(struct_ptr, struct_len, method_ptr, method_len);
}

func builder_emit_call(ctx: *BuilderCtx, call: *AstCall, dst: u64, extra_dst: u64) -> u64 {
    var name_ptr: u64 = call.name_ptr;
    var name_len: u64 = call.name_len;
    if (compiler_func_exists(name_ptr, name_len) == 0) {
        var callee: *AstNode = ast_ident(name_ptr, name_len);
        var cp: *AstCallPtr = ast_call_ptr(callee, call.args_vec);
        return builder_emit_call_ptr(ctx, cp, dst, extra_dst);
    }
    var resolved_ptr: u64 = name_ptr;
    var resolved_len: u64 = name_len;
    var resolved: *NameInfo = resolve_name(name_ptr, name_len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }

    var args: *Vec<u64> = call.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    var total_regs: u64 = arg_regs.len();

    var ret_type: u64 = TYPE_I64;
    var ret_ptr_depth: u64 = 0;
    var ret_struct_size: u64 = 0;
    var ret_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)call, ctx.symtab);
    if (ret_ti != 0) {
        ret_type = ret_ti.type_kind;
        ret_ptr_depth = ret_ti.ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            ret_struct_size = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
        }
    }

    var info: *SSACallInfo = new SSACallInfo();
    info.name_ptr = resolved_ptr;
    info.name_len = resolved_len;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;
    info.ret_struct_size = ret_struct_size;

    var extra_opr: u64 = 0;
    if (extra_dst != 0) { extra_opr = ssa_operand_reg(extra_dst); }
    var call_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL, dst, ssa_operand_const((u64)info), extra_opr);
    ssa_inst_append(ctx.cur_block, call_ptr);
    return dst;
}

func builder_emit_call_sret(ctx: *BuilderCtx, call: *AstCall, addr_reg: u64) -> u64 {
    if (addr_reg == 0) { return 0; }
    var name_ptr: u64 = call.name_ptr;
    var name_len: u64 = call.name_len;
    if (compiler_func_exists(name_ptr, name_len) == 0) {
        var callee: *AstNode = ast_ident(name_ptr, name_len);
        var cp: *AstCallPtr = ast_call_ptr(callee, call.args_vec);
        return builder_emit_call_ptr_sret(ctx, cp, addr_reg);
    }
    var resolved_ptr: u64 = name_ptr;
    var resolved_len: u64 = name_len;
    var resolved: *NameInfo = resolve_name(name_ptr, name_len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }

    var args: *Vec<u64> = call.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2 + 1);
    arg_regs.push(addr_reg);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    var total_regs: u64 = arg_regs.len();

    var ret_type: u64 = TYPE_STRUCT;
    var ret_ptr_depth: u64 = 0;
    var ret_struct_size: u64 = 0;
    var ret_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)call, ctx.symtab);
    if (ret_ti != 0) {
        ret_type = ret_ti.type_kind;
        ret_ptr_depth = ret_ti.ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            ret_struct_size = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
        }
    }

    var info: *SSACallInfo = new SSACallInfo();
    var info_ptr: u64 = (u64)info;
    info.name_ptr = resolved_ptr;
    info.name_len = resolved_len;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;
    info.ret_struct_size = ret_struct_size;

    var call_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL, 0, ssa_operand_const(info_ptr), 0);
    ssa_inst_append(ctx.cur_block, call_ptr);
    return 0;
}

func builder_emit_call_slice_store(ctx: *BuilderCtx, call: *AstCall, addr_reg: u64) -> u64 {
    var name_ptr: u64 = call.name_ptr;
    var name_len: u64 = call.name_len;
    if (compiler_func_exists(name_ptr, name_len) == 0) {
        var callee: *AstNode = ast_ident(name_ptr, name_len);
        var cp: *AstCallPtr = ast_call_ptr(callee, call.args_vec);
        return builder_emit_call_ptr_slice_store(ctx, cp, addr_reg);
    }
    var resolved_ptr: u64 = name_ptr;
    var resolved_len: u64 = name_len;
    var resolved: *NameInfo = resolve_name(name_ptr, name_len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }

    var args: *Vec<u64> = call.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    var total_regs: u64 = arg_regs.len();

    var ret_type: u64 = TYPE_I64;
    var ret_ptr_depth: u64 = 0;
    var ret_struct_size: u64 = 0;
    var ret_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)call, ctx.symtab);
    if (ret_ti != 0) {
        ret_type = ret_ti.type_kind;
        ret_ptr_depth = ret_ti.ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            ret_struct_size = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
        }
    }

    var info: *SSACallSliceStoreInfo = new SSACallSliceStoreInfo();
    var info_ptr: u64 = (u64)info;
    info.is_ptr = 0;
    info.name_ptr = resolved_ptr;
    info.name_len = resolved_len;
    info.callee_reg = 0;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;

    var call_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL_SLICE_STORE, 0, ssa_operand_const(info_ptr), ssa_operand_reg(addr_reg));
    ssa_inst_append(ctx.cur_block, call_ptr);
    return 0;
}

func builder_emit_method_call(ctx: *BuilderCtx, mc: *AstMethodCall, dst: u64, extra_dst: u64) -> u64 {
    var receiver: u64 = mc.receiver;
    var recv_ti: *TypeInfo = get_expr_type_with_symtab(receiver, ctx.symtab);
    if (recv_ti == 0) { return 0; }
    if (recv_ti.type_kind != TYPE_STRUCT) { return 0; }
    var struct_ptr: u64 = recv_ti.struct_name_ptr;
    var struct_len: u64 = recv_ti.struct_name_len;

    var name_info: *NameInfo = builder_build_method_name(struct_ptr, struct_len, mc.method_ptr, mc.method_len);
    var resolved_ptr: u64 = name_info.ptr;
    var resolved_len: u64 = name_info.len;
    var resolved: *NameInfo = resolve_name(name_info.ptr, name_info.len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }

    var args: *Vec<u64> = mc.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2 + 1);
    var recv_addr: u64 = builder_lvalue_addr(ctx, receiver);
    arg_regs.push(recv_addr);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    var total_regs: u64 = arg_regs.len();

    var ret_type: u64 = TYPE_I64;
    var ret_ptr_depth: u64 = 0;
    var ret_struct_size: u64 = 0;
    var ret_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)mc, ctx.symtab);
    if (ret_ti != 0) {
        ret_type = ret_ti.type_kind;
        ret_ptr_depth = ret_ti.ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            ret_struct_size = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
        }
    }

    var info: *SSACallInfo = new SSACallInfo();
    var info_ptr: u64 = (u64)info;
    info.name_ptr = resolved_ptr;
    info.name_len = resolved_len;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;
    info.ret_struct_size = ret_struct_size;

    var extra_opr2: u64 = 0;
    if (extra_dst != 0) { extra_opr2 = ssa_operand_reg(extra_dst); }
    var call_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL, dst, ssa_operand_const(info_ptr), extra_opr2);
    ssa_inst_append(ctx.cur_block, call_ptr2);
    return dst;
}

func builder_emit_method_call_sret(ctx: *BuilderCtx, mc: *AstMethodCall, addr_reg: u64) -> u64 {
    if (addr_reg == 0) { return 0; }
    var receiver: u64 = mc.receiver;
    var recv_ti: *TypeInfo = get_expr_type_with_symtab(receiver, ctx.symtab);
    if (recv_ti == 0) { return 0; }
    if (recv_ti.type_kind != TYPE_STRUCT) { return 0; }
    var struct_ptr: u64 = recv_ti.struct_name_ptr;
    var struct_len: u64 = recv_ti.struct_name_len;

    var name_info: *NameInfo = builder_build_method_name(struct_ptr, struct_len, mc.method_ptr, mc.method_len);
    var resolved_ptr: u64 = name_info.ptr;
    var resolved_len: u64 = name_info.len;
    var resolved: *NameInfo = resolve_name(name_info.ptr, name_info.len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }

    var args: *Vec<u64> = mc.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2 + 2);
    arg_regs.push(addr_reg);
    var recv_addr: u64 = builder_lvalue_addr(ctx, receiver);
    arg_regs.push(recv_addr);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    var total_regs: u64 = arg_regs.len();

    var ret_type: u64 = TYPE_STRUCT;
    var ret_ptr_depth: u64 = 0;
    var ret_struct_size: u64 = 0;
    var ret_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)mc, ctx.symtab);
    if (ret_ti != 0) {
        ret_type = ret_ti.type_kind;
        ret_ptr_depth = ret_ti.ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            ret_struct_size = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
        }
    }

    var info: *SSACallInfo = new SSACallInfo();
    var info_ptr: u64 = (u64)info;
    info.name_ptr = resolved_ptr;
    info.name_len = resolved_len;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;
    info.ret_struct_size = ret_struct_size;

    var call_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL, 0, ssa_operand_const(info_ptr), 0);
    ssa_inst_append(ctx.cur_block, call_ptr2);
    return 0;
}

func builder_emit_method_call_slice_store(ctx: *BuilderCtx, mc: *AstMethodCall, addr_reg: u64) -> u64 {
    var receiver: u64 = mc.receiver;
    var recv_ti: *TypeInfo = get_expr_type_with_symtab(receiver, ctx.symtab);
    if (recv_ti == 0) { return 0; }
    if (recv_ti.type_kind != TYPE_STRUCT) { return 0; }
    var struct_ptr: u64 = recv_ti.struct_name_ptr;
    var struct_len: u64 = recv_ti.struct_name_len;

    var name_info: *NameInfo = builder_build_method_name(struct_ptr, struct_len, mc.method_ptr, mc.method_len);
    var resolved_ptr: u64 = name_info.ptr;
    var resolved_len: u64 = name_info.len;
    var resolved: *NameInfo = resolve_name(name_info.ptr, name_info.len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }

    var args: *Vec<u64> = mc.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2 + 1);
    var recv_addr: u64 = builder_lvalue_addr(ctx, receiver);
    arg_regs.push(recv_addr);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    var total_regs: u64 = arg_regs.len();

    var ret_type: u64 = TYPE_I64;
    var ret_ptr_depth: u64 = 0;
    var ret_struct_size: u64 = 0;
    var ret_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)mc, ctx.symtab);
    if (ret_ti != 0) {
        ret_type = ret_ti.type_kind;
        ret_ptr_depth = ret_ti.ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            ret_struct_size = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
        }
    }

    var info: *SSACallSliceStoreInfo = new SSACallSliceStoreInfo();
    var info_ptr: u64 = (u64)info;
    info.is_ptr = 0;
    info.name_ptr = resolved_ptr;
    info.name_len = resolved_len;
    info.callee_reg = 0;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;

    var call_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL_SLICE_STORE, 0, ssa_operand_const(info_ptr), ssa_operand_reg(addr_reg));
    ssa_inst_append(ctx.cur_block, call_ptr2);
    return 0;
}

func builder_emit_call_ptr(ctx: *BuilderCtx, cp: *AstCallPtr, dst: u64, extra_dst: u64) -> u64 {
    var args: *Vec<u64> = cp.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    var total_regs: u64 = arg_regs.len();

    var callee: u64 = cp.callee;
    var callee_reg: u64 = 0;
    if (ast_kind(callee) == AST_IDENT) {
        var idn: *AstIdent = (*AstIdent)callee;
        if (compiler_func_exists(idn.name_ptr, idn.name_len) != 0) {
            var resolved_ptr: u64 = idn.name_ptr;
            var resolved_len: u64 = idn.name_len;
            var resolved: *NameInfo = resolve_name(idn.name_ptr, idn.name_len);
            if (resolved != 0) {
                resolved_ptr = resolved.ptr;
                resolved_len = resolved.len;
            }
            callee_reg = builder_new_lea_func(ctx, resolved_ptr, resolved_len);
        } else {
            callee_reg = build_expr(ctx, callee);
        }
    } else {
        callee_reg = build_expr(ctx, callee);
    }

    var ret_type: u64 = TYPE_I64;
    var ret_ptr_depth: u64 = 0;
    var ret_struct_size: u64 = 0;
    var ret_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)cp, ctx.symtab);
    if (ret_ti != 0) {
        ret_type = ret_ti.type_kind;
        ret_ptr_depth = ret_ti.ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            ret_struct_size = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
        }
    }

    var info: *SSACallPtrInfo = new SSACallPtrInfo();
    var info_ptr: u64 = (u64)info;
    info.callee_reg = callee_reg;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;
    info.ret_struct_size = ret_struct_size;

    var extra_opr3: u64 = 0;
    if (extra_dst != 0) { extra_opr3 = ssa_operand_reg(extra_dst); }
    var call_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL_PTR, dst, ssa_operand_const(info_ptr), extra_opr3);
    ssa_inst_append(ctx.cur_block, call_ptr);
    return dst;
}

func builder_emit_call_ptr_sret(ctx: *BuilderCtx, cp: *AstCallPtr, addr_reg: u64) -> u64 {
    if (addr_reg == 0) { return 0; }
    var callee_reg: u64 = build_expr(ctx, cp.callee);
    var args: *Vec<u64> = cp.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2 + 1);
    arg_regs.push(addr_reg);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    var total_regs: u64 = arg_regs.len();

    var ret_type: u64 = TYPE_STRUCT;
    var ret_ptr_depth: u64 = 0;
    var ret_struct_size: u64 = 0;
    var ret_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)cp, ctx.symtab);
    if (ret_ti != 0) {
        ret_type = ret_ti.type_kind;
        ret_ptr_depth = ret_ti.ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            ret_struct_size = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
        }
    }

    var info: *SSACallPtrInfo = new SSACallPtrInfo();
    var info_ptr: u64 = (u64)info;
    info.callee_reg = callee_reg;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;
    info.ret_struct_size = ret_struct_size;

    var call_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL_PTR, 0, ssa_operand_const(info_ptr), 0);
    ssa_inst_append(ctx.cur_block, call_ptr);
    return 0;
}

func builder_emit_call_ptr_slice_store(ctx: *BuilderCtx, cp: *AstCallPtr, addr_reg: u64) -> u64 {
    var args: *Vec<u64> = cp.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    var total_regs: u64 = arg_regs.len();

    var callee: u64 = cp.callee;
    var callee_reg: u64 = 0;
    if (ast_kind(callee) == AST_IDENT) {
        var idn: *AstIdent = (*AstIdent)callee;
        if (compiler_func_exists(idn.name_ptr, idn.name_len) != 0) {
            var resolved_ptr: u64 = idn.name_ptr;
            var resolved_len: u64 = idn.name_len;
            var resolved: *NameInfo = resolve_name(idn.name_ptr, idn.name_len);
            if (resolved != 0) {
                resolved_ptr = resolved.ptr;
                resolved_len = resolved.len;
            }
            callee_reg = builder_new_lea_func(ctx, resolved_ptr, resolved_len);
        } else {
            callee_reg = build_expr(ctx, callee);
        }
    } else {
        callee_reg = build_expr(ctx, callee);
    }

    var ret_type: u64 = TYPE_I64;
    var ret_ptr_depth: u64 = 0;
    var ret_struct_size: u64 = 0;
    var ret_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)cp, ctx.symtab);
    if (ret_ti != 0) {
        ret_type = ret_ti.type_kind;
        ret_ptr_depth = ret_ti.ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            ret_struct_size = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
        }
    }

    var info: *SSACallSliceStoreInfo = new SSACallSliceStoreInfo();
    var info_ptr: u64 = (u64)info;
    info.is_ptr = 1;
    info.name_ptr = 0;
    info.name_len = 0;
    info.callee_reg = callee_reg;
    info.args_vec = arg_regs;
    info.nargs = total_regs;
    info.ret_type = ret_type;
    info.ret_ptr_depth = ret_ptr_depth;

    var call_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CALL_SLICE_STORE, 0, ssa_operand_const(info_ptr), ssa_operand_reg(addr_reg));
    ssa_inst_append(ctx.cur_block, call_ptr);
    return 0;
}

func builder_type_size_from_expr(ctx: *BuilderCtx, node: u64) -> u64 {
    var ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)node, ctx.symtab);
    if (ti == 0) { return 8; }
    return sizeof_type(ti.type_kind, ti.ptr_depth, ti.struct_name_ptr, ti.struct_name_len);
}

func builder_lvalue_addr_ident(ctx: *BuilderCtx, node: u64) -> u64 {
    var idn: *AstIdent = (*AstIdent)node;
    var offset: u64 = symtab_find(ctx.symtab, idn.name_ptr, idn.name_len);
    if (offset != 0) {
        return builder_new_lea_local(ctx, offset);
    }
    if (compiler_func_exists(idn.name_ptr, idn.name_len) != 0) {
        var resolved_ptr2: u64 = idn.name_ptr;
        var resolved_len2: u64 = idn.name_len;
        var resolved2: *NameInfo = resolve_name(idn.name_ptr, idn.name_len);
        if (resolved2 != 0) {
            resolved_ptr2 = resolved2.ptr;
            resolved_len2 = resolved2.len;
        }
        return builder_new_lea_func(ctx, resolved_ptr2, resolved_len2);
    }
    var resolved_ptr: u64 = idn.name_ptr;
    var resolved_len: u64 = idn.name_len;
    var resolved: *NameInfo = resolve_name(idn.name_ptr, idn.name_len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }
    return builder_new_lea_global(ctx, resolved_ptr, resolved_len);
}

func builder_lvalue_addr_member(ctx: *BuilderCtx, node: u64) -> u64 {
    var m: *AstMemberAccess = (*AstMemberAccess)node;
    var obj: u64 = m.object;
    var ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)obj, ctx.symtab);
    if (ti == 0) { return 0; }
    var base_addr: u64 = 0;
    if (ti.ptr_depth > 0) {
        base_addr = build_expr(ctx, obj);
    } else {
        base_addr = builder_lvalue_addr(ctx, obj);
    }
    var struct_def: *AstStructDef = ti.struct_def;
    if (struct_def == 0) { return base_addr; }
    var field_offset: u64 = 0;
    var field_desc: *FieldDesc = 0;
    var found: u64 = struct_find_field_desc_scoped(struct_def, m.parent_ptr, m.parent_len, m.member_ptr, m.member_len, &field_offset, &field_desc);
    if (found == 0 || field_offset == 0) { return base_addr; }
    var off_reg: u64 = build_const(ctx, field_offset);
    var out_reg: u64 = builder_new_reg(ctx);
    var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, out_reg, ssa_operand_reg(base_addr), ssa_operand_reg(off_reg));
    ssa_inst_append(ctx.cur_block, add_ptr);
    return out_reg;
}

func builder_lvalue_addr_deref(ctx: *BuilderCtx, node: u64) -> u64 {
    var d: *AstDeref = (*AstDeref)node;
    var addr_reg: u64 = build_expr(ctx, d.operand);
    var op_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)d.operand, ctx.symtab);
    if (op_ti != 0 && op_ti.is_tagged == 1) {
        addr_reg = builder_mask_tagged_ptr(ctx, addr_reg);
    }
    return addr_reg;
}

func builder_lvalue_addr_scale_index(ctx: *BuilderCtx, idx_reg: u64, elem_size: u64) -> u64 {
    if (elem_size <= 1) { return idx_reg; }
    var size_reg: u64 = build_const(ctx, elem_size);
    var mul_reg: u64 = builder_new_reg(ctx);
    var mul_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_MUL, mul_reg, ssa_operand_reg(idx_reg), ssa_operand_reg(size_reg));
    ssa_inst_append(ctx.cur_block, mul_ptr);
    return mul_reg;
}

func builder_lvalue_addr_index(ctx: *BuilderCtx, node: u64) -> u64 {
    var idx: *AstIndex = (*AstIndex)node;
    var base: u64 = idx.base;
    var bt: *TypeInfo = get_expr_type_with_symtab((*AstNode)base, ctx.symtab);
    if (bt == 0) { return 0; }

    var elem_size: u64 = get_pointee_size(bt.type_kind, bt.ptr_depth);
    if (bt.ptr_depth == 1 && bt.type_kind == TYPE_STRUCT) {
        elem_size = sizeof_type(bt.type_kind, 0, bt.struct_name_ptr, bt.struct_name_len);
    }
    if (bt.type_kind == TYPE_ARRAY && bt.ptr_depth == 0) {
        elem_size = sizeof_type(bt.elem_type_kind, bt.elem_ptr_depth, bt.struct_name_ptr, bt.struct_name_len);
        var base_addr: u64 = builder_lvalue_addr(ctx, base);
        var idx_reg: u64 = build_expr(ctx, idx.index);
        idx_reg = builder_lvalue_addr_scale_index(ctx, idx_reg, elem_size);
        var out_reg2: u64 = builder_new_reg(ctx);
        var add_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, out_reg2, ssa_operand_reg(base_addr), ssa_operand_reg(idx_reg));
        ssa_inst_append(ctx.cur_block, add_ptr2);
        return out_reg2;
    }

    var base_ptr: u64 = build_expr(ctx, base);
    if (bt.ptr_depth > 0 && bt.is_tagged == 1) {
        base_ptr = builder_mask_tagged_ptr(ctx, base_ptr);
    }
    if (bt.type_kind == TYPE_SLICE && bt.ptr_depth == 0) {
        var addr_reg: u64 = builder_lvalue_addr(ctx, base);
        base_ptr = builder_load_by_size(ctx, addr_reg, 8);
        elem_size = sizeof_type(bt.elem_type_kind, bt.elem_ptr_depth, bt.struct_name_ptr, bt.struct_name_len);
    }

    var idx_reg2: u64 = build_expr(ctx, idx.index);
    idx_reg2 = builder_lvalue_addr_scale_index(ctx, idx_reg2, elem_size);
    var out_reg3: u64 = builder_new_reg(ctx);
    var add_ptr3: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, out_reg3, ssa_operand_reg(base_ptr), ssa_operand_reg(idx_reg2));
    ssa_inst_append(ctx.cur_block, add_ptr3);
    return out_reg3;
}

func builder_lvalue_addr(ctx: *BuilderCtx, node: u64) -> u64 {
    var k: u64 = ast_kind(node);
    if (k == AST_IDENT) { return builder_lvalue_addr_ident(ctx, node); }
    if (k == AST_MEMBER_ACCESS) { return builder_lvalue_addr_member(ctx, node); }
    if (k == AST_DEREF || k == AST_DEREF8) { return builder_lvalue_addr_deref(ctx, node); }
    if (k == AST_INDEX) { return builder_lvalue_addr_index(ctx, node); }
    return 0;
}

// ============================================
// Builder Helpers
// ============================================

func builder_block_is_terminated(block: *SSABlock) -> u64 {
    if (block == 0) { return true; }
    var tail: *SSAInstruction = block.inst_tail;
    if (tail == 0) { return false; }
    var op: u64 = ssa_inst_get_op(tail);
    if (op == SSA_OP_JMP || op == SSA_OP_BR || op == SSA_OP_RET || op == SSA_OP_RET_SLICE_HEAP) { return true; }
    return false;
}

func builder_block_is_reachable(block: *SSABlock) -> u64 {
    if (block == 0) { return false; }
    if (ssa_slice_len(block.preds) > 0) { return true; }
    return false;
}

func builder_stmt_or_expr(ctx: *BuilderCtx, node: u64) -> u64 {
    if (node == 0) { return 0; }
    var k: u64 = ast_kind(node);
    if (k == AST_VAR_DECL || k == AST_CONST_DECL || k == AST_ASSIGN || k == AST_EXPR_STMT) {
        build_stmt(ctx, node);
        return 0;
    }
    build_expr(ctx, node);
    return 0;
}

func builder_binop_to_ssa_op(op: u64, use_signed: u64) -> u64 {
    if (op == TOKEN_PLUS) { return SSA_OP_ADD; }
    if (op == TOKEN_MINUS) { return SSA_OP_SUB; }
    if (op == TOKEN_STAR) { return SSA_OP_MUL; }
    if (op == TOKEN_SLASH) {
        if (use_signed != 0) { return SSA_OP_DIV; }
        return SSA_OP_UDIV;
    }
    if (op == TOKEN_PERCENT) {
        if (use_signed != 0) { return SSA_OP_MOD; }
        return SSA_OP_UMOD;
    }
    if (op == TOKEN_AMPERSAND) { return SSA_OP_AND; }
    if (op == TOKEN_PIPE) { return SSA_OP_OR; }
    if (op == TOKEN_CARET) { return SSA_OP_XOR; }
    if (op == TOKEN_LSHIFT) { return SSA_OP_SHL; }
    if (op == TOKEN_RSHIFT) {
        if (use_signed != 0) { return SSA_OP_SAR; }
        return SSA_OP_SHR;
    }
    if (op == TOKEN_EQEQ) { return SSA_OP_EQ; }
    if (op == TOKEN_BANGEQ) { return SSA_OP_NE; }
    if (op == TOKEN_LT) {
        if (use_signed != 0) { return SSA_OP_LT; }
        return SSA_OP_ULT;
    }
    if (op == TOKEN_GT) {
        if (use_signed != 0) { return SSA_OP_GT; }
        return SSA_OP_UGT;
    }
    if (op == TOKEN_LTEQ) {
        if (use_signed != 0) { return SSA_OP_LE; }
        return SSA_OP_ULE;
    }
    if (op == TOKEN_GTEQ) {
        if (use_signed != 0) { return SSA_OP_GE; }
        return SSA_OP_UGE;
    }
    return SSA_OP_NOP;
}

func builder_is_f64_expr(ctx: *BuilderCtx, node: u64) -> u64 {
    if (node == 0) { return false; }
    var ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)node, ctx.symtab);
    if (ti == 0) { return false; }
    if (ti.ptr_depth != 0) { return false; }
    if (ti.type_kind == TYPE_F64) { return true; }
    return false;
}

func builder_is_signed_i64_expr(ctx: *BuilderCtx, node: u64) -> u64 {
    if (node == 0) { return false; }
    var ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)node, ctx.symtab);
    if (ti == 0) { return false; }
    if (ti.ptr_depth != 0) { return false; }
    if (ti.type_kind == TYPE_I64) { return true; }
    return false;
}

func build_const(ctx: *BuilderCtx, val: u64) -> u64 {
    var reg_id: u64 = builder_new_reg(ctx);
    var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_CONST, reg_id, ssa_operand_const(val), 0);
    ssa_inst_append(ctx.cur_block, inst_ptr);
    return reg_id;
}

func build_bool_from_reg(ctx: *BuilderCtx, reg: u64) -> u64 {
    var zero_reg: u64 = build_const(ctx, 0);
    var dst: u64 = builder_new_reg(ctx);
    var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_NE, dst, ssa_operand_reg(reg), ssa_operand_reg(zero_reg));
    ssa_inst_append(ctx.cur_block, inst_ptr);
    return dst;
}

func build_short_circuit(ctx: *BuilderCtx, op: u64, left: u64, right: u64) -> u64 {
    var entry_bb: *SSABlock = ctx.cur_block;
    var left_reg: u64 = build_expr(ctx, left);

    var right_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var merge_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);

    var entry_val: u64 = 0;
    if (op == TOKEN_ANDAND) {
        entry_val = build_const(ctx, 0);
        var br_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_BR, ssa_operand_const(merge_bb.id), ssa_operand_reg(left_reg), ssa_operand_const(right_bb.id));
        ssa_inst_append(ctx.cur_block, br_ptr);
        ssa_add_edge(ctx.cur_block, right_bb);
        ssa_add_edge(ctx.cur_block, merge_bb);
    } else {
        entry_val = build_const(ctx, 1);
        var br_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_BR, ssa_operand_const(right_bb.id), ssa_operand_reg(left_reg), ssa_operand_const(merge_bb.id));
        ssa_inst_append(ctx.cur_block, br_ptr2);
        ssa_add_edge(ctx.cur_block, merge_bb);
        ssa_add_edge(ctx.cur_block, right_bb);
    }

    builder_set_block(ctx, right_bb);
    var right_reg: u64 = build_expr(ctx, right);
    var right_bool: u64 = build_bool_from_reg(ctx, right_reg);
    var jmp_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(merge_bb.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr);
    ssa_add_edge(ctx.cur_block, merge_bb);

    builder_set_block(ctx, merge_bb);
    var head: *SSAPhiArg = ssa_phi_arg_new(entry_val, entry_bb.id);
    head = ssa_phi_arg_append(head, right_bool, right_bb.id);
    var dest: u64 = builder_new_reg(ctx);
    var phi_ptr: *SSAInstruction = ssa_phi_new(ctx.ssa_ctx, dest, head);
    ssa_phi_append(merge_bb, phi_ptr);
    return dest;
}

func builder_scale_ptr_arith(ctx: *BuilderCtx, left_expr: u64, op: u64, rhs_reg: u64) -> u64 {
    if (op != TOKEN_PLUS && op != TOKEN_MINUS) { return rhs_reg; }
    var left_ti: *TypeInfo = get_expr_type_with_symtab(left_expr, ctx.symtab);
    if (left_ti == 0) { return rhs_reg; }
    if (left_ti.ptr_depth == 0) { return rhs_reg; }
    var elem_size: u64 = get_pointee_size(left_ti.type_kind, left_ti.ptr_depth);
    if (elem_size <= 1) { return rhs_reg; }
    var size_reg: u64 = build_const(ctx, elem_size);
    var scaled_reg: u64 = builder_new_reg(ctx);
    var mul_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_MUL, scaled_reg, ssa_operand_reg(rhs_reg), ssa_operand_reg(size_reg));
    ssa_inst_append(ctx.cur_block, mul_ptr);
    return scaled_reg;
}

func builder_try_resolve_meta_or_panic(ctx: *BuilderCtx, operand: u64, ret_type: u64, ret_ptr_depth: u64, ret_struct_name_ptr: u64, ret_struct_name_len: u64, opt_ti_out: *u64, struct_def_out: *u64, check_ptr_out: *u64, check_len_out: *u64, value_ptr_out: *u64, value_len_out: *u64, value_desc_out: *u64) -> u64 {
    var opt_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)operand, ctx.symtab);
    if (opt_ti == 0) {
        emit_stderr("[ERROR] try operand type not found\n");
        panic("SSA build error");
    }

    var try_kind: u64 = compiler_try_kind_from_typeinfo(opt_ti);
    if (try_kind == COMPILER_TRY_KIND_INVALID) {
        if (opt_ti.type_kind != TYPE_STRUCT || opt_ti.ptr_depth != 0) {
            emit_stderr("[ERROR] try operator requires Option/Result value\n");
        } else {
            emit_stderr("[ERROR] try operator requires Option or Result\n");
        }
        panic("SSA build error");
    }

    if (compiler_try_return_matches_type(opt_ti, ret_type, ret_ptr_depth, ret_struct_name_ptr, ret_struct_name_len) == 0) {
        if (ret_type != TYPE_STRUCT || ret_ptr_depth != 0) {
            emit_stderr("[ERROR] try operator requires Option/Result return type\n");
        } else {
            emit_stderr("[ERROR] try operand type must match function return type\n");
        }
        panic("SSA build error");
    }

    var struct_def: *AstStructDef = compiler_try_resolve_struct_def(opt_ti);
    if (struct_def == 0) {
        emit_stderr("[ERROR] try operand struct definition not found\n");
        panic("SSA build error");
    }

    var check_ptr: u64 = 0;
    var check_len: u64 = 0;
    var value_ptr: u64 = 0;
    var value_len: u64 = 0;
    if (compiler_try_field_names(try_kind, &check_ptr, &check_len, &value_ptr, &value_len) == 0) {
        emit_stderr("[ERROR] invalid try kind\n");
        panic("SSA build error");
    }

    var value_desc: *FieldDesc = get_field_desc(struct_def, value_ptr, value_len);
    if (value_desc == 0) {
        emit_stderr("[ERROR] try value field not found\n");
        panic("SSA build error");
    }

    *opt_ti_out = (u64)opt_ti;
    *struct_def_out = (u64)struct_def;
    *check_ptr_out = check_ptr;
    *check_len_out = check_len;
    *value_ptr_out = value_ptr;
    *value_len_out = value_len;
    *value_desc_out = (u64)value_desc;
    return 1;
}

func builder_try_addr_with_offset(ctx: *BuilderCtx, base_addr: u64, field_off: u64) -> u64 {
    if (field_off == 0) { return base_addr; }
    var off_reg: u64 = build_const(ctx, field_off);
    var addr: u64 = builder_new_reg(ctx);
    var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr, ssa_operand_reg(base_addr), ssa_operand_reg(off_reg));
    ssa_inst_append(ctx.cur_block, add_ptr);
    return addr;
}

func builder_try_materialize_operand(ctx: *BuilderCtx, operand: u64, struct_size: u64, tmp_addr: u64) -> u64 {
    var op_kind: u64 = ast_kind(operand);
    if (struct_size > 16) {
        if (op_kind == AST_CALL) {
            builder_emit_call_sret(ctx, (*AstCall)operand, tmp_addr);
            return 1;
        }
        if (op_kind == AST_METHOD_CALL) {
            builder_emit_method_call_sret(ctx, (*AstMethodCall)operand, tmp_addr);
            return 1;
        }
        if (op_kind == AST_CALL_PTR) {
            builder_emit_call_ptr_sret(ctx, (*AstCallPtr)operand, tmp_addr);
            return 1;
        }
        var src_addr: u64 = builder_lvalue_addr(ctx, operand);
        if (src_addr == 0) { return 0; }
        builder_struct_copy(ctx, tmp_addr, src_addr, struct_size);
        return 1;
    }

    if (op_kind == AST_CALL || op_kind == AST_METHOD_CALL || op_kind == AST_CALL_PTR) {
        var lo_reg: u64 = builder_new_reg(ctx);
        var hi_reg: u64 = 0;
        if (struct_size > 8) { hi_reg = builder_new_reg(ctx); }
        if (op_kind == AST_CALL) {
            builder_emit_call(ctx, (*AstCall)operand, lo_reg, hi_reg);
        } else if (op_kind == AST_METHOD_CALL) {
            builder_emit_method_call(ctx, (*AstMethodCall)operand, lo_reg, hi_reg);
        } else {
            builder_emit_call_ptr(ctx, (*AstCallPtr)operand, lo_reg, hi_reg);
        }
        builder_store_by_size(ctx, tmp_addr, lo_reg, 8);
        if (hi_reg != 0) {
            var addr2: u64 = builder_try_addr_with_offset(ctx, tmp_addr, 8);
            var tail_size: u64 = struct_size - 8;
            if (tail_size > 8) { tail_size = 8; }
            builder_store_by_size(ctx, addr2, hi_reg, tail_size);
        }
        return 1;
    }

    var src_addr2: u64 = builder_lvalue_addr(ctx, operand);
    if (src_addr2 == 0) { return 0; }
    builder_struct_copy(ctx, tmp_addr, src_addr2, struct_size);
    return 1;
}

func builder_try_emit_failure_return(ctx: *BuilderCtx, tmp_addr: u64, ret_struct_name_ptr: u64, ret_struct_name_len: u64) -> u64 {
    var ret_struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, ret_struct_name_ptr, ret_struct_name_len);
    if (ret_struct_size > 16) {
        if (ctx.sret_addr_reg == 0) { return 0; }
        builder_struct_copy(ctx, ctx.sret_addr_reg, tmp_addr, ret_struct_size);
        var ret_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, 0, 0);
        ssa_inst_append(ctx.cur_block, ret_ptr);
        return 0;
    }
    builder_emit_return_struct_from_addr_reg(ctx, tmp_addr, ret_struct_size);
    return 0;
}

func builder_try_load_value_or_panic(ctx: *BuilderCtx, value_addr: u64, value_size: u64) -> u64 {
    if (value_size <= 8) {
        return builder_load_by_size(ctx, value_addr, value_size);
    }
    if (value_size <= 16) {
        if (ctx.debug_mode != 0) {
            emit("[DEBUG] try value >8 bytes: returning lo only in SSA expr\n");
        }
        return builder_load_by_size(ctx, value_addr, 8);
    }
    emit_stderr("[ERROR] try value size too large for expression result\n");
    panic("SSA build error");
}

func builder_build_try_expr(ctx: *BuilderCtx, node: u64) -> u64 {
    var tr: *AstTry = (*AstTry)node;
    var operand: u64 = tr.operand;

    var ret_type: u64 = emitter_get_ret_type();
    var ret_ptr_depth: u64 = emitter_get_ret_ptr_depth();
    var ret_struct_name_ptr: u64 = emitter_get_ret_struct_name_ptr();
    var ret_struct_name_len: u64 = emitter_get_ret_struct_name_len();
    var opt_ti_raw: u64 = 0;
    var struct_def_raw: u64 = 0;
    var value_desc_raw: u64 = 0;

    var check_ptr: u64 = 0;
    var check_len: u64 = 0;
    var value_ptr: u64 = 0;
    var value_len: u64 = 0;
    builder_try_resolve_meta_or_panic(
        ctx,
        operand,
        ret_type,
        ret_ptr_depth,
        ret_struct_name_ptr,
        ret_struct_name_len,
        &opt_ti_raw,
        &struct_def_raw,
        &check_ptr,
        &check_len,
        &value_ptr,
        &value_len,
        &value_desc_raw
    );

    var opt_ti: *TypeInfo = (*TypeInfo)opt_ti_raw;
    var struct_def: *AstStructDef = (*AstStructDef)struct_def_raw;
    var value_desc: *FieldDesc = (*FieldDesc)value_desc_raw;
    var check_off: u64 = get_field_offset(struct_def, check_ptr, check_len);
    var value_off: u64 = get_field_offset(struct_def, value_ptr, value_len);

    var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, opt_ti.struct_name_ptr, opt_ti.struct_name_len);
    var tmp_offset: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, struct_size);
    var tmp_addr: u64 = builder_new_lea_local(ctx, tmp_offset);
    if (builder_try_materialize_operand(ctx, operand, struct_size, tmp_addr) == 0) { return 0; }

    var check_addr: u64 = builder_try_addr_with_offset(ctx, tmp_addr, check_off);
    var check_desc: *FieldDesc = get_field_desc(struct_def, check_ptr, check_len);
    var check_size: u64 = 8;
    if (check_desc != 0) { check_size = sizeof_field_desc(check_desc); }
    var check_reg: u64 = builder_load_by_size(ctx, check_addr, check_size);
    var cond_reg: u64 = build_bool_from_reg(ctx, check_reg);

    var ok_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var ret_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);

    var br_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_BR, ssa_operand_const(ok_bb.id), ssa_operand_reg(cond_reg), ssa_operand_const(ret_bb.id));
    ssa_inst_append(ctx.cur_block, br_ptr);
    ssa_add_edge(ctx.cur_block, ok_bb);
    ssa_add_edge(ctx.cur_block, ret_bb);

    builder_set_block(ctx, ret_bb);
    builder_try_emit_failure_return(ctx, tmp_addr, ret_struct_name_ptr, ret_struct_name_len);

    builder_set_block(ctx, ok_bb);
    var value_addr: u64 = builder_try_addr_with_offset(ctx, tmp_addr, value_off);
    var value_size: u64 = sizeof_field_desc(value_desc);
    return builder_try_load_value_or_panic(ctx, value_addr, value_size);
}

func builder_expr_new(ctx: *BuilderCtx, node: u64) -> u64 {
    var nw: *AstNew = (*AstNew)node;
    if (nw.array_len_is_param != 0) {
        emit_stderr("[ERROR] new with unresolved generic array length\n");
        panic("SSA build error");
    }

    var size: u64 = 0;
    if (nw.type_kind == TYPE_ARRAY) {
        var elem_size: u64 = sizeof_type(nw.elem_type_kind, nw.elem_ptr_depth, nw.struct_name_ptr, nw.struct_name_len);
        size = elem_size * nw.array_len;
    } else if (nw.type_kind == TYPE_SLICE) {
        size = 16;
    } else {
        size = sizeof_type(nw.type_kind, nw.ptr_depth, nw.struct_name_ptr, nw.struct_name_len);
    }

    var malloc_ptr: u64 = (u64)"malloc";
    var malloc_len: u64 = 6;
    var malloc_res: *NameInfo = resolve_name(malloc_ptr, malloc_len);
    if (malloc_res != 0) {
        malloc_ptr = malloc_res.ptr;
        malloc_len = malloc_res.len;
    }

    var size_reg: u64 = build_const(ctx, size);
    var malloc_args: *Vec<u64> = new Vec<u64>(1);
    malloc_args.push(size_reg);
    var heap_reg: u64 = builder_new_reg(ctx);
    builder_emit_call_name_raw(ctx, malloc_ptr, malloc_len, malloc_args, heap_reg, 0, TYPE_I64, 0, 0);

    var memset_ptr: u64 = (u64)"memset";
    var memset_len: u64 = 6;
    var memset_res: *NameInfo = resolve_name(memset_ptr, memset_len);
    if (memset_res != 0) {
        memset_ptr = memset_res.ptr;
        memset_len = memset_res.len;
    }
    var memset_args: *Vec<u64> = new Vec<u64>(3);
    var zero_reg: u64 = build_const(ctx, 0);
    memset_args.push(heap_reg);
    memset_args.push(zero_reg);
    memset_args.push(size_reg);
    builder_emit_call_name_raw(ctx, memset_ptr, memset_len, memset_args, 0, 0, TYPE_I64, 0, 0);

    if (nw.type_kind == TYPE_STRUCT) {
        builder_emit_trait_vptr_init_at_addr(ctx, heap_reg, nw.struct_name_ptr, nw.struct_name_len);
    }

    if (nw.literal_expr != 0) {
        if (ast_kind(nw.literal_expr) == AST_STRUCT_LITERAL) {
            var lit_new: *AstStructLiteral = (*AstStructLiteral)nw.literal_expr;
            builder_struct_literal_init(ctx, lit_new.struct_def, lit_new.values_vec, heap_reg);
        }
    }

    if (nw.ctor_args_vec != 0) {
        if (nw.type_kind != TYPE_STRUCT) {
            emit_stderr("[ERROR] new constructor call requires struct type\n");
            panic("SSA build error");
        }
        var name_info: *PtrLen = builder_resolve_constructor_name(nw.struct_name_ptr, nw.struct_name_len);
        if (name_info == 0) { return heap_reg; }
        var args: *Vec<*AstNode> = nw.ctor_args_vec;
        var nargs: u64 = 0;
        if (args != 0) { nargs = args.len(); }
        var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2 + 1);
        arg_regs.push(heap_reg);
        for (var i: u64 = 0; i < nargs; i++) {
            var arg: u64 = args.get(i);
            builder_append_call_arg(ctx, arg_regs, arg);
        }
        builder_emit_call_name_raw(ctx, name_info.ptr, name_info.len, arg_regs, 0, 0, TYPE_VOID, 0, 0);
    }

    return heap_reg;
}

func builder_expr_ident(ctx: *BuilderCtx, node: u64) -> u64 {
    var idn: *AstIdent = (*AstIdent)node;
    var offset: u64 = symtab_find(ctx.symtab, idn.name_ptr, idn.name_len);
    if (offset != 0) {
        var var_ti: *TypeInfo = symtab_get_type(ctx.symtab, idn.name_ptr, idn.name_len);
        if (var_ti != 0) {
            if (var_ti.ptr_depth == 0) {
                if (var_ti.type_kind == TYPE_ARRAY || var_ti.array_len != 0) {
                    return builder_new_lea_local(ctx, offset);
                }
            }
        }
        if (builder_is_addr_taken(ctx, idn.name_ptr, idn.name_len) != 0) {
            var addr_reg: u64 = builder_new_lea_local(ctx, offset);
            var size: u64 = builder_type_size_from_expr(ctx, node);
            return builder_load_by_size(ctx, addr_reg, size);
        }
        var var_id: u64 = builder_get_var_id(ctx, idn.name_ptr, idn.name_len);
        var reg_id: u64 = builder_new_reg(ctx);
        var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_LOAD, reg_id, ssa_operand_const(var_id), 0);
        ssa_inst_append(ctx.cur_block, inst_ptr);
        return reg_id;
    }
    var const_encoded: u64 = builder_get_const(ctx, idn.name_ptr, idn.name_len);
    if (const_encoded != 0) {
        return build_const(ctx, const_encoded - 1);
    }
    var resolved_ptr: u64 = idn.name_ptr;
    var resolved_len: u64 = idn.name_len;
    var resolved: *NameInfo = resolve_name(idn.name_ptr, idn.name_len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }
    var c_result: u64 = compiler_find_const(resolved_ptr, resolved_len);
    var c: *ConstResult = (*ConstResult)c_result;
    if (c.found != 0) {
        return build_const(ctx, c.value);
    }
    var addr_reg2: u64 = builder_lvalue_addr(ctx, node);
    var size2: u64 = builder_type_size_from_expr(ctx, node);
    return builder_load_by_size(ctx, addr_reg2, size2);
}

func builder_expr_binary(ctx: *BuilderCtx, node: u64) -> u64 {
    var bin: *AstBinary = (*AstBinary)node;
    if (bin.op == TOKEN_ANDAND || bin.op == TOKEN_OROR) {
        return build_short_circuit(ctx, bin.op, bin.left, bin.right);
    }
    var l_is_f: u64 = builder_is_f64_expr(ctx, bin.left);
    var r_is_f: u64 = builder_is_f64_expr(ctx, bin.right);
    if (l_is_f != r_is_f) {
        emit_stderr("[ERROR] Mixed float/integer binary operation is not supported\n");
        ctx.build_failed = 1;
        return build_const(ctx, 0);
    }
    var lhs_reg: u64 = build_expr(ctx, bin.left);
    var rhs_reg: u64 = build_expr(ctx, bin.right);
    if (l_is_f != 0) {
        var fop: u64 = SSA_OP_NOP;
        if (bin.op == TOKEN_PLUS) { fop = SSA_OP_FADD; }
        else if (bin.op == TOKEN_MINUS) { fop = SSA_OP_FSUB; }
        else if (bin.op == TOKEN_STAR) { fop = SSA_OP_FMUL; }
        else if (bin.op == TOKEN_SLASH) { fop = SSA_OP_FDIV; }
        else if (bin.op == TOKEN_EQEQ) { fop = SSA_OP_FEQ; }
        else if (bin.op == TOKEN_BANGEQ) { fop = SSA_OP_FNE; }
        else if (bin.op == TOKEN_LT) { fop = SSA_OP_FLT; }
        else if (bin.op == TOKEN_GT) { fop = SSA_OP_FGT; }
        else if (bin.op == TOKEN_LTEQ) { fop = SSA_OP_FLE; }
        else if (bin.op == TOKEN_GTEQ) { fop = SSA_OP_FGE; }
        if (fop == SSA_OP_NOP) {
            emit_stderr("[ERROR] Unsupported float binary operator in SSA builder\n");
            ctx.build_failed = 1;
            return build_const(ctx, 0);
        }
        var freg: u64 = builder_new_reg(ctx);
        var finst: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, fop, freg, ssa_operand_reg(lhs_reg), ssa_operand_reg(rhs_reg));
        ssa_inst_append(ctx.cur_block, finst);
        return freg;
    }
    rhs_reg = builder_scale_ptr_arith(ctx, bin.left, bin.op, rhs_reg);
    var use_signed: u64 = 0;
    if (builder_is_signed_i64_expr(ctx, bin.left) != 0) { use_signed = 1; }
    var op: u64 = builder_binop_to_ssa_op(bin.op, use_signed);
    if (op == SSA_OP_NOP) {
        return build_const(ctx, 0);
    }
    var reg_id2: u64 = builder_new_reg(ctx);
    var inst_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, op, reg_id2, ssa_operand_reg(lhs_reg), ssa_operand_reg(rhs_reg));
    ssa_inst_append(ctx.cur_block, inst_ptr2);
    return reg_id2;
}

func builder_expr_unary(ctx: *BuilderCtx, node: u64) -> u64 {
    var un: *AstUnary = (*AstUnary)node;
    var op: u64 = un.op;
    if (op == TOKEN_MINUS && un.operand != 0 && ast_kind(un.operand) == AST_LITERAL) {
        var lit: *AstLiteral = (*AstLiteral)un.operand;
        return build_const(ctx, 0 - lit.value);
    }
    var val_reg: u64 = build_expr(ctx, un.operand);

    if (op == TOKEN_MINUS && builder_is_f64_expr(ctx, un.operand) != 0) {
        var dstf: u64 = builder_new_reg(ctx);
        var instf: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_FNEG, dstf, ssa_operand_reg(val_reg), 0);
        ssa_inst_append(ctx.cur_block, instf);
        return dstf;
    }

    if (op == TOKEN_MINUS) {
        var zero_reg: u64 = build_const(ctx, 0);
        var dst: u64 = builder_new_reg(ctx);
        var inst_ptr3: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_SUB, dst, ssa_operand_reg(zero_reg), ssa_operand_reg(val_reg));
        ssa_inst_append(ctx.cur_block, inst_ptr3);
        return dst;
    }

    if (op == TOKEN_BANG) {
        if (builder_is_f64_expr(ctx, un.operand) != 0) {
            emit_stderr("[ERROR] '!' on float is not supported in SSA builder\n");
            ctx.build_failed = 1;
            return build_const(ctx, 0);
        }
        var zero_reg2: u64 = build_const(ctx, 0);
        var dst2: u64 = builder_new_reg(ctx);
        var inst_ptr4: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_EQ, dst2, ssa_operand_reg(val_reg), ssa_operand_reg(zero_reg2));
        ssa_inst_append(ctx.cur_block, inst_ptr4);
        return dst2;
    }

    if (op == TOKEN_TILDE) {
        if (builder_is_f64_expr(ctx, un.operand) != 0) {
            emit_stderr("[ERROR] '~' on float is not supported in SSA builder\n");
            ctx.build_failed = 1;
            return build_const(ctx, 0);
        }
        var all_ones_reg: u64 = build_const(ctx, -1);
        var dst3: u64 = builder_new_reg(ctx);
        var inst_ptr5: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_XOR, dst3, ssa_operand_reg(val_reg), ssa_operand_reg(all_ones_reg));
        ssa_inst_append(ctx.cur_block, inst_ptr5);
        return dst3;
    }

    return val_reg;
}

func builder_safe_member_receiver_type(ctx: *BuilderCtx, obj_safe: u64) -> *TypeInfo {
    var ot: *TypeInfo = get_expr_type_with_symtab((*AstNode)obj_safe, ctx.symtab);
    if (ot == 0) {
        emit_stderr("[ERROR] Safe member access type not found\n");
        return 0;
    }
    if (ot.ptr_depth == 0) {
        emit_stderr("[ERROR] Safe member access requires pointer receiver\n");
        return 0;
    }
    if (ot.type_kind != TYPE_STRUCT) {
        emit_stderr("[ERROR] Safe member access requires struct pointer\n");
        return 0;
    }
    return ot;
}

func builder_safe_member_tagged_value(ctx: *BuilderCtx, m_safe: *AstMemberAccess, obj_reg: u64, ot: *TypeInfo) -> u64 {
    var layout_info: *AstStructDef = get_struct_def(ot.tag_layout_ptr, ot.tag_layout_len);
    if (layout_info == 0) {
        emit("[ERROR] Tagged layout struct not found\n");
        panic("SSA build error");
    }
    var packed_flag: u64 = layout_info.is_packed;
    if (packed_flag == 0) {
        emit("[ERROR] Tagged layout must be packed struct\n");
        panic("SSA build error");
    }
    var total_bits: u64 = builder_get_packed_layout_total_bits(layout_info);
    var field_offset: u64 = builder_get_packed_field_bit_offset(layout_info, m_safe.member_ptr, m_safe.member_len);
    var field_width: u64 = builder_get_packed_field_bit_width(layout_info, m_safe.member_ptr, m_safe.member_len);
    var start_bit: u64 = 64 - total_bits;
    var shift_bits: u64 = start_bit + field_offset;
    var ok_val: u64 = builder_shift_right(ctx, obj_reg, shift_bits);
    ok_val = builder_mask_low_bits(ctx, ok_val, field_width);
    return ok_val;
}

func builder_safe_member_struct_value(ctx: *BuilderCtx, m_safe: *AstMemberAccess, obj_reg: u64, ot: *TypeInfo) -> u64 {
    var struct_def2: *AstStructDef = ot.struct_def;
    if (struct_def2 == 0) {
        struct_def2 = get_struct_def(ot.struct_name_ptr, ot.struct_name_len);
    }
    if (struct_def2 == 0) {
        emit("[ERROR] Safe member access struct definition not found\n");
        panic("SSA build error");
    }
    var field_offset2: u64 = 0;
    var field_desc: *FieldDesc = 0;
    var found2: u64 = struct_find_field_desc_scoped(struct_def2, m_safe.parent_ptr, m_safe.parent_len, m_safe.member_ptr, m_safe.member_len, &field_offset2, &field_desc);
    if (found2 == 0 || field_desc == 0) { return 0; }
    var fd: *FieldDesc = field_desc;
    if (fd.type_kind == TYPE_STRUCT && fd.ptr_depth == 0) {
        emit_stderr("[ERROR] Safe member access cannot return struct by value\n");
        return 0;
    }
    if (fd.type_kind == TYPE_ARRAY) {
        emit_stderr("[ERROR] Safe member access cannot return array by value\n");
        return 0;
    }
    var field_addr: u64 = obj_reg;
    if (field_offset2 != 0) {
        var off_reg3: u64 = build_const(ctx, field_offset2);
        var addr5: u64 = builder_new_reg(ctx);
        var add_ptr4: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr5, ssa_operand_reg(obj_reg), ssa_operand_reg(off_reg3));
        ssa_inst_append(ctx.cur_block, add_ptr4);
        field_addr = addr5;
    }
    if (fd.type_kind == TYPE_SLICE && fd.ptr_depth == 0) {
        return builder_load_by_size(ctx, field_addr, 8);
    }
    var load_size: u64 = sizeof_field_desc(fd);
    if (load_size == 0) { load_size = 8; }
    if (load_size > 8) { load_size = 8; }
    return builder_load_by_size(ctx, field_addr, load_size);
}

func builder_expr_safe_member_access(ctx: *BuilderCtx, node: u64) -> u64 {
    var m_safe: *AstMemberAccess = (*AstMemberAccess)node;
    var obj_safe: u64 = m_safe.object;
    var ot: *TypeInfo = builder_safe_member_receiver_type(ctx, obj_safe);
    if (ot == 0) { return 0; }

    var null_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var ok_bb2: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var merge_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);

    var obj_reg: u64 = build_expr(ctx, obj_safe);
    if (ot.is_tagged == 1) {
        obj_reg = builder_mask_tagged_ptr(ctx, obj_reg);
    }
    var cond_reg2: u64 = build_bool_from_reg(ctx, obj_reg);
    var br_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_BR, ssa_operand_const(ok_bb2.id), ssa_operand_reg(cond_reg2), ssa_operand_const(null_bb.id));
    ssa_inst_append(ctx.cur_block, br_ptr2);
    ssa_add_edge(ctx.cur_block, ok_bb2);
    ssa_add_edge(ctx.cur_block, null_bb);

    builder_set_block(ctx, null_bb);
    var null_val: u64 = build_const(ctx, 0);
    var jmp_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(merge_bb.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr);
    ssa_add_edge(ctx.cur_block, merge_bb);

    builder_set_block(ctx, ok_bb2);
    var ok_val: u64 = 0;
    if (ot.is_tagged == 1 && ot.tag_layout_ptr != 0) {
        ok_val = builder_safe_member_tagged_value(ctx, m_safe, obj_reg, ot);
    } else {
        ok_val = builder_safe_member_struct_value(ctx, m_safe, obj_reg, ot);
        if (ok_val == 0) { return 0; }
    }
    var jmp_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(merge_bb.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr2);
    ssa_add_edge(ctx.cur_block, merge_bb);

    builder_set_block(ctx, merge_bb);
    var head: *SSAPhiArg = ssa_phi_arg_new(null_val, null_bb.id);
    head = ssa_phi_arg_append(head, ok_val, ok_bb2.id);
    var dest: u64 = builder_new_reg(ctx);
    var phi_ptr: *SSAInstruction = ssa_phi_new(ctx.ssa_ctx, dest, head);
    ssa_phi_append(merge_bb, phi_ptr);
    return dest;
}

func builder_safe_method_arg_regs(ctx: *BuilderCtx, recv_reg: u64, args: *Vec<*AstNode>, nargs: u64) -> *Vec<u64> {
    var arg_regs: *Vec<u64> = new Vec<u64>(nargs * 2 + 1);
    arg_regs.push(recv_reg);
    for (var i: u64 = 0; i < nargs; i++) {
        var arg: u64 = args.get(i);
        builder_append_call_arg(ctx, arg_regs, arg);
    }
    return arg_regs;
}

func builder_safe_method_emit_trait_ptr_call(ctx: *BuilderCtx, smc: *AstMethodCall, recv_ti: *TypeInfo, recv_reg: u64, args: *Vec<*AstNode>, nargs: u64) -> u64 {
    var method_index: u64 = compiler_find_trait_method_index(recv_ti.struct_name_ptr, recv_ti.struct_name_len, smc.method_ptr, smc.method_len);
    if (compiler_is_not_found_u64(method_index) != 0) {
        emit_stderr("[ERROR] Trait method not found: ");
        emit_stderr_len(smc.method_ptr, smc.method_len);
        emit_stderr("\n");
        return 0;
    }

    var arg_regs_t: *Vec<u64> = builder_safe_method_arg_regs(ctx, recv_reg, args, nargs);
    var vtable_reg: u64 = builder_load_by_size(ctx, recv_reg, 8);
    if (method_index != 0) {
        var off_reg_t: u64 = build_const(ctx, method_index * 8);
        var addr_t: u64 = builder_new_reg(ctx);
        var add_ptr_t: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr_t, ssa_operand_reg(vtable_reg), ssa_operand_reg(off_reg_t));
        ssa_inst_append(ctx.cur_block, add_ptr_t);
        vtable_reg = addr_t;
    }
    var callee_reg: u64 = builder_load_by_size(ctx, vtable_reg, 8);
    var call_val: u64 = builder_new_reg(ctx);
    builder_emit_call_ptr_raw(ctx, callee_reg, arg_regs_t, call_val, 0, TYPE_I64, 0, 0);
    return call_val;
}

func builder_safe_method_emit_struct_ptr_call(ctx: *BuilderCtx, smc: *AstMethodCall, recv_ti: *TypeInfo, recv_mode: u64, recv_reg: u64, args: *Vec<*AstNode>, nargs: u64) -> u64 {
    if (recv_mode == COMPILER_SAFE_RECV_INVALID) {
        if (recv_ti.ptr_depth == 0) {
            emit_stderr("[ERROR] Safe method call requires pointer receiver\n");
            return 0;
        }
        emit_stderr("[ERROR] Safe method call requires struct pointer\n");
        return 0;
    }

    var name_info2: *NameInfo = compiler_build_method_name(recv_ti.struct_name_ptr, recv_ti.struct_name_len, smc.method_ptr, smc.method_len);
    var resolved_ptr: u64 = name_info2.ptr;
    var resolved_len: u64 = name_info2.len;
    var resolved2: *NameInfo = resolve_name(name_info2.ptr, name_info2.len);
    if (resolved2 != 0) {
        resolved_ptr = resolved2.ptr;
        resolved_len = resolved2.len;
    }

    var ret_type: u64 = TYPE_I64;
    var ret_ptr_depth: u64 = 0;
    var fn: *AstFunc = typeinfo_find_func(resolved_ptr, resolved_len);
    if (fn != 0) {
        ret_type = fn.ret_type;
        ret_ptr_depth = fn.ret_ptr_depth;
        if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
            emit_stderr("[ERROR] Safe method call cannot return struct by value\n");
            return 0;
        }
    }

    var arg_regs: *Vec<u64> = builder_safe_method_arg_regs(ctx, recv_reg, args, nargs);
    var call_val: u64 = builder_new_reg(ctx);
    builder_emit_call_name_raw(ctx, resolved_ptr, resolved_len, arg_regs, call_val, 0, ret_type, ret_ptr_depth, 0);
    return call_val;
}

func builder_expr_safe_method_call(ctx: *BuilderCtx, node: u64) -> u64 {
    var smc: *AstMethodCall = (*AstMethodCall)node;
    var receiver: u64 = smc.receiver;
    var args: *Vec<*AstNode> = smc.args_vec;
    var nargs: u64 = 0;
    if (args != 0) { nargs = args.len(); }

    var recv_ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)receiver, ctx.symtab);
    if (recv_ti == 0) {
        emit_stderr("[ERROR] Safe method call receiver type not found\n");
        return 0;
    }
    var recv_mode: u64 = compiler_safe_receiver_mode(recv_ti);

    var null_bb2: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var call_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var merge_bb2: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);

    var recv_reg: u64 = build_expr(ctx, receiver);
    if (recv_ti.is_tagged == 1) {
        recv_reg = builder_mask_tagged_ptr(ctx, recv_reg);
    }
    var cond_reg3: u64 = build_bool_from_reg(ctx, recv_reg);
    var br_ptr3: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_BR, ssa_operand_const(call_bb.id), ssa_operand_reg(cond_reg3), ssa_operand_const(null_bb2.id));
    ssa_inst_append(ctx.cur_block, br_ptr3);
    ssa_add_edge(ctx.cur_block, call_bb);
    ssa_add_edge(ctx.cur_block, null_bb2);

    builder_set_block(ctx, null_bb2);
    var null_val2: u64 = build_const(ctx, 0);
    var jmp_ptr3: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(merge_bb2.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr3);
    ssa_add_edge(ctx.cur_block, merge_bb2);

    builder_set_block(ctx, call_bb);
    var call_val: u64 = 0;
    if (recv_mode == COMPILER_SAFE_RECV_TRAIT_PTR) {
        call_val = builder_safe_method_emit_trait_ptr_call(ctx, smc, recv_ti, recv_reg, args, nargs);
    } else {
        call_val = builder_safe_method_emit_struct_ptr_call(ctx, smc, recv_ti, recv_mode, recv_reg, args, nargs);
    }
    if (call_val == 0) { return 0; }

    var jmp_ptr4: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(merge_bb2.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr4);
    ssa_add_edge(ctx.cur_block, merge_bb2);

    builder_set_block(ctx, merge_bb2);
    var head2: *SSAPhiArg = ssa_phi_arg_new(null_val2, null_bb2.id);
    head2 = ssa_phi_arg_append(head2, call_val, call_bb.id);
    var dest2: u64 = builder_new_reg(ctx);
    var phi_ptr2: *SSAInstruction = ssa_phi_new(ctx.ssa_ctx, dest2, head2);
    ssa_phi_append(merge_bb2, phi_ptr2);
    return dest2;
}

func builder_emit_call_by_kind(ctx: *BuilderCtx, call_kind: u64, call_node: u64, dst: u64, extra_dst: u64) -> u64 {
    if (call_kind == AST_CALL) {
        builder_emit_call(ctx, (*AstCall)call_node, dst, extra_dst);
        return 1;
    }
    if (call_kind == AST_METHOD_CALL) {
        builder_emit_method_call(ctx, (*AstMethodCall)call_node, dst, extra_dst);
        return 1;
    }
    if (call_kind == AST_CALL_PTR) {
        builder_emit_call_ptr(ctx, (*AstCallPtr)call_node, dst, extra_dst);
        return 1;
    }
    return 0;
}

func builder_member_load_from_base_with_offset(ctx: *BuilderCtx, base_addr: u64, field_offset: u64, field_size: u64) -> u64 {
    var field_addr: u64 = base_addr;
    if (field_offset != 0) {
        var off_reg: u64 = build_const(ctx, field_offset);
        var addr2: u64 = builder_new_reg(ctx);
        var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(base_addr), ssa_operand_reg(off_reg));
        ssa_inst_append(ctx.cur_block, add_ptr);
        field_addr = addr2;
    }
    return builder_load_by_size(ctx, field_addr, field_size);
}

func builder_member_extract_from_small_struct_call(ctx: *BuilderCtx, call_kind: u64, call_node: u64, struct_size: u64, field_offset: u64, field_size: u64) -> u64 {
    if (field_offset + field_size <= 8) {
        var lo_reg: u64 = builder_new_reg(ctx);
        if (builder_emit_call_by_kind(ctx, call_kind, call_node, lo_reg, 0) == 0) {
            return 0;
        }
        if (field_offset == 0) { return lo_reg; }
        var shift_amt: u64 = field_offset * 8;
        return builder_shift_right(ctx, lo_reg, shift_amt);
    }
    if (field_offset >= 8 && field_offset + field_size <= 16) {
        var lo_reg2: u64 = builder_new_reg(ctx);
        var hi_reg: u64 = builder_new_reg(ctx);
        if (builder_emit_call_by_kind(ctx, call_kind, call_node, lo_reg2, hi_reg) == 0) {
            return 0;
        }
        if (field_offset == 8) { return hi_reg; }
        var shift_amt2: u64 = (field_offset - 8) * 8;
        return builder_shift_right(ctx, hi_reg, shift_amt2);
    }
    var lo_reg_span: u64 = builder_new_reg(ctx);
    var hi_reg_span: u64 = builder_new_reg(ctx);
    if (builder_emit_call_by_kind(ctx, call_kind, call_node, lo_reg_span, hi_reg_span) == 0) {
        return 0;
    }
    return builder_extract_field_from_small_struct_regs(ctx, lo_reg_span, hi_reg_span, struct_size, field_offset, field_size);
}

func builder_member_resolve_field_info(ctx: *BuilderCtx, node: u64, m: *AstMemberAccess, struct_def: *AstStructDef, field_offset_out: *u64, field_size_out: *u64) -> u64 {
    if (struct_def == 0) { return 0; }
    var field_offset: u64 = 0;
    var field_desc: *FieldDesc = 0;
    var found: u64 = struct_find_field_desc_scoped(struct_def, m.parent_ptr, m.parent_len, m.member_ptr, m.member_len, &field_offset, &field_desc);
    if (found == 0) { return 0; }
    *field_offset_out = field_offset;
    *field_size_out = builder_type_size_from_expr(ctx, node);
    return 1;
}

func builder_member_access_struct_call(ctx: *BuilderCtx, node: u64, m: *AstMemberAccess, call_kind: u64, call_node: u64, struct_def: *AstStructDef, struct_size: u64, debug_prefix: u64) -> u64 {
    if (struct_def == 0 || struct_size == 0) { return 0; }
    var field_offset: u64 = 0;
    var field_size: u64 = 0;
    if (builder_member_resolve_field_info(ctx, node, m, struct_def, &field_offset, &field_size) == 0) {
        return 0;
    }
    if (struct_size > 16) {
        var temp_offset: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, struct_size);
        var temp_addr: u64 = builder_new_lea_local(ctx, temp_offset);
        if (ctx.debug_mode != 0 && debug_prefix != 0) {
            emit(debug_prefix);
            print_u64(struct_size);
            emit("\n");
        }
        if (builder_emit_struct_call_sret_by_kind(ctx, call_kind, call_node, temp_addr) == 0) {
            return 0;
        }
        return builder_member_load_from_base_with_offset(ctx, temp_addr, field_offset, field_size);
    }
    return builder_member_extract_from_small_struct_call(ctx, call_kind, call_node, struct_size, field_offset, field_size);
}

func builder_member_access_try_call(ctx: *BuilderCtx, node: u64, m: *AstMemberAccess, obj: u64, obj_kind: u64, handled_out: *u64) -> u64 {
    *handled_out = 0;
    if (obj_kind != AST_CALL) { return 0; }

    var call: *AstCall = (*AstCall)obj;
    var fn_ptr: *AstFunc = compiler_get_func(call.name_ptr, call.name_len);
    if (fn_ptr == 0) {
        var fp_info2: *PtrLen = builder_get_func_ptr(ctx, call.name_ptr, call.name_len);
        if (fp_info2 != 0) {
            var fp_struct_name_ptr2: u64 = fp_info2.ptr;
            var fp_struct_name_len2: u64 = fp_info2.len;
            var fp_struct_def2: *AstStructDef = get_struct_def(fp_struct_name_ptr2, fp_struct_name_len2);
            if (fp_struct_def2 != 0) {
                var callee_tmp: *AstNode = ast_ident(call.name_ptr, call.name_len);
                var cp_tmp: *AstCallPtr = ast_call_ptr(callee_tmp, call.args_vec);
                var struct_size_fp2: u64 = builder_struct_size_from_def(fp_struct_def2);
                if (struct_size_fp2 == 0) {
                    struct_size_fp2 = sizeof_type(TYPE_STRUCT, 0, fp_struct_name_ptr2, fp_struct_name_len2);
                }
                *handled_out = 1;
                return builder_member_access_struct_call(ctx, node, m, AST_CALL_PTR, (u64)cp_tmp, fp_struct_def2, struct_size_fp2, "[DEBUG] ssa member access call.ptr sret size=");
            }
        }
    }

    if (fn_ptr != 0) {
        var fn: *AstFunc = (*AstFunc)fn_ptr;
        if (fn.ret_type == TYPE_STRUCT && fn.ret_ptr_depth == 0) {
            var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, fn.ret_struct_name_ptr, fn.ret_struct_name_len);
            var struct_def_call: *AstStructDef = get_struct_def(fn.ret_struct_name_ptr, fn.ret_struct_name_len);
            if (struct_def_call != 0) {
                *handled_out = 1;
                return builder_member_access_struct_call(ctx, node, m, AST_CALL, (u64)call, struct_def_call, struct_size, "[DEBUG] ssa member access call sret size=");
            }
        }
    }
    return 0;
}

func builder_member_access_try_typed_struct_call(ctx: *BuilderCtx, node: u64, m: *AstMemberAccess, obj: u64, obj_kind: u64, ti: *TypeInfo, handled_out: *u64) -> u64 {
    *handled_out = 0;
    if (ti.ptr_depth != 0 || ti.type_kind != TYPE_STRUCT) { return 0; }

    var struct_def: *AstStructDef = ti.struct_def;
    if (struct_def == 0 && ti.struct_name_ptr != 0) {
        struct_def = get_struct_def(ti.struct_name_ptr, ti.struct_name_len);
    }
    if (struct_def == 0 && (obj_kind == AST_CALL || obj_kind == AST_CALL_PTR)) {
        if (obj_kind == AST_CALL) {
            var call_obj: *AstCall = (*AstCall)obj;
            var fn_obj: *AstFunc = compiler_get_func(call_obj.name_ptr, call_obj.name_len);
            if (fn_obj != 0) {
                if (fn_obj.ret_struct_name_ptr != 0) {
                    struct_def = get_struct_def(fn_obj.ret_struct_name_ptr, fn_obj.ret_struct_name_len);
                    ti.struct_name_ptr = fn_obj.ret_struct_name_ptr;
                    ti.struct_name_len = fn_obj.ret_struct_name_len;
                }
            }
        } else {
            var cp_obj: *AstCallPtr = (*AstCallPtr)obj;
            var callee_obj: u64 = cp_obj.callee;
            var name_ptr_obj: u64 = 0;
            var name_len_obj: u64 = 0;
            var ck_obj: u64 = ast_kind(callee_obj);
            if (ck_obj == AST_IDENT) {
                var idn_obj: *AstIdent = (*AstIdent)callee_obj;
                name_ptr_obj = idn_obj.name_ptr;
                name_len_obj = idn_obj.name_len;
            } else if (ck_obj == AST_ADDR_OF) {
                var a_obj: *AstAddrOf = (*AstAddrOf)callee_obj;
                if (ast_kind(a_obj.operand) == AST_IDENT) {
                    var idn_obj2: *AstIdent = (*AstIdent)a_obj.operand;
                    name_ptr_obj = idn_obj2.name_ptr;
                    name_len_obj = idn_obj2.name_len;
                }
            }
            if (name_ptr_obj != 0) {
                var resolved_ptr_obj: u64 = name_ptr_obj;
                var resolved_len_obj: u64 = name_len_obj;
                var resolved_obj: *NameInfo = resolve_name(name_ptr_obj, name_len_obj);
                if (resolved_obj != 0) {
                    resolved_ptr_obj = resolved_obj.ptr;
                    resolved_len_obj = resolved_obj.len;
                }
                var fn_obj2: *AstFunc = compiler_get_func(resolved_ptr_obj, resolved_len_obj);
                if (fn_obj2 != 0) {
                    if (fn_obj2.ret_struct_name_ptr != 0) {
                        struct_def = get_struct_def(fn_obj2.ret_struct_name_ptr, fn_obj2.ret_struct_name_len);
                        ti.struct_name_ptr = fn_obj2.ret_struct_name_ptr;
                        ti.struct_name_len = fn_obj2.ret_struct_name_len;
                    }
                }
            }
        }
    }
    if (struct_def != 0 && (obj_kind == AST_CALL || obj_kind == AST_METHOD_CALL || obj_kind == AST_CALL_PTR)) {
        var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, ti.struct_name_ptr, ti.struct_name_len);
        var def_size2: u64 = builder_struct_size_from_def(struct_def);
        if (def_size2 > struct_size) { struct_size = def_size2; }
        *handled_out = 1;
        return builder_member_access_struct_call(ctx, node, m, obj_kind, obj, struct_def, struct_size, "[DEBUG] ssa member access sret struct size=");
    }
    return 0;
}

func builder_member_access_try_typed_tagged_packed(ctx: *BuilderCtx, m: *AstMemberAccess, obj: u64, ti: *TypeInfo, handled_out: *u64) -> u64 {
    *handled_out = 0;
    if (ti.ptr_depth == 0 || ti.is_tagged != 1 || ti.tag_layout_ptr == 0) { return 0; }
    var layout_def: *AstStructDef = get_struct_def(ti.tag_layout_ptr, ti.tag_layout_len);
    if (layout_def == 0) { return 0; }
    var layout_info: *AstStructDef = layout_def;
    var packed_flag: u64 = layout_info.is_packed;
    if (packed_flag != 1) { return 0; }
    var total_bits: u64 = builder_get_packed_layout_total_bits(layout_def);
    var field_offset: u64 = builder_get_packed_field_bit_offset(layout_def, m.member_ptr, m.member_len);
    var field_width: u64 = builder_get_packed_field_bit_width(layout_def, m.member_ptr, m.member_len);
    var start_bit: u64 = 64 - total_bits;
    var shift_bits: u64 = start_bit + field_offset;
    var reg_val: u64 = build_expr(ctx, obj);
    reg_val = builder_shift_right(ctx, reg_val, shift_bits);
    reg_val = builder_mask_low_bits(ctx, reg_val, field_width);
    *handled_out = 1;
    return reg_val;
}

func builder_member_access_try_typed_struct_packed(ctx: *BuilderCtx, m: *AstMemberAccess, obj: u64, ti: *TypeInfo, handled_out: *u64) -> u64 {
    *handled_out = 0;
    if (ti.ptr_depth != 0 || ti.type_kind != TYPE_STRUCT) { return 0; }
    var struct_def2: *AstStructDef = ti.struct_def;
    if (struct_def2 == 0 && ti.struct_name_ptr != 0) {
        struct_def2 = get_struct_def(ti.struct_name_ptr, ti.struct_name_len);
    }
    if (struct_def2 == 0) { return 0; }
    var struct_info2: *AstStructDef = struct_def2;
    var packed_flag2: u64 = struct_info2.is_packed;
    if (packed_flag2 != 1) { return 0; }
    var total_bits2: u64 = builder_get_packed_layout_total_bits(struct_def2);
    var field_offset2: u64 = builder_get_packed_field_bit_offset(struct_def2, m.member_ptr, m.member_len);
    var field_width2: u64 = builder_get_packed_field_bit_width(struct_def2, m.member_ptr, m.member_len);
    var shift_bits2: u64 = field_offset2;
    var size_bytes2: u64 = (total_bits2 + 7) / 8;
    var base_addr: u64 = builder_lvalue_addr(ctx, obj);
    var raw_val: u64 = builder_load_by_size(ctx, base_addr, size_bytes2);
    raw_val = builder_shift_right(ctx, raw_val, shift_bits2);
    raw_val = builder_mask_low_bits(ctx, raw_val, field_width2);
    *handled_out = 1;
    return raw_val;
}

func builder_member_access_try_typed(ctx: *BuilderCtx, node: u64, m: *AstMemberAccess, obj: u64, obj_kind: u64, handled_out: *u64) -> u64 {
    *handled_out = 0;
    var ti: *TypeInfo = get_expr_type_with_symtab((*AstNode)obj, ctx.symtab);
    if (ti == 0) { return 0; }

    var reg_val: u64 = builder_member_access_try_typed_struct_call(ctx, node, m, obj, obj_kind, ti, handled_out);
    if (*handled_out != 0) { return reg_val; }

    reg_val = builder_member_access_try_typed_tagged_packed(ctx, m, obj, ti, handled_out);
    if (*handled_out != 0) { return reg_val; }

    return builder_member_access_try_typed_struct_packed(ctx, m, obj, ti, handled_out);
}

func builder_member_access_try_call_ptr_fp(ctx: *BuilderCtx, node: u64, m: *AstMemberAccess, obj: u64, obj_kind: u64, handled_out: *u64) -> u64 {
    *handled_out = 0;
    if (obj_kind != AST_CALL_PTR) { return 0; }
    var cp_fp: *AstCallPtr = (*AstCallPtr)obj;
    var callee_fp: u64 = cp_fp.callee;
    if (ast_kind(callee_fp) != AST_IDENT) { return 0; }

    var idn_fp: *AstIdent = (*AstIdent)callee_fp;
    var fp_info: *PtrLen = builder_get_func_ptr(ctx, idn_fp.name_ptr, idn_fp.name_len);
    if (fp_info == 0) { return 0; }
    var fp_struct_name_ptr: u64 = fp_info.ptr;
    var fp_struct_name_len: u64 = fp_info.len;
    var fp_struct_def: *AstStructDef = get_struct_def(fp_struct_name_ptr, fp_struct_name_len);
    if (fp_struct_def == 0) { return 0; }

    var struct_size_fp: u64 = builder_struct_size_from_def(fp_struct_def);
    if (struct_size_fp == 0) {
        struct_size_fp = sizeof_type(TYPE_STRUCT, 0, fp_struct_name_ptr, fp_struct_name_len);
    }
    *handled_out = 1;
    return builder_member_access_struct_call(ctx, node, m, AST_CALL_PTR, obj, fp_struct_def, struct_size_fp, "[DEBUG] ssa member access call_ptr sret size=");
}

func builder_expr_member_access(ctx: *BuilderCtx, node: u64) -> u64 {
    var m: *AstMemberAccess = (*AstMemberAccess)node;
    var obj: u64 = m.object;
    var obj_kind: u64 = ast_kind(obj);

    var handled: u64 = 0;
    var reg_val: u64 = builder_member_access_try_call(ctx, node, m, obj, obj_kind, &handled);
    if (handled != 0) { return reg_val; }

    reg_val = builder_member_access_try_typed(ctx, node, m, obj, obj_kind, &handled);
    if (handled != 0) { return reg_val; }

    reg_val = builder_member_access_try_call_ptr_fp(ctx, node, m, obj, obj_kind, &handled);
    if (handled != 0) { return reg_val; }

    var addr_reg4: u64 = builder_lvalue_addr(ctx, node);
    var size4: u64 = builder_type_size_from_expr(ctx, node);
    return builder_load_by_size(ctx, addr_reg4, size4);
}

func builder_expr_call(ctx: *BuilderCtx, node: u64) -> u64 {
    var call_ptr: u64 = node;
    var dst: u64 = builder_new_reg(ctx);
    var ret_ti: *TypeInfo = get_expr_type_with_symtab(node, ctx.symtab);
    if (ret_ti != 0) {
        if (ret_ti.type_kind == TYPE_VOID && ret_ti.ptr_depth == 0) {
            dst = 0;
        }
        if (ret_ti.type_kind == TYPE_STRUCT && ret_ti.ptr_depth == 0) {
            var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
            if (struct_size > 16) {
                var temp_offset: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, struct_size);
                var temp_addr: u64 = builder_new_lea_local(ctx, temp_offset);
                builder_emit_call_sret(ctx, (*AstCall)call_ptr, temp_addr);
                return temp_addr;
            }
        }
    }
    return builder_emit_call(ctx, (*AstCall)call_ptr, dst, 0);
}

func builder_expr_call_ptr(ctx: *BuilderCtx, node: u64) -> u64 {
    var cp_ptr: u64 = node;
    var dst: u64 = builder_new_reg(ctx);
    var ret_ti: *TypeInfo = get_expr_type_with_symtab(node, ctx.symtab);
    if (ret_ti != 0) {
        if (ret_ti.type_kind == TYPE_VOID && ret_ti.ptr_depth == 0) {
            dst = 0;
        }
        if (ret_ti.type_kind == TYPE_STRUCT && ret_ti.ptr_depth == 0) {
            var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
            if (struct_size > 16) {
                var temp_offset: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, struct_size);
                var temp_addr: u64 = builder_new_lea_local(ctx, temp_offset);
                builder_emit_call_ptr_sret(ctx, (*AstCallPtr)cp_ptr, temp_addr);
                return temp_addr;
            }
        }
    }
    return builder_emit_call_ptr(ctx, (*AstCallPtr)cp_ptr, dst, 0);
}

func builder_expr_method_call(ctx: *BuilderCtx, node: u64) -> u64 {
    var mc_ptr: u64 = node;
    var dst: u64 = builder_new_reg(ctx);
    var ret_ti: *TypeInfo = get_expr_type_with_symtab(node, ctx.symtab);
    if (ret_ti != 0) {
        if (ret_ti.type_kind == TYPE_VOID && ret_ti.ptr_depth == 0) {
            dst = 0;
        }
        if (ret_ti.type_kind == TYPE_STRUCT && ret_ti.ptr_depth == 0) {
            var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, ret_ti.struct_name_ptr, ret_ti.struct_name_len);
            if (struct_size > 16) {
                var temp_offset: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, struct_size);
                var temp_addr: u64 = builder_new_lea_local(ctx, temp_offset);
                builder_emit_method_call_sret(ctx, (*AstMethodCall)mc_ptr, temp_addr);
                return temp_addr;
            }
        }
    }
    return builder_emit_method_call(ctx, (*AstMethodCall)mc_ptr, dst, 0);
}

func builder_expr_float(ctx: *BuilderCtx, node: u64) -> u64 {
    var fl: *AstFloat = (*AstFloat)node;
    var info: *PtrLen = new PtrLen{fl.str_ptr, fl.str_len};
    var reg_id: u64 = builder_new_reg(ctx);
    var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_FCONST, reg_id, ssa_operand_const((u64)info), 0);
    ssa_inst_append(ctx.cur_block, inst_ptr);
    return reg_id;
}

func builder_expr_string(ctx: *BuilderCtx, node: u64) -> u64 {
    var s: *AstString = (*AstString)node;
    var info: *PtrLen = new PtrLen{s.str_ptr, s.str_len};
    var reg_id: u64 = builder_new_reg(ctx);
    var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_LEA_STR, reg_id, ssa_operand_const((u64)info), 0);
    ssa_inst_append(ctx.cur_block, inst_ptr);
    return reg_id;
}

func builder_expr_stack_ctor_value(ctx: *BuilderCtx, node: u64) -> u64 {
    var sc: *AstStackCtor = (*AstStackCtor)node;
    var sc_ti: *TypeInfo = get_expr_type_with_symtab(node, ctx.symtab);
    if (sc_ti == 0 || sc_ti.type_kind != TYPE_STRUCT || sc_ti.ptr_depth != 0) {
        emit_stderr("[ERROR] stack constructor expression requires struct value\n");
        panic("SSA build error");
    }
    var sc_size: u64 = sizeof_type(TYPE_STRUCT, 0, sc_ti.struct_name_ptr, sc_ti.struct_name_len);
    var tmp_offset: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, sc_size);
    var base_addr: u64 = builder_new_lea_local(ctx, tmp_offset);
    builder_stack_ctor_init_at_addr(ctx, sc, base_addr);
    if (sc_size <= 8) {
        return builder_load_by_size(ctx, base_addr, sc_size);
    }
    if (sc_size <= 16) {
        if (ctx.debug_mode != 0) {
            emit("[DEBUG] stack ctor expr returns lo only (hi handled in callers)\n");
        }
        return builder_load_by_size(ctx, base_addr, 8);
    }
    return base_addr;
}

func builder_expr_deref8(ctx: *BuilderCtx, node: u64) -> u64 {
    var d8: *AstDeref8 = (*AstDeref8)node;
    var addr_reg: u64 = build_expr(ctx, d8.operand);
    var op_ti: *TypeInfo = get_expr_type_with_symtab(d8.operand, ctx.symtab);
    if (op_ti != 0 && op_ti.is_tagged == 1) {
        addr_reg = builder_mask_tagged_ptr(ctx, addr_reg);
    }
    return builder_load_by_size(ctx, addr_reg, 1);
}

func builder_expr_deref(ctx: *BuilderCtx, node: u64) -> u64 {
    var d: *AstDeref = (*AstDeref)node;
    var addr_reg: u64 = build_expr(ctx, d.operand);
    var op_ti: *TypeInfo = get_expr_type_with_symtab(d.operand, ctx.symtab);
    if (op_ti != 0 && op_ti.is_tagged == 1) {
        addr_reg = builder_mask_tagged_ptr(ctx, addr_reg);
    }
    var size: u64 = builder_type_size_from_expr(ctx, node);
    return builder_load_by_size(ctx, addr_reg, size);
}

func builder_expr_sizeof(ctx: *BuilderCtx, node: u64) -> u64 {
    var sz: *AstSizeof = (*AstSizeof)node;
    var size_val: u64 = 0;
    if (sz.type_kind == TYPE_ARRAY || sz.type_kind == TYPE_SLICE) {
        if (sz.array_len_is_param != 0) {
            emit_stderr("[ERROR] sizeof array with unresolved generic length\n");
            panic("SSA build error");
        }
        var ti_ptr: *TypeInfo = 0;
        if (sz.type_kind == TYPE_ARRAY) {
            ti_ptr = typeinfo_make_array(sz.ptr_depth, sz.elem_type_kind, sz.elem_ptr_depth, sz.struct_name_ptr, sz.struct_name_len, 0, sz.array_len);
        } else {
            ti_ptr = typeinfo_make_slice(sz.ptr_depth, sz.elem_type_kind, sz.elem_ptr_depth, sz.struct_name_ptr, sz.struct_name_len, 0);
        }
        size_val = sizeof_type_ex(ti_ptr);
    } else {
        size_val = sizeof_type(sz.type_kind, sz.ptr_depth, sz.struct_name_ptr, sz.struct_name_len);
    }
    return build_const(ctx, size_val);
}

func builder_expr_sizeof_expr(ctx: *BuilderCtx, node: u64) -> u64 {
    var sz_expr: *AstSizeofExpr = (*AstSizeofExpr)node;
    var ti_ptr: *TypeInfo = get_expr_type_with_symtab(sz_expr.expr, ctx.symtab);
    var size_val: u64 = 8;
    if (ti_ptr != 0) {
        size_val = sizeof_type_ex(ti_ptr);
    }
    return build_const(ctx, size_val);
}

func build_expr(ctx: *BuilderCtx, node: u64) -> u64 {
    push_trace("build_expr", "ssa_builder.b", __LINE__);
    defer pop_trace();
    if (node == 0) { return 0; }
    var kind: u64 = ast_kind(node);

    if (kind == AST_LITERAL) {
        var lit: *AstLiteral = (*AstLiteral)node;
        return build_const(ctx, lit.value);
    }

    if (kind == AST_FLOAT) { return builder_expr_float(ctx, node); }

    if (kind == AST_STRING) { return builder_expr_string(ctx, node); }

    if (kind == AST_NEW) {
        return builder_expr_new(ctx, node);
    }

    if (kind == AST_STACK_CTOR) { return builder_expr_stack_ctor_value(ctx, node); }

    if (kind == AST_IDENT) {
        return builder_expr_ident(ctx, node);
    }

    if (kind == AST_BINARY) {
        return builder_expr_binary(ctx, node);
    }

    if (kind == AST_UNARY) {
        return builder_expr_unary(ctx, node);
    }

    if (kind == AST_TRY) {
        return builder_build_try_expr(ctx, node);
    }

    if (kind == AST_SAFE_MEMBER_ACCESS) {
        return builder_expr_safe_member_access(ctx, node);
    }

    if (kind == AST_SAFE_METHOD_CALL) {
        return builder_expr_safe_method_call(ctx, node);
    }

    if (kind == AST_ADDR_OF) {
        var a: *AstAddrOf = (*AstAddrOf)node;
        return builder_lvalue_addr(ctx, a.operand);
    }

    if (kind == AST_DEREF8) { return builder_expr_deref8(ctx, node); }

    if (kind == AST_DEREF) { return builder_expr_deref(ctx, node); }

    if (kind == AST_INDEX) {
        var addr_reg3: u64 = builder_lvalue_addr(ctx, node);
        var size3: u64 = builder_type_size_from_expr(ctx, node);
        return builder_load_by_size(ctx, addr_reg3, size3);
    }

    if (kind == AST_MEMBER_ACCESS) {
        return builder_expr_member_access(ctx, node);
    }

    if (kind == AST_CAST) {
        var cast: *AstCast = (*AstCast)node;
        return build_expr(ctx, cast.expr);
    }

    if (kind == AST_SIZEOF) { return builder_expr_sizeof(ctx, node); }

    if (kind == AST_SIZEOF_EXPR) { return builder_expr_sizeof_expr(ctx, node); }

    if (kind == AST_CALL) {
        return builder_expr_call(ctx, node);
    }

    if (kind == AST_CALL_PTR) {
        return builder_expr_call_ptr(ctx, node);
    }

    if (kind == AST_METHOD_CALL) {
        return builder_expr_method_call(ctx, node);
    }

    return build_const(ctx, 0);
}

// ============================================
// CFG Builders
// ============================================

func build_block(ctx: *BuilderCtx, block_node: u64) -> u64 {
    push_trace("build_block", "ssa_builder.b", __LINE__);
    defer pop_trace();
    if (block_node == 0) { return 0; }
    var blk: *AstBlock = (*AstBlock)block_node;
    var stmts: *Vec<u64> = blk.stmts_vec;
    var n: u64 = stmts.len();
    for (var i: u64 = 0; i < n; i++) {
        var stmt: u64 = stmts.get(i);
        build_stmt(ctx, stmt);
    }
    return 0;
}

func build_for(ctx: *BuilderCtx, node: u64) -> u64 {
    push_trace("build_for", "ssa_builder.b", __LINE__);
    defer pop_trace();
    var f: *AstFor = (*AstFor)node;

    if (f.init != 0) {
        builder_stmt_or_expr(ctx, f.init);
    }

    var cond_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var body_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var update_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var exit_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);

    var jmp_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(cond_bb.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr);
    ssa_add_edge(ctx.cur_block, cond_bb);

    builder_set_block(ctx, cond_bb);
    var cond_reg: u64 = 0;
    if (f.cond != 0) {
        cond_reg = build_expr(ctx, f.cond);
    } else {
        cond_reg = build_const(ctx, 1);
    }
    var br_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_BR, ssa_operand_const(exit_bb.id), ssa_operand_reg(cond_reg), ssa_operand_const(body_bb.id));
    ssa_inst_append(ctx.cur_block, br_ptr);
    ssa_add_edge(ctx.cur_block, body_bb);
    ssa_add_edge(ctx.cur_block, exit_bb);

    builder_push_loop(ctx, exit_bb, update_bb);
    builder_set_block(ctx, body_bb);
    build_block(ctx, f.body);
    if (builder_block_is_reachable(ctx.cur_block) != 0 && builder_block_is_terminated(ctx.cur_block) == 0) {
        var jmp_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(update_bb.id), 0);
        ssa_inst_append(ctx.cur_block, jmp_ptr2);
        ssa_add_edge(ctx.cur_block, update_bb);
    }
    builder_pop_loop(ctx);

    builder_set_block(ctx, update_bb);
    if (f.update != 0) {
        builder_stmt_or_expr(ctx, f.update);
    }
    if (builder_block_is_reachable(ctx.cur_block) != 0 && builder_block_is_terminated(ctx.cur_block) == 0) {
        var jmp_ptr3: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(cond_bb.id), 0);
        ssa_inst_append(ctx.cur_block, jmp_ptr3);
        ssa_add_edge(ctx.cur_block, cond_bb);
    }

    builder_set_block(ctx, exit_bb);
    return 0;
}

func build_switch(ctx: *BuilderCtx, node: u64) -> u64 {
    push_trace("build_switch", "ssa_builder.b", __LINE__);
    defer pop_trace();
    var sw: *AstSwitch = (*AstSwitch)node;
    var cases: *Vec<u64> = sw.cases_vec;
    var count: u64 = 0;
    if (cases != 0) { count = cases.len(); }

    var exit_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    if (count == 0) {
        var jmp_ptr0: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(exit_bb.id), 0);
        ssa_inst_append(ctx.cur_block, jmp_ptr0);
        ssa_add_edge(ctx.cur_block, exit_bb);
        builder_set_block(ctx, exit_bb);
        return 0;
    }

    var expr_reg: u64 = build_expr(ctx, sw.expr);

    var case_blocks: *Vec<*SSABlock> = new Vec<*SSABlock>(count);
    var case_nodes: *Vec<*AstCase> = new Vec<*AstCase>(count);
    var default_bb: *SSABlock = exit_bb;

    for (var i: u64 = 0; i < count; i++) {
        var c_ptr: u64 = cases.get(i);
        var c: *AstCase = (*AstCase)c_ptr;
        var case_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
        case_blocks.push(case_bb);
        case_nodes.push(c);
        if (c.is_default != 0) {
            default_bb = case_bb;
        }
    }

    for (var i: u64 = 0; i < count; i++) {
        var c2: *AstCase = case_nodes.get(i);
        if (c2.is_default == 0) {
            var case_bb2: *SSABlock = case_blocks.get(i);
            var val_reg: u64 = build_expr(ctx, c2.value);
            var cmp_reg: u64 = builder_new_reg(ctx);
            var cmp_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_EQ, cmp_reg, ssa_operand_reg(expr_reg), ssa_operand_reg(val_reg));
            ssa_inst_append(ctx.cur_block, cmp_ptr);

            var next_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
            var br_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_BR, ssa_operand_const(next_bb.id), ssa_operand_reg(cmp_reg), ssa_operand_const(case_bb2.id));
            ssa_inst_append(ctx.cur_block, br_ptr);
            ssa_add_edge(ctx.cur_block, case_bb2);
            ssa_add_edge(ctx.cur_block, next_bb);
            builder_set_block(ctx, next_bb);
        }
    }

    var jmp_ptr1: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(default_bb.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr1);
    ssa_add_edge(ctx.cur_block, default_bb);

    builder_push_loop(ctx, exit_bb, 0);
    for (var i: u64 = 0; i < count; i++) {
        var case_bb3: *SSABlock = case_blocks.get(i);
        var c3: *AstCase = case_nodes.get(i);
        builder_set_block(ctx, case_bb3);
        build_block(ctx, c3.body);

        if (builder_block_is_reachable(ctx.cur_block) != 0 && builder_block_is_terminated(ctx.cur_block) == 0) {
            var next_bb2: *SSABlock = exit_bb;
            if (i + 1 < count) {
                next_bb2 = case_blocks.get(i + 1);
            }
            var jmp_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(next_bb2.id), 0);
            ssa_inst_append(ctx.cur_block, jmp_ptr2);
            ssa_add_edge(ctx.cur_block, next_bb2);
        }
    }
    builder_pop_loop(ctx);

    builder_set_block(ctx, exit_bb);
    return 0;
}

func build_if(ctx: *BuilderCtx, node: u64) -> u64 {
    push_trace("build_if", "ssa_builder.b", __LINE__);
    defer pop_trace();
    var ifn: *AstIf = (*AstIf)node;
    var has_else: u64 = 0;
    if (ifn.else_block != 0) { has_else = 1; }

    if (SSA_BUILDER_DEBUG != 0) {
        println("[DEBUG] build_if: cond", 25);
    }

    var cond_reg: u64 = build_expr(ctx, ifn.cond);

    if (SSA_BUILDER_DEBUG != 0) {
        println("[DEBUG] build_if: blocks", 27);
    }

    var then_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var merge_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var else_bb: *SSABlock = merge_bb;
    if (has_else == 1) {
        else_bb = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    }

    var br_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_BR, ssa_operand_const(else_bb.id), ssa_operand_reg(cond_reg), ssa_operand_const(then_bb.id));
    ssa_inst_append(ctx.cur_block, br_ptr);

    ssa_add_edge(ctx.cur_block, then_bb);
    ssa_add_edge(ctx.cur_block, else_bb);

    builder_set_block(ctx, then_bb);
    if (SSA_BUILDER_DEBUG != 0) {
        println("[DEBUG] build_if: then", 25);
    }
    build_block(ctx, ifn.then_block);
    var jmp_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(merge_bb.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr);
    ssa_add_edge(ctx.cur_block, merge_bb);

    if (has_else == 1) {
        builder_set_block(ctx, else_bb);
        if (SSA_BUILDER_DEBUG != 0) {
            println("[DEBUG] build_if: else", 25);
        }
        build_block(ctx, ifn.else_block);
        var jmp_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(merge_bb.id), 0);
        ssa_inst_append(ctx.cur_block, jmp_ptr2);
        ssa_add_edge(ctx.cur_block, merge_bb);
    }

    builder_set_block(ctx, merge_bb);
    return 0;
}

func build_while(ctx: *BuilderCtx, node: u64) -> u64 {
    push_trace("build_while", "ssa_builder.b", __LINE__);
    defer pop_trace();
    var w: *AstWhile = (*AstWhile)node;

    var cond_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var body_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    var exit_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);

    var jmp_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(cond_bb.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr);
    ssa_add_edge(ctx.cur_block, cond_bb);

    builder_set_block(ctx, cond_bb);
    var cond_reg: u64 = build_expr(ctx, w.cond);
    var br_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_BR, ssa_operand_const(exit_bb.id), ssa_operand_reg(cond_reg), ssa_operand_const(body_bb.id));
    ssa_inst_append(ctx.cur_block, br_ptr);
    ssa_add_edge(ctx.cur_block, body_bb);
    ssa_add_edge(ctx.cur_block, exit_bb);

    builder_push_loop(ctx, exit_bb, cond_bb);
    builder_set_block(ctx, body_bb);
    build_block(ctx, w.body);
    var jmp_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(cond_bb.id), 0);
    ssa_inst_append(ctx.cur_block, jmp_ptr2);
    ssa_add_edge(ctx.cur_block, cond_bb);
    builder_pop_loop(ctx);

    builder_set_block(ctx, exit_bb);
    return 0;
}

// ============================================
// Return Helpers
// ============================================

func builder_emit_return_slice_from_call(ctx: *BuilderCtx, expr: u64) -> u64 {
    var ptr_reg: u64 = builder_new_reg(ctx);
    var len_reg: u64 = builder_new_reg(ctx);
    var kind: u64 = ast_kind(expr);
    if (kind == AST_CALL) {
        builder_emit_call(ctx, (*AstCall)expr, ptr_reg, len_reg);
    } else if (kind == AST_METHOD_CALL) {
        builder_emit_method_call(ctx, (*AstMethodCall)expr, ptr_reg, len_reg);
    } else {
        builder_emit_call_ptr(ctx, (*AstCallPtr)expr, ptr_reg, len_reg);
    }
    var ret_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, ssa_operand_reg(ptr_reg), ssa_operand_reg(len_reg));
    ssa_inst_append(ctx.cur_block, ret_ptr);
    return 0;
}

func builder_emit_return_struct_from_call(ctx: *BuilderCtx, expr: u64, struct_size: u64) -> u64 {
    var lo_reg: u64 = builder_new_reg(ctx);
    var hi_reg: u64 = 0;
    if (struct_size > 8) { hi_reg = builder_new_reg(ctx); }
    var kind: u64 = ast_kind(expr);
    if (kind == AST_CALL) {
        builder_emit_call(ctx, (*AstCall)expr, lo_reg, hi_reg);
    } else if (kind == AST_METHOD_CALL) {
        builder_emit_method_call(ctx, (*AstMethodCall)expr, lo_reg, hi_reg);
    } else {
        builder_emit_call_ptr(ctx, (*AstCallPtr)expr, lo_reg, hi_reg);
    }
    var ret_src2: u64 = 0;
    if (hi_reg != 0) { ret_src2 = ssa_operand_reg(hi_reg); }
    var ret_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, ssa_operand_reg(lo_reg), ret_src2);
    ssa_inst_append(ctx.cur_block, ret_ptr);
    return 0;
}

func builder_emit_return_struct_from_addr(ctx: *BuilderCtx, expr: u64, struct_size: u64) -> u64 {
    var addr_reg: u64 = builder_lvalue_addr(ctx, expr);
    if (addr_reg == 0) { return 0; }
    var head_size: u64 = struct_size;
    if (head_size > 8) { head_size = 8; }
    var lo_reg: u64 = builder_load_by_size(ctx, addr_reg, head_size);
    if (lo_reg == 0) {
        lo_reg = build_const(ctx, 0);
    }
    var hi_reg: u64 = 0;
    if (struct_size > 8) {
        var off_reg: u64 = build_const(ctx, 8);
        var addr2: u64 = builder_new_reg(ctx);
        var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(addr_reg), ssa_operand_reg(off_reg));
        ssa_inst_append(ctx.cur_block, add_ptr);
        var tail_size: u64 = struct_size - 8;
        if (tail_size > 8) { tail_size = 8; }
        hi_reg = builder_load_by_size(ctx, addr2, tail_size);
        if (hi_reg == 0) {
            hi_reg = build_const(ctx, 0);
        }
    }
    var ret_src2: u64 = 0;
    if (struct_size > 8) {
        if (hi_reg != 0) {
            ret_src2 = ssa_operand_reg(hi_reg);
        } else {
            var zero_reg: u64 = build_const(ctx, 0);
            ret_src2 = ssa_operand_reg(zero_reg);
        }
    }
    var ret_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, ssa_operand_reg(lo_reg), ret_src2);
    ssa_inst_append(ctx.cur_block, ret_ptr2);
    return 0;
}

func builder_build_struct_literal_scalar(ctx: *BuilderCtx, lit: *AstStructLiteral) -> u64 {
    var values: *Vec<*AstNode> = lit.values_vec;
    if (values == 0) { return build_const(ctx, 0); }
    var count: u64 = values.len();
    if (count == 0) { return build_const(ctx, 0); }
    var first: *AstNode = values.get(0);
    if (ast_kind(first) == AST_STRUCT_LITERAL) {
        return builder_build_struct_literal_scalar(ctx, (*AstStructLiteral)first);
    }
    var reg: u64 = build_expr(ctx, first);
    if (reg == 0) { reg = build_const(ctx, 0); }
    return reg;
}

func builder_struct_literal_eval_value_or_zero(ctx: *BuilderCtx, values: *Vec<*AstNode>, idx: u64) -> u64 {
    if (values == 0) { return build_const(ctx, 0); }
    if (idx >= values.len()) { return build_const(ctx, 0); }
    var v: *AstNode = values.get(idx);
    var out: u64 = 0;
    if (ast_kind(v) == AST_STRUCT_LITERAL) {
        out = builder_build_struct_literal_scalar(ctx, (*AstStructLiteral)v);
    } else {
        out = build_expr(ctx, v);
    }
    if (out == 0) {
        out = build_const(ctx, 0);
    }
    return out;
}

func builder_emit_return_zero_value(ctx: *BuilderCtx) -> u64 {
    var zero_reg: u64 = build_const(ctx, 0);
    var ret_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, ssa_operand_reg(zero_reg), 0);
    ssa_inst_append(ctx.cur_block, ret_ptr);
    return 0;
}

func builder_emit_return_struct_from_literal(ctx: *BuilderCtx, lit: *AstStructLiteral, struct_size: u64) -> u64 {
    var values: *Vec<*AstNode> = lit.values_vec;
    if (values == 0) { return builder_emit_return_zero_value(ctx); }

    var num_values: u64 = values.len();
    if (num_values == 0) { return builder_emit_return_zero_value(ctx); }

    var struct_def: *AstStructDef = lit.struct_def;
    var first_val: u64 = 0;
    var second_val: u64 = 0;

    if (struct_def != 0) {
        var sd: *AstStructDef = struct_def;
        var fields: *Vec<*FieldDesc> = sd.fields_vec;
        if (fields != 0 && num_values > 0) {
            first_val = builder_struct_literal_eval_value_or_zero(ctx, values, 0);
            if (struct_size > 8) {
                if (num_values > 1) {
                    second_val = builder_struct_literal_eval_value_or_zero(ctx, values, 1);
                } else {
                    second_val = build_const(ctx, 0);
                }
            }
        }
    } else {
        if (num_values > 0) {
            first_val = builder_struct_literal_eval_value_or_zero(ctx, values, 0);
            if (struct_size > 8) {
                if (num_values > 1) {
                    second_val = builder_struct_literal_eval_value_or_zero(ctx, values, 1);
                } else {
                    second_val = build_const(ctx, 0);
                }
            }
        }
    }

    if (first_val == 0) {
        first_val = build_const(ctx, 0);
    }

    if (struct_size > 8 && second_val == 0) {
        second_val = build_const(ctx, 0);
    }

    var ret_src2: u64 = 0;
    if (struct_size > 8) {
        if (second_val != 0) {
            ret_src2 = ssa_operand_reg(second_val);
        } else {
            var zero_reg: u64 = build_const(ctx, 0);
            ret_src2 = ssa_operand_reg(zero_reg);
        }
    }
    var ret_ptr3: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, ssa_operand_reg(first_val), ret_src2);
    ssa_inst_append(ctx.cur_block, ret_ptr3);
    return 0;
}

func builder_emit_expr_stmt_call(ctx: *BuilderCtx, expr: u64) -> u64 {
    var expr_kind: u64 = ast_kind(expr);
    if (expr_kind == AST_CALL) {
        var sret_size: u64 = builder_get_sret_struct_size(ctx, expr);
        if (sret_size != 0) {
            var sret_offset: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, sret_size);
            var sret_addr_reg: u64 = builder_new_lea_local(ctx, sret_offset);
            builder_emit_call_sret(ctx, (*AstCall)expr, sret_addr_reg);
            return 1;
        }
        builder_emit_call(ctx, (*AstCall)expr, 0, 0);
        return 1;
    }
    if (expr_kind == AST_METHOD_CALL) {
        var sret_size2: u64 = builder_get_sret_struct_size(ctx, expr);
        if (sret_size2 != 0) {
            var sret_offset2: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, sret_size2);
            var sret_addr_reg2: u64 = builder_new_lea_local(ctx, sret_offset2);
            builder_emit_method_call_sret(ctx, (*AstMethodCall)expr, sret_addr_reg2);
            return 1;
        }
        builder_emit_method_call(ctx, (*AstMethodCall)expr, 0, 0);
        return 1;
    }
    if (expr_kind == AST_CALL_PTR) {
        var sret_size3: u64 = builder_get_sret_struct_size(ctx, expr);
        if (sret_size3 != 0) {
            var sret_offset3: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, sret_size3);
            var sret_addr_reg3: u64 = builder_new_lea_local(ctx, sret_offset3);
            builder_emit_call_ptr_sret(ctx, (*AstCallPtr)expr, sret_addr_reg3);
            return 1;
        }
        builder_emit_call_ptr(ctx, (*AstCallPtr)expr, 0, 0);
        return 1;
    }
    return 0;
}

func builder_track_func_ptr_from_addr_of_ident(ctx: *BuilderCtx, target_name_ptr: u64, target_name_len: u64, value_expr: u64) -> u64 {
    if (value_expr == 0) {
        builder_set_func_ptr(ctx, target_name_ptr, target_name_len, 0, 0);
        return 0;
    }
    if (ast_kind(value_expr) != AST_ADDR_OF) {
        builder_set_func_ptr(ctx, target_name_ptr, target_name_len, 0, 0);
        return 0;
    }
    var addr_val: *AstAddrOf = (*AstAddrOf)value_expr;
    if (ast_kind(addr_val.operand) != AST_IDENT) {
        builder_set_func_ptr(ctx, target_name_ptr, target_name_len, 0, 0);
        return 0;
    }
    var idn_val: *AstIdent = (*AstIdent)addr_val.operand;
    var resolved_ptr: u64 = idn_val.name_ptr;
    var resolved_len: u64 = idn_val.name_len;
    var resolved: *NameInfo = resolve_name(idn_val.name_ptr, idn_val.name_len);
    if (resolved != 0) {
        resolved_ptr = resolved.ptr;
        resolved_len = resolved.len;
    }
    var fn_map: *AstFunc = compiler_get_func(resolved_ptr, resolved_len);
    if (fn_map != 0 && fn_map.ret_type == TYPE_STRUCT && fn_map.ret_ptr_depth == 0) {
        builder_set_func_ptr(ctx, target_name_ptr, target_name_len, fn_map.ret_struct_name_ptr, fn_map.ret_struct_name_len);
        return 0;
    }
    builder_set_func_ptr(ctx, target_name_ptr, target_name_len, 0, 0);
    return 0;
}

func builder_store_struct_call_result_to_addr(ctx: *BuilderCtx, value_expr: u64, struct_size: u64, target_addr: u64) -> u64 {
    if (struct_size == 0) {
        return 0;
    }
    var value_kind: u64 = ast_kind(value_expr);
    if (!(value_kind == AST_CALL || value_kind == AST_METHOD_CALL || value_kind == AST_CALL_PTR)) {
        return 0;
    }
    if (struct_size > 16) {
        if (value_kind == AST_CALL) {
            builder_emit_call_sret(ctx, (*AstCall)value_expr, target_addr);
        } else if (value_kind == AST_METHOD_CALL) {
            builder_emit_method_call_sret(ctx, (*AstMethodCall)value_expr, target_addr);
        } else {
            builder_emit_call_ptr_sret(ctx, (*AstCallPtr)value_expr, target_addr);
        }
        return 1;
    }
    var lo_reg: u64 = builder_new_reg(ctx);
    var hi_reg: u64 = 0;
    if (struct_size > 8) {
        hi_reg = builder_new_reg(ctx);
    }
    if (value_kind == AST_CALL) {
        builder_emit_call(ctx, (*AstCall)value_expr, lo_reg, hi_reg);
    } else if (value_kind == AST_METHOD_CALL) {
        builder_emit_method_call(ctx, (*AstMethodCall)value_expr, lo_reg, hi_reg);
    } else {
        builder_emit_call_ptr(ctx, (*AstCallPtr)value_expr, lo_reg, hi_reg);
    }
    builder_store_by_size(ctx, target_addr, lo_reg, 8);
    if (hi_reg != 0) {
        var off8: u64 = build_const(ctx, 8);
        var addr2: u64 = builder_new_reg(ctx);
        var add_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ADD, addr2, ssa_operand_reg(target_addr), ssa_operand_reg(off8));
        ssa_inst_append(ctx.cur_block, add_ptr);
        var tail_size: u64 = struct_size - 8;
        if (tail_size > 8) {
            tail_size = 8;
        }
        builder_store_by_size(ctx, addr2, hi_reg, tail_size);
    }
    return 1;
}

func builder_stmt_var_decl(ctx: *BuilderCtx, node: u64) -> u64 {
    var vd: *AstVarDecl = (*AstVarDecl)node;
    var var_id: u64 = builder_get_var_id(ctx, vd.name_ptr, vd.name_len);
    builder_symtab_add_local(ctx, vd);
    if (vd.init_expr != 0) {
        var init_kind: u64 = ast_kind(vd.init_expr);
        builder_track_func_ptr_from_addr_of_ident(ctx, vd.name_ptr, vd.name_len, vd.init_expr);
        if (vd.type_kind == TYPE_SLICE && vd.ptr_depth == 0) {
            var offset_slice: u64 = symtab_find(ctx.symtab, vd.name_ptr, vd.name_len);
            var base_addr: u64 = builder_new_lea_local(ctx, offset_slice);
            var init_kind2: u64 = ast_kind(vd.init_expr);
            if (init_kind2 == AST_CALL) {
                builder_emit_call_slice_store(ctx, (*AstCall)vd.init_expr, base_addr);
                return 0;
            }
            if (init_kind2 == AST_METHOD_CALL) {
                builder_emit_method_call_slice_store(ctx, (*AstMethodCall)vd.init_expr, base_addr);
                return 0;
            }
            if (init_kind2 == AST_CALL_PTR) {
                builder_emit_call_ptr_slice_store(ctx, (*AstCallPtr)vd.init_expr, base_addr);
                return 0;
            }
            var slice_info: *SliceRegs = builder_slice_regs(ctx, vd.init_expr);
            builder_store_slice_regs(ctx, base_addr, slice_info);
            return 0;
        }
        if (init_kind == AST_STRUCT_LITERAL) {
            var offset: u64 = symtab_find(ctx.symtab, vd.name_ptr, vd.name_len);
            var base_addr: u64 = builder_new_lea_local(ctx, offset);
            var lit: *AstStructLiteral = (*AstStructLiteral)vd.init_expr;
            builder_struct_literal_init(ctx, lit.struct_def, lit.values_vec, base_addr);
            return 0;
        }
        if (init_kind == AST_STACK_CTOR) {
            var offset_sc: u64 = symtab_find(ctx.symtab, vd.name_ptr, vd.name_len);
            var base_addr_sc: u64 = builder_new_lea_local(ctx, offset_sc);
            var sc_init: *AstStackCtor = (*AstStackCtor)vd.init_expr;
            builder_stack_ctor_init_at_addr(ctx, sc_init, base_addr_sc);
            return 0;
        }
        // Handle struct-returning function calls
        if (vd.type_kind == TYPE_STRUCT && vd.ptr_depth == 0) {
            var struct_size: u64 = sizeof_type(TYPE_STRUCT, 0, vd.struct_name_ptr, vd.struct_name_len);
            if (init_kind == AST_CALL || init_kind == AST_METHOD_CALL || init_kind == AST_CALL_PTR) {
                var offset_call: u64 = symtab_find(ctx.symtab, vd.name_ptr, vd.name_len);
                if (offset_call == 0) {
                    if (struct_size > 16) {
                        return 0;
                    }
                    // Fall back to normal handling if offset not found
                    var val_reg: u64 = build_expr(ctx, vd.init_expr);
                    var st_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_STORE, 0, ssa_operand_const(var_id), ssa_operand_reg(val_reg));
                    ssa_inst_append(ctx.cur_block, st_ptr);
                    return 0;
                }
                var base_addr_call: u64 = builder_new_lea_local(ctx, offset_call);
                if (builder_store_struct_call_result_to_addr(ctx, vd.init_expr, struct_size, base_addr_call) != 0) {
                    return 0;
                }
            }
        }
        if (builder_is_addr_taken(ctx, vd.name_ptr, vd.name_len) != 0) {
            var offset_addr: u64 = symtab_find(ctx.symtab, vd.name_ptr, vd.name_len);
            if (offset_addr != 0) {
                var base_addr3: u64 = builder_new_lea_local(ctx, offset_addr);
                var val_reg2: u64 = build_expr(ctx, vd.init_expr);
                var size_at: u64 = 0;
                if (vd.type_kind == TYPE_ARRAY) {
                    var elem_size_at: u64 = sizeof_type(vd.elem_type_kind, vd.elem_ptr_depth, vd.struct_name_ptr, vd.struct_name_len);
                    size_at = elem_size_at * vd.array_len;
                } else if (vd.type_kind == TYPE_SLICE) {
                    size_at = 16;
                } else {
                    size_at = sizeof_type(vd.type_kind, vd.ptr_depth, vd.struct_name_ptr, vd.struct_name_len);
                }
                if (size_at == 0) { size_at = 8; }
                builder_store_by_size(ctx, base_addr3, val_reg2, size_at);
                return 0;
            }
        }
        var val_reg: u64 = build_expr(ctx, vd.init_expr);
        var st_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_STORE, 0, ssa_operand_const(var_id), ssa_operand_reg(val_reg));
        ssa_inst_append(ctx.cur_block, st_ptr);
    }
    return 0;
}

func builder_assign_addr_taken_ident(ctx: *BuilderCtx, asn: *AstAssign) -> u64 {
    if (ast_kind(asn.target) != AST_IDENT) {
        return 0;
    }
    var idn_tgt: *AstIdent = (*AstIdent)asn.target;
    if (builder_is_addr_taken(ctx, idn_tgt.name_ptr, idn_tgt.name_len) == 0) {
        return 0;
    }
    var ti_at: *TypeInfo = get_expr_type_with_symtab(asn.target, ctx.symtab);
    if (ti_at != 0 && ti_at.type_kind == TYPE_SLICE && ti_at.ptr_depth == 0) {
        return 0;
    }
    var target_addr: u64 = builder_lvalue_addr(ctx, asn.target);
    var value_reg: u64 = build_expr(ctx, asn.value);
    var size_bytes: u64 = builder_type_size_from_expr(ctx, asn.target);
    builder_store_by_size(ctx, target_addr, value_reg, size_bytes);
    return 1;
}

func builder_assign_try_packed_member(ctx: *BuilderCtx, asn: *AstAssign) -> u64 {
    if (ast_kind(asn.target) != AST_MEMBER_ACCESS) {
        return 0;
    }
    var m: *AstMemberAccess = (*AstMemberAccess)asn.target;
    var obj: u64 = m.object;
    var ot: *TypeInfo = get_expr_type_with_symtab((*AstNode)obj, ctx.symtab);
    if (ot == 0) {
        return 0;
    }
    if (ot.ptr_depth > 0 && ot.is_tagged == 1 && ot.tag_layout_ptr != 0) {
        var layout_def: *AstStructDef = get_struct_def(ot.tag_layout_ptr, ot.tag_layout_len);
        if (layout_def != 0) {
            var layout_info: *AstStructDef = layout_def;
            if (layout_info.is_packed == 1) {
                var total_bits: u64 = builder_get_packed_layout_total_bits(layout_def);
                var field_offset: u64 = builder_get_packed_field_bit_offset(layout_def, m.member_ptr, m.member_len);
                var field_width: u64 = builder_get_packed_field_bit_width(layout_def, m.member_ptr, m.member_len);
                var start_bit: u64 = 64 - total_bits;
                var shift_bits: u64 = start_bit + field_offset;
                var value_reg: u64 = build_expr(ctx, asn.value);
                value_reg = builder_mask_low_bits(ctx, value_reg, field_width);
                value_reg = builder_shift_left(ctx, value_reg, shift_bits);
                var obj_val: u64 = build_expr(ctx, obj);
                var merged: u64 = value_reg;
                if (field_width < 64) {
                    var field_mask_val: u64 = builder_make_bitmask(field_width);
                    var field_mask_reg: u64 = build_const(ctx, field_mask_val);
                    field_mask_reg = builder_shift_left(ctx, field_mask_reg, shift_bits);
                    var all_ones_reg: u64 = builder_all_ones_reg(ctx);
                    var inv_mask_reg: u64 = builder_new_reg(ctx);
                    var xor_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_XOR, inv_mask_reg, ssa_operand_reg(field_mask_reg), ssa_operand_reg(all_ones_reg));
                    ssa_inst_append(ctx.cur_block, xor_ptr);
                    var cleared_reg: u64 = builder_new_reg(ctx);
                    var and_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_AND, cleared_reg, ssa_operand_reg(obj_val), ssa_operand_reg(inv_mask_reg));
                    ssa_inst_append(ctx.cur_block, and_ptr);
                    merged = builder_new_reg(ctx);
                    var or_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_OR, merged, ssa_operand_reg(cleared_reg), ssa_operand_reg(value_reg));
                    ssa_inst_append(ctx.cur_block, or_ptr);
                }
                if (ast_kind(obj) == AST_IDENT) {
                    var idn_tag: *AstIdent = (*AstIdent)obj;
                    var tag_offset: u64 = symtab_find(ctx.symtab, idn_tag.name_ptr, idn_tag.name_len);
                    if (tag_offset != 0) {
                        var var_id_tag: u64 = builder_get_var_id(ctx, idn_tag.name_ptr, idn_tag.name_len);
                        var st_ptr_tag: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_STORE, 0, ssa_operand_const(var_id_tag), ssa_operand_reg(merged));
                        ssa_inst_append(ctx.cur_block, st_ptr_tag);
                        return 1;
                    }
                }
                var obj_addr: u64 = builder_lvalue_addr(ctx, obj);
                builder_store_by_size(ctx, obj_addr, merged, 8);
                return 1;
            }
        }
    }
    if (ot.ptr_depth == 0 && ot.type_kind == TYPE_STRUCT) {
        var struct_def: *AstStructDef = ot.struct_def;
        if (struct_def == 0 && ot.struct_name_ptr != 0) {
            struct_def = get_struct_def(ot.struct_name_ptr, ot.struct_name_len);
        }
        if (struct_def != 0) {
            var struct_info: *AstStructDef = struct_def;
            if (struct_info.is_packed == 1) {
                var total_bits2: u64 = builder_get_packed_layout_total_bits(struct_def);
                var field_offset2: u64 = builder_get_packed_field_bit_offset(struct_def, m.member_ptr, m.member_len);
                var field_width2: u64 = builder_get_packed_field_bit_width(struct_def, m.member_ptr, m.member_len);
                var shift_bits2: u64 = field_offset2;
                var size_bytes2: u64 = (total_bits2 + 7) / 8;
                var base_addr2: u64 = builder_lvalue_addr(ctx, obj);
                var cur_val: u64 = builder_load_by_size(ctx, base_addr2, size_bytes2);
                var value_reg2: u64 = build_expr(ctx, asn.value);
                value_reg2 = builder_mask_low_bits(ctx, value_reg2, field_width2);
                value_reg2 = builder_shift_left(ctx, value_reg2, shift_bits2);
                var merged2: u64 = value_reg2;
                if (field_width2 < 64) {
                    var field_mask_val2: u64 = builder_make_bitmask(field_width2);
                    var field_mask_reg2: u64 = build_const(ctx, field_mask_val2);
                    field_mask_reg2 = builder_shift_left(ctx, field_mask_reg2, shift_bits2);
                    var all_ones_reg2: u64 = builder_all_ones_reg(ctx);
                    var inv_mask_reg2: u64 = builder_new_reg(ctx);
                    var xor_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_XOR, inv_mask_reg2, ssa_operand_reg(field_mask_reg2), ssa_operand_reg(all_ones_reg2));
                    ssa_inst_append(ctx.cur_block, xor_ptr2);
                    var cleared_reg2: u64 = builder_new_reg(ctx);
                    var and_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_AND, cleared_reg2, ssa_operand_reg(cur_val), ssa_operand_reg(inv_mask_reg2));
                    ssa_inst_append(ctx.cur_block, and_ptr2);
                    merged2 = builder_new_reg(ctx);
                    var or_ptr2: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_OR, merged2, ssa_operand_reg(cleared_reg2), ssa_operand_reg(value_reg2));
                    ssa_inst_append(ctx.cur_block, or_ptr2);
                }
                builder_store_by_size(ctx, base_addr2, merged2, size_bytes2);
                return 1;
            }
        }
    }
    return 0;
}

func builder_assign_load_target_struct_meta(ctx: *BuilderCtx, asn: *AstAssign, target_kind: u64, tgt_ti_out: *u64, tgt_is_struct_out: *u64, tgt_struct_size_out: *u64) -> u64 {
    *tgt_ti_out = 0;
    *tgt_is_struct_out = 0;
    *tgt_struct_size_out = 0;
    if (!(target_kind == AST_IDENT || target_kind == AST_DEREF || target_kind == AST_DEREF8 || target_kind == AST_MEMBER_ACCESS)) {
        return 0;
    }
    var tgt_ti_ptr: *TypeInfo = get_expr_type_with_symtab((*AstNode)asn.target, ctx.symtab);
    if (tgt_ti_ptr == 0) { return 0; }
    *tgt_ti_out = (u64)tgt_ti_ptr;
    var ti_s: *TypeInfo = tgt_ti_ptr;
    if (ti_s.type_kind == TYPE_STRUCT && ti_s.ptr_depth == 0) {
        *tgt_is_struct_out = 1;
        *tgt_struct_size_out = sizeof_type(TYPE_STRUCT, 0, ti_s.struct_name_ptr, ti_s.struct_name_len);
    }
    return 0;
}

func builder_assign_resolve_target_addr(ctx: *BuilderCtx, asn: *AstAssign, target_kind: u64, target_addr_out: *u64, target_offset_out: *u64) -> u64 {
    *target_addr_out = 0;
    *target_offset_out = 0;
    if (target_kind == AST_IDENT) {
        var idn: *AstIdent = (*AstIdent)asn.target;
        *target_offset_out = symtab_find(ctx.symtab, idn.name_ptr, idn.name_len);
        if (*target_offset_out != 0) {
            *target_addr_out = builder_new_lea_local(ctx, *target_offset_out);
        } else {
            *target_addr_out = builder_lvalue_addr(ctx, asn.target);
        }
        return 1;
    }
    if (target_kind == AST_DEREF || target_kind == AST_DEREF8 || target_kind == AST_INDEX || target_kind == AST_MEMBER_ACCESS) {
        *target_addr_out = builder_lvalue_addr(ctx, asn.target);
        return 1;
    }
    return 0;
}

func builder_stmt_assign(ctx: *BuilderCtx, node: u64) -> u64 {
    var asn: *AstAssign = (*AstAssign)node;
    var target_kind: u64 = ast_kind(asn.target);
    if (target_kind == AST_IDENT && asn.value != 0) {
        var idn_tgt: *AstIdent = (*AstIdent)asn.target;
        builder_track_func_ptr_from_addr_of_ident(ctx, idn_tgt.name_ptr, idn_tgt.name_len, asn.value);
    }
    if (builder_assign_addr_taken_ident(ctx, asn) != 0) {
        return 0;
    }
    var tgt_ti_raw: u64 = 0;
    var tgt_is_struct: u64 = 0;
    var tgt_struct_size: u64 = 0;
    builder_assign_load_target_struct_meta(ctx, asn, target_kind, &tgt_ti_raw, &tgt_is_struct, &tgt_struct_size);
    if (builder_assign_try_packed_member(ctx, asn) != 0) {
        return 0;
    }
    var target_addr: u64 = 0;
    var target_offset: u64 = 0;

    if (builder_assign_resolve_target_addr(ctx, asn, target_kind, &target_addr, &target_offset) == 0) {
        return 0;
    }

    if (ast_kind(asn.value) == AST_STRUCT_LITERAL) {
        builder_assign_struct_literal_to_addr(ctx, (*AstStructLiteral)asn.value, target_addr);
        return 0;
    }

    if (ast_kind(asn.value) == AST_STACK_CTOR) {
        builder_assign_stack_ctor_to_addr(ctx, (*AstStackCtor)asn.value, target_addr);
        return 0;
    }

    if (tgt_is_struct != 0 && tgt_struct_size > 0) {
        if (builder_store_struct_call_result_to_addr(ctx, asn.value, tgt_struct_size, target_addr) != 0) {
            return 0;
        }

        var src_addr_s: u64 = builder_lvalue_addr(ctx, asn.value);
        if (src_addr_s == 0) { return 0; }
        builder_struct_copy(ctx, target_addr, src_addr_s, tgt_struct_size);
        return 0;
    }

    if (tgt_ti_raw != 0) {
        var ti: *TypeInfo = (*TypeInfo)tgt_ti_raw;
        if (ti.type_kind == TYPE_SLICE && ti.ptr_depth == 0) {
            builder_assign_slice_to_addr(ctx, asn.value, target_addr);
            return 0;
        }
    }

    var val_reg3: u64 = build_expr(ctx, asn.value);
    if (target_kind == AST_IDENT && target_offset != 0) {
        var idn2: *AstIdent = (*AstIdent)asn.target;
        var var_id3: u64 = builder_get_var_id(ctx, idn2.name_ptr, idn2.name_len);
        var st_ptr3: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_STORE, 0, ssa_operand_const(var_id3), ssa_operand_reg(val_reg3));
        ssa_inst_append(ctx.cur_block, st_ptr3);
        return 0;
    }

    var size4: u64 = 8;
    if (target_kind == AST_DEREF8) {
        size4 = 1;
    } else {
        size4 = builder_type_size_from_expr(ctx, asn.target);
    }
    builder_store_by_size(ctx, target_addr, val_reg3, size4);
    return 0;
}

func builder_emit_return_slice_value(ctx: *BuilderCtx, expr: u64) -> u64 {
    var expr_kind: u64 = ast_kind(expr);
    if (expr_kind == AST_SLICE) {
        var slice_node: *AstSlice = (*AstSlice)expr;
        var ptr_ti: *TypeInfo = get_expr_type_with_symtab(slice_node.ptr_expr, ctx.symtab);
        if (ptr_ti != 0) {
            var is_local_array: u64 = 0;
            if (ptr_ti.ptr_depth == 0) {
                if (ptr_ti.type_kind == TYPE_ARRAY || ptr_ti.array_len != 0) {
                    is_local_array = 1;
                }
            }
            if (is_local_array != 0) {
                var elem_size: u64 = sizeof_type(ptr_ti.elem_type_kind, ptr_ti.elem_ptr_depth, ptr_ti.struct_name_ptr, ptr_ti.struct_name_len);
                if (elem_size == 0) { elem_size = 8; }
                var ptr_reg: u64 = builder_lvalue_addr(ctx, slice_node.ptr_expr);
                if (ptr_reg == 0) {
                    ptr_reg = build_expr(ctx, slice_node.ptr_expr);
                }
                var len_reg: u64 = build_expr(ctx, slice_node.len_expr);
                var ret_ptr_heap: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET_SLICE_HEAP, elem_size, ssa_operand_reg(ptr_reg), ssa_operand_reg(len_reg));
                ssa_inst_append(ctx.cur_block, ret_ptr_heap);
                var ptr_is_reg: u64 = 1;
                var len_is_reg: u64 = 1;
                var len_val: u64 = len_reg;
                if (ast_kind(slice_node.len_expr) == AST_LITERAL) {
                    var lit_len: *AstLiteral = (*AstLiteral)slice_node.len_expr;
                    len_val = lit_len.value;
                    len_is_reg = 0;
                }
                ssa_ret_slice_heap_set(ret_ptr_heap, elem_size);
                ssa_ret_slice_heap_set_ex(ret_ptr_heap, elem_size, ptr_reg, len_val, ptr_is_reg, len_is_reg);
                return 0;
            }
        }
    }
    if (expr_kind == AST_CALL || expr_kind == AST_METHOD_CALL || expr_kind == AST_CALL_PTR) {
        return builder_emit_return_slice_from_call(ctx, expr);
    }
    var slice_regs: *SliceRegs = builder_slice_regs(ctx, expr);
    var ptr_reg2: u64 = slice_regs.ptr_reg;
    var len_reg2: u64 = slice_regs.len_reg;
    var ret_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, ssa_operand_reg(ptr_reg2), ssa_operand_reg(len_reg2));
    ssa_inst_append(ctx.cur_block, ret_ptr);
    return 0;
}

func builder_emit_return_void_inst(ctx: *BuilderCtx) -> u64 {
    var ret_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, 0, 0);
    ssa_inst_append(ctx.cur_block, ret_ptr);
    return 0;
}

func builder_stmt_return_try_struct_literal(ctx: *BuilderCtx, expr: u64) -> u64 {
    if (ast_kind(expr) != AST_STRUCT_LITERAL) {
        return 0;
    }
    var lit: *AstStructLiteral = (*AstStructLiteral)expr;
    var fallback_name_ptr: u64 = emitter_get_ret_struct_name_ptr();
    var fallback_name_len: u64 = emitter_get_ret_struct_name_len();
    var struct_size: u64 = builder_resolve_struct_literal_size(ctx, lit, fallback_name_ptr, fallback_name_len);
    if (struct_size == 0) {
        emit_stderr("[ERROR] SSA return struct literal size unresolved\n");
        return 1;
    }
    if (struct_size > 16) {
        if (ctx.sret_addr_reg == 0) { return 1; }
        builder_struct_literal_init(ctx, lit.struct_def, lit.values_vec, ctx.sret_addr_reg);
        builder_emit_return_void_inst(ctx);
        return 1;
    }
    builder_emit_return_struct_from_literal(ctx, lit, struct_size);
    return 1;
}

func builder_stmt_return_try_stack_ctor(ctx: *BuilderCtx, expr: u64) -> u64 {
    if (ast_kind(expr) != AST_STACK_CTOR) {
        return 0;
    }
    var sc_ret: *AstStackCtor = (*AstStackCtor)expr;
    var sc_ti: *TypeInfo = get_expr_type_with_symtab(expr, ctx.symtab);
    if (sc_ti == 0 || sc_ti.type_kind != TYPE_STRUCT || sc_ti.ptr_depth != 0) { return 1; }
    var sc_size: u64 = sizeof_type(TYPE_STRUCT, 0, sc_ti.struct_name_ptr, sc_ti.struct_name_len);
    if (sc_size == 0) { return 1; }
    if (sc_size > 16) {
        if (ctx.sret_addr_reg == 0) { return 1; }
        builder_stack_ctor_init_at_addr(ctx, sc_ret, ctx.sret_addr_reg);
        builder_emit_return_void_inst(ctx);
        return 1;
    }
    var tmp_offset_sc: u64 = symtab_add(ctx.symtab, 0, 0, TYPE_STRUCT, 0, sc_size);
    var tmp_addr_sc: u64 = builder_new_lea_local(ctx, tmp_offset_sc);
    builder_stack_ctor_init_at_addr(ctx, sc_ret, tmp_addr_sc);
    builder_emit_return_struct_from_addr_reg(ctx, tmp_addr_sc, sc_size);
    return 1;
}

func builder_stmt_return_large_struct(ctx: *BuilderCtx, expr: u64, expr_kind: u64, struct_size: u64) -> u64 {
    if (ctx.sret_addr_reg == 0) {
        return 0;
    }
    if (expr_kind == AST_STRUCT_LITERAL) {
        var lit: *AstStructLiteral = (*AstStructLiteral)expr;
        builder_struct_literal_init(ctx, lit.struct_def, lit.values_vec, ctx.sret_addr_reg);
    } else if (builder_emit_struct_call_sret_by_kind(ctx, expr_kind, expr, ctx.sret_addr_reg) == 0) {
        var src_addr: u64 = builder_lvalue_addr(ctx, expr);
        if (src_addr == 0) { return 0; }
        builder_struct_copy(ctx, ctx.sret_addr_reg, src_addr, struct_size);
    }
    builder_emit_return_void_inst(ctx);
    return 0;
}

func builder_stmt_return_resolve_struct_target(ctx: *BuilderCtx, expr: u64, ret_type: u64, ret_ptr_depth: u64, ret_struct_name_ptr: u64, ret_struct_name_len: u64, use_struct_return_out: *u64, struct_name_ptr_out: *u64, struct_name_len_out: *u64, expr_struct_def_out: *u64) -> u64 {
    var ret_expr_ti: *TypeInfo = get_expr_type_with_symtab(expr, ctx.symtab);
    var ret_expr_is_struct: u64 = 0;
    var ret_expr_struct_name_ptr: u64 = 0;
    var ret_expr_struct_name_len: u64 = 0;
    var ret_expr_struct_def: *AstStructDef = 0;
    if (ret_expr_ti != 0) {
        if (ret_expr_ti.type_kind == TYPE_STRUCT && ret_expr_ti.ptr_depth == 0) {
            ret_expr_is_struct = 1;
            ret_expr_struct_name_ptr = ret_expr_ti.struct_name_ptr;
            ret_expr_struct_name_len = ret_expr_ti.struct_name_len;
            ret_expr_struct_def = ret_expr_ti.struct_def;
        }
    }

    var use_struct_return: u64 = 0;
    var struct_name_ptr: u64 = ret_struct_name_ptr;
    var struct_name_len: u64 = ret_struct_name_len;
    if (ret_type == TYPE_STRUCT && ret_ptr_depth == 0) {
        use_struct_return = 1;
        if ((struct_name_ptr == 0 || struct_name_len == 0) && ret_expr_is_struct != 0) {
            struct_name_ptr = ret_expr_struct_name_ptr;
            struct_name_len = ret_expr_struct_name_len;
            if ((struct_name_ptr == 0 || struct_name_len == 0) && ret_expr_struct_def != 0) {
                var ret_expr_struct_info: *AstStructDef = ret_expr_struct_def;
                struct_name_ptr = ret_expr_struct_info.name_ptr;
                struct_name_len = ret_expr_struct_info.name_len;
            }
        }
    } else if (ret_expr_is_struct != 0) {
        use_struct_return = 1;
        struct_name_ptr = ret_expr_struct_name_ptr;
        struct_name_len = ret_expr_struct_name_len;
        if ((struct_name_ptr == 0 || struct_name_len == 0) && ret_expr_struct_def != 0) {
            var ret_expr_struct_info2: *AstStructDef = ret_expr_struct_def;
            struct_name_ptr = ret_expr_struct_info2.name_ptr;
            struct_name_len = ret_expr_struct_info2.name_len;
        }
    }
    if (ctx.sret_addr_reg != 0) {
        use_struct_return = 1;
    }

    *use_struct_return_out = use_struct_return;
    *struct_name_ptr_out = struct_name_ptr;
    *struct_name_len_out = struct_name_len;
    *expr_struct_def_out = (u64)ret_expr_struct_def;
    return 0;
}

func builder_stmt_return_emit_struct(ctx: *BuilderCtx, expr: u64, struct_name_ptr0: u64, struct_name_len0: u64, ret_expr_struct_def: *AstStructDef) -> u64 {
    var expr_kind: u64 = ast_kind(expr);
    var struct_name_ptr: u64 = struct_name_ptr0;
    var struct_name_len: u64 = struct_name_len0;
    var struct_size: u64 = 0;
    var struct_def_for_size: *AstStructDef = ret_expr_struct_def;
    if ((struct_name_ptr == 0 || struct_name_len == 0) && expr_kind == AST_CALL) {
        var call_node0: *AstCall = (*AstCall)expr;
        var call_fn0: *AstFunc = compiler_get_func(call_node0.name_ptr, call_node0.name_len);
        if (call_fn0 != 0) {
            if (call_fn0.ret_type == TYPE_STRUCT && call_fn0.ret_ptr_depth == 0) {
                struct_name_ptr = call_fn0.ret_struct_name_ptr;
                struct_name_len = call_fn0.ret_struct_name_len;
                struct_def_for_size = get_struct_def(struct_name_ptr, struct_name_len);
            }
        }
    }
    if (struct_def_for_size == 0 && expr_kind == AST_STRUCT_LITERAL) {
        var lit_size: *AstStructLiteral = (*AstStructLiteral)expr;
        struct_def_for_size = lit_size.struct_def;
    }
    if (struct_name_ptr != 0 && struct_name_len != 0) {
        struct_size = sizeof_type(TYPE_STRUCT, 0, struct_name_ptr, struct_name_len);
    }
    if (struct_def_for_size != 0) {
        var def_size: u64 = builder_struct_size_from_def(struct_def_for_size);
        if (def_size > struct_size) { struct_size = def_size; }
    }
    if (struct_name_ptr != 0 && struct_name_len != 0) {
        var name_def: *AstStructDef = get_struct_def(struct_name_ptr, struct_name_len);
        if (name_def != 0) {
            var name_def_size: u64 = builder_struct_size_from_def(name_def);
            if (name_def_size > struct_size) { struct_size = name_def_size; }
        }
    }
    if (struct_size == 0 && expr_kind == AST_STRUCT_LITERAL) {
        var lit_fallback: *AstStructLiteral = (*AstStructLiteral)expr;
        struct_size = builder_resolve_struct_literal_size(ctx, lit_fallback, struct_name_ptr, struct_name_len);
    }
    if (expr_kind == AST_CALL) {
        var call_node: *AstCall = (*AstCall)expr;
        var call_fn: *AstFunc = compiler_get_func(call_node.name_ptr, call_node.name_len);
        if (call_fn != 0) {
            if (call_fn.ret_type == TYPE_STRUCT && call_fn.ret_ptr_depth == 0) {
                var call_def: *AstStructDef = get_struct_def(call_fn.ret_struct_name_ptr, call_fn.ret_struct_name_len);
                var call_def_size: u64 = builder_struct_size_from_def(call_def);
                if (call_def_size > 16 && ctx.sret_addr_reg != 0) {
                    builder_emit_call_sret(ctx, call_node, ctx.sret_addr_reg);
                    builder_emit_return_void_inst(ctx);
                    return 0;
                }
                if (call_def_size == 0) {
                    call_def_size = sizeof_type(TYPE_STRUCT, 0, call_fn.ret_struct_name_ptr, call_fn.ret_struct_name_len);
                }
                if (call_def_size > struct_size) { struct_size = call_def_size; }
            }
        }
    }
    if (struct_size == 0) {
        emit_stderr("[ERROR] SSA return struct size unresolved\n");
        return 0;
    }
    if (struct_size > 16) {
        builder_stmt_return_large_struct(ctx, expr, expr_kind, struct_size);
        return 0;
    }
    if (expr_kind == AST_STRUCT_LITERAL) {
        return builder_emit_return_struct_from_literal(ctx, (*AstStructLiteral)expr, struct_size);
    }
    if (expr_kind == AST_CALL || expr_kind == AST_METHOD_CALL || expr_kind == AST_CALL_PTR) {
        return builder_emit_return_struct_from_call(ctx, expr, struct_size);
    }
    return builder_emit_return_struct_from_addr(ctx, expr, struct_size);
}

func builder_stmt_return(ctx: *BuilderCtx, node: u64) -> u64 {
    var ret: *AstReturn = (*AstReturn)node;
    if (ret.expr == 0) {
        builder_emit_return_void_inst(ctx);
        return 0;
    }

    if (builder_stmt_return_try_struct_literal(ctx, ret.expr) != 0) {
        return 0;
    }

    if (builder_stmt_return_try_stack_ctor(ctx, ret.expr) != 0) {
        return 0;
    }

    var ret_type: u64 = emitter_get_ret_type();
    var ret_ptr_depth: u64 = emitter_get_ret_ptr_depth();
    var ret_struct_name_ptr: u64 = emitter_get_ret_struct_name_ptr();
    var ret_struct_name_len: u64 = emitter_get_ret_struct_name_len();
    var use_struct_return: u64 = 0;
    var struct_name_ptr: u64 = 0;
    var struct_name_len: u64 = 0;
    var ret_expr_struct_def_raw: u64 = 0;
    builder_stmt_return_resolve_struct_target(
        ctx,
        ret.expr,
        ret_type,
        ret_ptr_depth,
        ret_struct_name_ptr,
        ret_struct_name_len,
        &use_struct_return,
        &struct_name_ptr,
        &struct_name_len,
        &ret_expr_struct_def_raw
    );

    if (use_struct_return != 0) {
        var ret_expr_struct_def: *AstStructDef = (*AstStructDef)ret_expr_struct_def_raw;
        return builder_stmt_return_emit_struct(ctx, ret.expr, struct_name_ptr, struct_name_len, ret_expr_struct_def);
    }

    if (ret_type == TYPE_SLICE && ret_ptr_depth == 0) {
        return builder_emit_return_slice_value(ctx, ret.expr);
    }

    var ret_ti: *TypeInfo = get_expr_type_with_symtab(ret.expr, ctx.symtab);
    if (ret_ti != 0 && ret_ti.type_kind == TYPE_SLICE && ret_ti.ptr_depth == 0) {
        return builder_emit_return_slice_value(ctx, ret.expr);
    }

    var val_reg4: u64 = build_expr(ctx, ret.expr);
    var ret_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_RET, 0, ssa_operand_reg(val_reg4), 0);
    ssa_inst_append(ctx.cur_block, ret_ptr);
    return 0;
}

func builder_stmt_expr_stmt(ctx: *BuilderCtx, node: u64) -> u64 {
    var es: *AstExprStmt = (*AstExprStmt)node;
    if (builder_emit_expr_stmt_call(ctx, es.expr) != 0) {
        return 0;
    }
    build_expr(ctx, es.expr);
    return 0;
}

func builder_stmt_const_decl(ctx: *BuilderCtx, node: u64) -> u64 {
    var cd: *AstConstDecl = (*AstConstDecl)node;
    builder_set_const(ctx, cd.name_ptr, cd.name_len, cd.value);
    return 0;
}

func builder_stmt_emit_loop_jump(ctx: *BuilderCtx, target_bb: *SSABlock) -> u64 {
    if (target_bb != 0) {
        var jmp_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_JMP, 0, ssa_operand_const(target_bb.id), 0);
        ssa_inst_append(ctx.cur_block, jmp_ptr);
        ssa_add_edge(ctx.cur_block, target_bb);
    }
    var dead_bb: *SSABlock = ssa_new_block(ctx.ssa_ctx, ctx.cur_func);
    builder_set_block(ctx, dead_bb);
    return 0;
}

func builder_stmt_dispatch_structural(ctx: *BuilderCtx, node: u64, kind: u64, result_out: *u64) -> u64 {
    if (kind == AST_BLOCK) {
        build_block(ctx, node);
        *result_out = 0;
        return 1;
    }
    if (kind == AST_IF) {
        build_if(ctx, node);
        *result_out = 0;
        return 1;
    }
    if (kind == AST_WHILE) {
        build_while(ctx, node);
        *result_out = 0;
        return 1;
    }
    if (kind == AST_FOR) {
        build_for(ctx, node);
        *result_out = 0;
        return 1;
    }
    if (kind == AST_SWITCH) {
        build_switch(ctx, node);
        *result_out = 0;
        return 1;
    }
    if (kind == AST_ALIAS) {
        var al: *AstAlias = (*AstAlias)node;
        if (ctx.debug_mode != 0) {
            emit("[DEBUG] alias reg=");
            emit_len(al.reg_ptr, al.reg_len);
            emit(" name=");
            emit_len(al.name_ptr, al.name_len);
            emit("\n");
        }
        compiler_reg_alias_set(al.reg_ptr, al.reg_len, al.name_ptr, al.name_len);
        *result_out = 0;
        return 1;
    }
    if (kind == AST_DEFER) {
        if (ctx.debug_mode != 0) {
            emit("[DEBUG] defer skipped in SSA builder\n");
        }
        *result_out = 0;
        return 1;
    }
    if (kind == AST_DELETE) {
        if (ctx.debug_mode != 0) {
            emit("[DEBUG] delete skipped in SSA builder\n");
        }
        *result_out = 0;
        return 1;
    }
    if (kind == AST_ASM) {
        var a: *AstAsm = (*AstAsm)node;
        var inst_ptr: *SSAInstruction = ssa_new_inst(ctx.ssa_ctx, SSA_OP_ASM, 0, ssa_operand_const(a.text_vec), 0);
        ssa_inst_append(ctx.cur_block, inst_ptr);
        *result_out = 0;
        return 1;
    }
    if (kind == AST_BREAK) {
        *result_out = builder_stmt_emit_loop_jump(ctx, builder_top_break(ctx));
        return 1;
    }
    if (kind == AST_CONTINUE) {
        *result_out = builder_stmt_emit_loop_jump(ctx, builder_top_continue(ctx));
        return 1;
    }
    return 0;
}

func builder_stmt_dispatch_terminal(ctx: *BuilderCtx, node: u64, kind: u64, result_out: *u64) -> u64 {
    if (kind == AST_EXPR_STMT) {
        *result_out = builder_stmt_expr_stmt(ctx, node);
        return 1;
    }
    if (kind == AST_VAR_DECL) {
        *result_out = builder_stmt_var_decl(ctx, node);
        return 1;
    }
    if (kind == AST_CONST_DECL) {
        *result_out = builder_stmt_const_decl(ctx, node);
        return 1;
    }
    if (kind == AST_ASSIGN) {
        *result_out = builder_stmt_assign(ctx, node);
        return 1;
    }
    if (kind == AST_RETURN) {
        *result_out = builder_stmt_return(ctx, node);
        return 1;
    }
    return 0;
}

func build_stmt(ctx: *BuilderCtx, node: u64) -> u64 {
    push_trace("build_stmt", "ssa_builder.b", __LINE__);
    defer pop_trace();
    var kind: u64 = ast_kind(node);
    if (SSA_BUILDER_DEBUG != 0) {
        emit("[DEBUG] build_stmt kind=");
        print_u64(kind);
        emit("\n");
    }

    var result: u64 = 0;
    if (builder_stmt_dispatch_structural(ctx, node, kind, &result) != 0) {
        return result;
    }
    if (builder_stmt_dispatch_terminal(ctx, node, kind, &result) != 0) {
        return result;
    }

    return 0;
}
